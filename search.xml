<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【译】子弹日志法（Bullet Journal）]]></title>
    <url>%2Fothers%2FBullet_Journal.html</url>
    <content type="text"><![CDATA[年前看了一篇国外程序员的博客，有提到Bullet Journal，不知所云。幸好我当时Gooole了一下。在Youtube上看到一份关于它的视频，便来了兴趣。当天下午便在它它的官网趴了半个下午，将它系统的学习了一遍。到现在，已经足有近月了，最初看的那篇博文已经毫无印象了，唯独对Bullet Journal一直念念。我自己呢，也觉得从最近这几天使用Bullet Journal的使用过程中获益不少。我既从中取利，便也有心为它做点贡献。我见网上对于Bullet Journal的介绍颇多，但多是英文，中文介绍零星有之，却又都是浅尝辄止，没有人做系统介绍。我想我便尽力将其官网完整介绍完整翻译吧。如果你有一定英文基础，我想原文才是最适合你的，里面图文并茂，排版精美。若是你视英文为洪水猛兽，希望下面的译文能对你有所助益。你可以先看一下下面这段视频，来点直观感受。 致列表疯子，笔记专家，便签狂人，和酷爱生活记录或涂鸦的家伙们。子弹日志正是给这些觉得很少有平台能像一张白纸一样强大的人所准备。它是一个为数字年代而生的模拟系统，助你梳理现在，记录过去，规划未来。 记录急速记录子弹日志的核心是一种叫做“急速记录”的方法。急速记录允许你快速的捕获和分析每天我们试图消化的各种各样的数据。这种技术让你能够区别哪些是重要的，剔除那些不重要的。搞清楚这些有助于你更有效的集中时间和精力。这是忙碌和高效之间的差别。 主题+条目 在子弹日志中，所有被你放入本子里面的东西都被称作为一条“条目”。若要加入一条条目，翻到第一个空白对开页。在左页的上方，给你的对开页一个简短的描述性标题，或者叫主题。主题是使子弹日志保持调理的关键组成模块。 如果某页仅是记录些普通的条目，可以直接用日期当主题。如果有一个特定的主题，花点时间给它想个名字。主题能帮你明确和集中你要输入的内容。问问你自己，“用什么描述我要输入的内容是最合适的？” 如果你觉得这个主题会比较复杂或者时间跨度很长，那么用一个子主题来明确这个集合指的是某个工程的哪个部分，例如装修/预算。 随意预留一到两个空的对开页，但无需为到底保留多少页而苦恼，因为很难知道一个特定的主题到底需要多少个对开页。主题经常是不连续的，所以确保总是将它们加入到索引——一个在你创建了它们后，可以快速查阅之处。 子弹 传统的日志和记笔记的方式最大的问题就是费时。条目越是复杂，你越得努力。你越是努力，就有越多的杂事被写下。你可能随时会放弃，又或者不能使日志的作用充分发挥。为了协助解决这个问题，急速记录深度依赖于使用简练符号表示法，或者叫子弹。子弹是一个简单的陈述句，用于把条目快速记录到你的日志中。它们通过把条目分类归入三个不同的类别来帮你组织条目，三个类别分别为：任务，便条，事件。 任务 任务用空白的复选框来表达，包括任意可执行的选项，例如“取干洗衣服”。一旦完成，愉悦的勾上复选框吧。有些任务需要多步才能完成。这些步骤或者说子任务可以紧挨着父任务的下面辅以一定的缩进列出来。父任务只有在所有的子任务都完成或被标记为无关紧要后才能勾选。 便条 便条用一个实心小圆丸表示。便条包括：灵感，想法，观察和所有非可执行条目。基本上，便条是所有那些，你不能马上去做想略记一下或没有什么时间背景的条目。 事件 事件用一个空心圈表示。一个事件本质上就是一个发生在特定日期的便条。事件可以被预先计划，例如“查理的生日”，也可以在它们发生后时记录，就像“签订了租契”。这个分类可能会让人难办，因为它具备令人无比沉重的潜力。 急速记录解决这个问题的办法是不论多么私人的问题，尽可能的保持客观和简明。例如，“电影之夜”这种说法比起“一个好朋友搬走了”的说法要更恰如其分。 记住，子弹仅仅是一种组织条目的快速方法。记录了这条事件后，在下一个可用的页，随你写下关于这条事件多么详细的情况。 子弹的日记的一个主要部分就是你可以照你的意愿取使用它，但是遵守这几条简单的指导方针能帮组你保持条理分明。 标识 标识赋予你的子弹们额外的语境。这儿有一组标识作为例子来指导你的起步，但是你完全可以自由发挥，使用你自己觉得在子弹日志过程中合适的标识。 优先级优先级的标识有一颗星来标识，用来指定一个任务应该优先解决。把它放在一个子弹的左边，因此你可以快速的翻页浏览并且找出最重要的条目。 深究深究标识用一个眼睛来标识，当有一些事情是你想要查阅的时，可以使用它。假设你写了一条需要进一步研究的便条，那么用深究标识来提醒你之后需要查阅一些资料。 灵感灵感标识最常用于和便条搭成一对，用感叹号来表示。再没有什么比有一个超赞的主意却记不起来要糟糕的了。现在，只需在那条便条前标识“!”，之后你就可以快速的查阅到它。 其它迁移标识用一个右箭头表示，置之于一个已被转移到子弹日志中其它部分的未完成任务子弹中。这是一个最顺手的标识之一，它使你能通过日志维持你对超时任务处理的轨迹。我们在下一章会对迁移有更多的接触。 舍弃标识通过对一个条目划删除线来表示，它在当一个任务失去了目标时使用。这种事一般发生在当某些事已经超时了，或者不再重要了。 页码为了能快速找到你要找的东西和保持条理，每次都给你的笔记页标上页码是子弹日志过程中极重要的一部分。一些反复发生的条目和集合往往不是连续的，因此在每一页的页脚写下页码使你能将它们加入到索引中非常重要。如果(例如我自己)你的子弹日志用于画草图，它也将有所帮助。每当我有一个想法需要阐明，我只是简单的翻转到下一个可用页或者平铺页输入它。把这些页面加入进去，我便能快速的自我定位了。 归类索引 索引应该在子弹日志的第一个空白页创建。 对内容编写索引，让你在快速找到想找的东西的同时，也让你可以你灵活自然的扩展子弹日志。它罗列了你的主题和主题的页码。 在你开始往子弹日志中添加内容时，只需将你的主题及其页所在页码加入到索引中。那些跨越了连续多个页的主题可以用“5-10”这样去索引。然而有些主题会反复出现并贯穿着子弹日志，这样的主题可以按这样的方式去索引：主题名：5-10,23, 34-39等等。 如果你有一些复杂的或者具有多面性的主题，你可能想要用子主题。子主题将允许你快速的索引一个大主题的特定部分。让我们来筹划一个长假。在过去的几个月中，你有五页专用于计划这个旅行。这些页面极可能是不连续的。每页都大概包含了像旅馆，航班，游览等等这次旅行的特定部分。依靠使用子主题，你便能快得多的在索引中找到想要查阅的内容了。 月历 月历为你提供一种计划和重组的方法。它提供了一种组织事件和任务的方法，在月初允许你为一个月做一个快速督促。在之后它也是一个很好的引用资料。 月历应该在每个月开始的时候创建。创建第一个月历时，应找到下一个可用的空白对开页。左页将是你的日历页，而右页将是你的任务页。 对于日历页，用当月的月份做你的标题，然后在左边界列举该月所有的日。在页边和数字之间给标识留一点空间。如果你愿意，你也可以在日期后加上那天所属星期的第一个子母。 填入所有像生日或约会之类这些看上去不会改变的事件。你在这儿的输入应该尽可能的简单，它只是为查询而设计的。使用铅笔来安排所有不确定的项。 任务页只是一个简单的任务子弹清单——一个所有你想要完成的事情的清单。同样的，在页边为附加标识留一点空间。当你列完所有的任务时，回顾一下你的清单，看一下哪些项是最重要的。在子弹的左边，挨着这些项标上一颗星。 到你准备开始你的第二个月历的时候，你也要用到你之前的月历，把所有未完成的任务迁移到你的新任务页中。 现在你有了一个需要完成的任务的概况和能去做它们的时间。当然如果你愿意，你也可以在你的日历页中安排你的任务，但是这儿真是的目的是获得你想做的事的基本概况和你的可用时间。 每日日历 在你的月历页后为你的每日日历翻开新的一页。在该页的上方，填入当天的日期。在这一天中的过程中，发生了什么事情便填入相应的子弹。如果没有用满一页，那么填上第二天的日期来把这一页分开成不同的日。这样既节省空间、时间，又让你可以看到你最近一次使用子弹日志是什么时候。 理想情况是，任何时候你都带着你的子弹日志，而且能实时的写下条目。如果不行，尝试养成在睡前拿出你的子弹日志坐到桌前回顾一天的习惯。除了使你保持规律外，我觉得它令人心情舒适并让你为第二天早晨准备好。 迁移内容迁移是子弹日志过程的基石之一。一旦到了下个月开启时，查阅你到上一个月历页之间所有页。很有可能，你有留下一些没有勾上的任务。仔细检查它们并评估你是否确实完成了它们，或者那个任务已经变得无关紧要了，如果一个打开的任务已经完成了，那么勾上它。如果它已经变得无关紧要了，那么用删除线划掉。如果这个任务仍然是你关心的事，那么把它加入你新月历的任务页。 这儿的目的不是尽量多的收集任务，而是为了谨记你需要做什么和过滤掉那些不再重要的项。再次声明，忙碌和高效之间是有区别的。 集合 当你开始经常使用你的子弹日志时, 你会注意到你的某些子弹具有相同的主题，或都和另外一个子弹有直接关系。当它们足够多之日，便是创建一个集合之时。要创建集合，翻到你的下一个空白页，并给你的集合一个主题。把这个主题加入到索引中，并且找出所有和这个主题相关的子弹。当你把所有的子弹都移到集合中以后，回到这些子弹原来的位置并把它们标记为已迁移。这些操作最适用于任务，不过也能用于想法和便条。 和其它主题一样，集合会随着时间增长，也是一个组织相关子弹的简单方式。我发现更新和创建一个集合的最佳时间在每个月的开始时你创建月历的时候。 其它小贴士笔记本类型我推荐使用Moleskin的大型方格笔记本，因为那些格子对于我要做的事来说堪称完美。不过这绝非一个先决条件。另外，我喜欢大部分Moleskine都会内置的小配件，像书签和后面的小口袋，我可以随便将一些碎片一直放在里面直到我处理掉它们。 大小和质量是需要在意的两个主要因素。如果它太大了，你就无法携带。如果它太小了，就不太实用。确保你获得的笔记足够耐用，如此它才能一直跟随你左右。我爱我那能让我回味过去几年的意义的旧子弹日志们。 生命周期我发现在新的一年使用一个新的笔记本会让你更容易对它们进行编册。即使你的本子仅仅用了四分之一，在新的一年以一个空白的状态开始会有鼓舞和促进之用。 钢笔 VS 铅笔大部分情况下，我使用钢笔因为铅笔的笔迹会逐渐变淡。子弹日志的最大好处就是随着时间的推移你用它们建立了一个资料库。我只在绘制草图或者往我月历的事件页中添加项的时候才使用铅笔，因为变化决定了计划。 身份和保障即使大部分子弹日志都会非常私密，我还是高度推荐在本子的前面加上显眼的记录，在它被遗失的时候方便别人可以联系到你。留下你的名字和手机号码会很管用。现金奖励是个极大刺激，当然个性化的留言也不错。在一辆交通高峰期内开往纽约的火车上，我的子弹日志从包里掉出来了，然后它又回到了我的手里。 关于我的名字叫Ryder Carroll, 是一个生活在纽约布鲁克林区的艺术指导和交互设计师。我经过多年的试验和错误开发了这套系统，伴随着更好的模式被我挖掘，希望能不断提升它。我希望你明白了这儿呈现的理念，应用/适应了它们并发挥了它们的最大的效用。 这个页面是我对在过去几年许多用他们的学识、天资和见识免费帮助和鼓舞我的那些聪颖而慷慨的人们的一点谢意。子弹日志系统在这些年来给我带来了巨大的帮助，我也希望它在某些细微之处能对你有所帮助。]]></content>
      <categories>
        <category>Others</category>
      </categories>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并查集(Disjoint Set)]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2FDisjoint_set.html</url>
    <content type="text"><![CDATA[一些应用经常有这样的需求：查找一个包含某个元素的唯一集合，合并两个集合。搜了一下google能够应用的地方还是挺多的，这里略去不表。 并查集又称不相交集，有两个名字的原因在于它原就有两个不同的英文名字，Disjointsets和Union-find set。更准确点应该说并查集是用来操作不相交集的数据结构。算法导论上这一章就叫用于不相交集合的数据结构（Data Structures for Disjoint Sets）。维基百科上也说： A union-find algorithm is an algorithm that performs two useful operationson such a data structure: Find: Determine which subset a particular element is in. This can be usedfor determining if two elements are in the same subset. Union: Join two subsets into a single subset.Because it supports these two operations, a disjoint-set data structure issometimes called a union-find data structure or merge-find set. 但一般说Disjoint Sets就指的是Data Structures for Disjoint Sets。 话休饶舌（最近金瓶梅看多了），转到并查集的正题上来。 并查集的操作并查集维持了一组不相交动态集合\(S = \lbrace S_1, S_2,…,S_k\rbrace\)，简言之并查集就是一些互不相交的动态集合的集合。假设\(x\)是某动态集合中的对象，那么并查集应该支持以下操作： MAKE-SET(x) 创建一个只有一个成员\(x\)的新集合，并要求\(x\)不在其它的集合中。 UNION(x, y) 合并\(x,y\)所在的集合。\(x, y\)所在的原集合都不再存在，一个新的集合产生。 FIND-SET(x) 返回包含\(x\)的集合。 并查集的一个应用并查集众多应用中的一个就是用来确定无向图中的联通子图。对于图\(G\),我们用\(G.V\)来表示它顶点的集合，用\(G.E\)来表示它所有边的集合。下图(a)是一个包含四个联通子图的图。我们用并查集的操作来实现CONNECTED-COMPONENTS用以计算图的联通子图，一旦CONNECTED-COMPONENTs执行，则可以用SAME-COMPONENT来判断两个顶点是否在同一个联通子图上。下图(b)则说明了对图(a)执行CONNECTED-COMPONENTS的过程。 123456789101112CONNECTED-COMPNENTS(G) for each vertex in G.V MAKE-SET(v) for each edge (u, v) in G.E if FIND-SET(u) != FIND-SET(v) UNION(u, v)SAME-COMPONENT(u, v) if FIND-SET(u) == FIND-SET(v) return TRUE else return FALSE 并查集的链表表示下图(a)展示了一个用链表表示的并查集:每个集合都有其自己的链表表示。每个集合的对象都有一个head指针指向链表的第一个对象，一个tail指针指向链表的最后一个对象。每一个链表对象都有一个next指针指向链表中的下一个对象，以及一个指向集合对象的的指针。 用链表表示的并查集实现MAKE-SET和FIND-SET都很容易，并且只需\(O(1)\),略去不表。对于UNION的实现，则要复杂点。 UNION的简单实现如上图(b)所示，实现UNION的最简单方法是将一个链表附加到另一个链表的最后。我们可以很快的通过tail和head指针找到一个链表的第一个对象和最后一个对象，并将两个链表链接起来，不过不幸的是我们还要将其中一个链表的所有对象中指向集合的指针更新。 实际上，我们可以轻易的构建一个用于\(n\)个对象上的m个操作且需要\(O(n^2)\)运行时间的序列。假设我们有对象\(x_1,x_2,…,x_n\)。我们用\(n\)个MAKE-SET来创建\(n\)个并查集，并依靠\(n-1\)来将它们合并成一个并查集，所以\(m = 2n -1 \)。最坏情况下，这\(2n-1\)个操作的顺序和用时是这样的： Operation Number of objects updated MAKE-SET(\(x_1\)) 1 MAKE-SET(\(x_2\)) 1 . . . . . . MAKE-SET(\(x_n\)) 1 UNION(\(x_2, x_1\)) 1 UNION(\(x_3, x_2\)) 2 . . . . . . UNION(\(xn, x{n-1}\)) n 很显然这\(2n-1\)个操作的复杂度为： \[ m + \sum^{n-1}_{i=1}{i} = \theta(n^2)\] 所有这\(2n-1\)个操作的平均复杂度在\(\theta (n)\)。 加权合并(weighted-union)的启发策略在最坏的情况下，合并的时候我们总是把一个长的链表合并到一个短的链表中去，于是我们不得不更新更多的对象。反过来，假如在合并的时候我们总能把一个短的链表合并到一个长的链表中去的话，则能保证我们每一次合并操作都以最合理的方式进行，而不是依赖于运气了，而我们仅仅只需维持一个属性来代表链表的长度就能轻而易举的达到上述目的。利用启发策略改进后的合并操作仍然需要\(\omega(n)\)的时间，假如两个集合都有\(\omega (n)\)个成员的话。但是对于一个由MAKE-SET、UNION、FIND-SET组成的大小为\(m\)，其中\(n\)个操作为MAKE-SET的操作序列来说，最多花费\(O(m + n\lg n)\)，下面给出证明： 对于合并操作来说，我们最多执行\(n-1\)次操作。先来计算一下合并操作最多能花费多少时间。合并操作的运行时间取决于更新链表中对象的指针的数目。换言之，通过计算对象指向集合指针的更新次数就能计算出合并操作花费的总时间。对于对象\(x\)来说，如果它指向集合的指针被更新，代表着它处在一个较短的链表中，那么当\(x\)指向集合的指针第一次被更新的时候它所在的链表最少有两个成员，第二次被更新时最少有4个成员，第三次最少有8个…，很显然对于\(x\)来说从始至终，它指向集合的指针最多能被更新\(\lg n\)次，那么所有\(n\)个它们指向集合的指针最多能被更新\(n\lg n\)次。 而除合并操作外的其它操作都只需要\(O(1)\)的时间，所以这个序列需要的总时间为:\(O(m + n\lg n)\)。 不相交集森林与之前用链表表示一个集合不同，不相交集森林用一棵树来表示一个集合。不相交集森林如下图(a)表示的，每个结点代表一个成员都只包含一个指向父亲的指针，根节点的父亲是自己。 以这样的方式来实现并查集的三个操作： A MAKE-SET operation simply creates a tree with just one node. We performa FIND-SET operation by following parent pointers until we find the rootof the tree. The nodes visited on this simple path toward the rootconstitute the find path. A UNION operation, shown in Figure 21.4(b),causes the root of one tree to point to the root of the other 可改进运行时间的启发式策略但直接用这个简单的结构并不会有更快的速度，极端的情况是当一颗树成棍状时，它和链表并没有什么区别。不过有两种方法可以对它进行优化——按秩合并(union by rank)和路径压缩(path compression)。 按秩合并(union by rank) 和链表的加权合并非常类似，不过这里是根据树的高度来合并，总是将矮的树合并到高的树中。对于每个结点，我们维持一个rank属性，用来表示每个结点高度的一个上界。 路径压缩方法用在FIND-SET操作中，其具体做法就是在查找的过程中将查找路径上的每一个结点都直接放到根结点下。查找路径并不改变任何结点的*rank*^1。 不相交集森林操作的伪码实现12345678910111213141516171819MAKE-SET x.p = x x.rank = 0UNION(x, y) LINK(FIND-SET(x), FIND-SET(y))LINK(x, y) if x.rank &gt; y.rank y.p = x else x.p = y if x.rank == y.rank y.rank + 1FIND-SET(x) if x != x.p x.p = FIND-SET(x.p) return x.p 当同时使用到上述两种启发式策略时，不相交集森林\(m\)个操作的运行时间在\(O(m\alpha(n))\),\(\alpha(n)\)的增长非常慢，在可以想象到的不相交集森林的应用中，\(\alpha(n) \leq 4\),所以这个运行时间可以看作是线性的。也就是说不相交集森林操作的平摊分析是\(O(1)\)。关于这个上限的证明，未曾吃透，也没什么心情去细细看了，这篇笔记就只能如此草草记之了。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>Disjoint set</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Van Emde Boas trees]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2FVan_Emde_Boas_trees.html</url>
    <content type="text"><![CDATA[van Emde Boas trees 支持所有优先级优先级队列的操作，并且巧妙的是它对于SEARCH,INSERT,DELETE,MINIMUM,MAXMUN,SUCCESSOR,和PREDECESSOR这些操作的支持都在最坏复杂度\( O(\lg{\lg n}) \)之内。不过有些限制的是，所有的Kye值都必须在\( 0 \dots n-1 \)之间，且不能有重复值。换言之，他的算法复杂度不由数据的规模有多 大而决定，而由key值的取值范围而决定。 算导上这一章的讲述方式我非常喜欢，循序渐进，从最基础最简单的一个结构开始，最终演化成Van Emde Boas trees，这样的方式更能让人捕捉到发明人思路发展的一个演变过程，毫无疑问，这一章得多记点笔记。 基础方法这部分会有三种方法来存储动态集合，尽管它们没有一个能达到\( O(\lg\lg u) \),但是通过这三种方法却能让我们得到理解Van Emde Boas trees的真知灼见。 Direct AddressDirect Addressing提供一种最简单的方法来存储一组数据。Direct Addressing直接用一个大小为\( u \)的位数组\( A[0..u-1] \)来存储这组属于集合\( \lbrace 0,1,2,…,u-1 \rbrace \)的数。如果这组数中有\( x \),那么\( A[x] \)的值存1，否则存0。 这种简单粗暴的方法，显然不能达到预期。对于INSERT、DELETE、MEMBER这些操作复杂度在\( O(1) \)内。而对于MINIMUM、MAXMIMUM、SUCCESSOR、PREDECESSOR这些操作每一个都要\( \theta(u) \)。我们不妨对Direct Addressing进行改进一下。几个\( \theta(u) \)的操作皆因必须对数组进行迭代才能得到结果的缘故。那么如果我们在Direct Addressing之上建立一棵二叉树想必有所改善。 Superimposing a binary tree structure为了提高几个操作的效率，我们的数据结构由一个数组，演变成了下面的结构： 二叉树中的结点存储着0或1，当两个孩子中有一个为1时它为1，只有当两个孩子都为0的时候它才为0。 在Direct Addressing中花费\( \theta(u) \)的操作，依赖于这棵二叉树现在都有了一个更低的上限\( O(\lg{u}) \)。但这个上限还并不理想，不然我们不如使用一棵红黑树，好歹人家还是\( O(\lg{n}) \)的上限。如果把这棵树的高度降低，说不定是一个突破口，姑且试试。 Superimposing a tree of constant height要降低树的高度，我们可以直接通过增加树的度数来实现，将二叉树将变为多叉树。假设全域的大小是\( u = 2^{2k} \),其中\( k \)是一个整数，那么\( \sqrt{u} \)也是一个整数。 和在位数组上建立一棵二叉树不同，现在我们在位数组上建立一棵度数为\(\sqrt{u}\)的树，如下图(a)。这棵树的高度是2。树中的每个结点存储了各子树的逻辑与结果。 如下图(b)所示，可以将那些结点看作是一个数组\( summary[0..\sqrt{u}-1] \),当且仅当\( A[i\sqrt{u}..(i+1)\sqrt{u}-1] \)含1,\( summary[i] \)才为1。 我们把\( A \)中的\( \sqrt{u} \)位的子数组称为簇，对于一个给定值\( x \),位\( A[x] \)存在于第\( \lfloor x/\sqrt{u}\rfloor \)个簇中。现在INSERT将在\( O(1) \)内完成——对于插入一个\( x \),分别将\( A[x] \)和\(\lfloor x/\sqrt{u}\rfloor \)设为1。对于MINIMUM、MAXIMUM、SUCCESSOR、PREDECESSOR和DELETE这些操作将花费\( O(\sqrt{u}) \)。具体操作不做赘述。 比起Superimposing a binary tree，现在的结构似乎反而更糟了，前者最差劲的操作也只要\( \lg{u} \),现在都要\( \sqrt{u} \)了，但是透过这个结构带来了一点新的想法，如果我们把数组\( summary \)也变作一个Superimposinga tree ofconstant height怎么样，一路递归下去情况会如何? A recursive structure前面用\(\sqrt{u} \)度数的树给了我们一个启示，假如我们能够把问题的规模以开平方的规模缩小的话，会有一个什么效果？假设我们能做到以开平方的规模递归减小一个数据结构的规模，而且每个操作在每一级递归上只产生一次新的递归调用，那么 对于一个大小为\( u \)的数据结构的操作有：\[ T(u) = T(\sqrt{u}) + O(1) \]令\( m= \lg{u} \), 有\( u = 2^m \)。那么可以有：\[ T(2^m) = T(2^{m/2}) + O(1)\]设\( S(m) = T(2^m)\),可得新方程：\[ S(m) = S(m/2) + O(1)\]可以得出\( S(m) = O(\lg m) \),回到\( T(u) \)上来，那么\( T(u) = T(2^m) = S(m) = O(\lg m) = O(\lg{\lg u}) \)。 这个假设说明如果我们能够以递归方式以开平方的规模来缩小数据的规模大小，并在每一级递归上花费\( O(1)\)的时间的话，我们这个假设的数据结构的操作的复杂度将是\( O(\lg{\lg u}) \)。 围绕方程 \( T(u) = T(\sqrt{u} + O(1)) \),我们来设计一个递归的数据结构，以开平方的规模来减小每一次递归的大小。当然，我们可能不能一步达到让所有的操作都达到\( O(\lg{\lg u}) \),但是我们还是可以先设计出一个原型。自\( u \)起，我们用一个\( \sqrt{u} = u^{1/2}\)项的数据结构来持有\( u^{1/4} \)项的，以\( u^{1/4}\)项的递归持有\( u^{1/8} \)项的，以\( u^{1/8} \)项的递归持有… \( u=2^{2^k} \)，如此，\( u^{1/2}，u^{1/4},u^{1/8},… \)都为整数。 对于一个全域为\( \lbrace 0,1,2,…u-1 \rbrace \)的van Emde Boas数据结构为原型，我们简称为proto-vEB(u)。它遵循以下这些规则： 如果\( u = 2\),那么已是基础大小，那么它包含两个标志位\( A[0…1]\) 否则，\( u = 2^{2^k} \), 且整数\( k \geq 1\), 所以\( u \geq 4 \)，这时，proto-vEB(u)包含两个属性: 一个名为summary指向proto-vEB(\(\sqrt u\))的指针。 一个\( \sqrt{u} \)大的指针数组\( cluster[0…1] \)，其中每一个指针指向一个proto-vEB(\( \sqrt u \))。 如果cluster的第i个指针所指向的的集合含有元素，那么i也存在于summary所指向的集合中，否则i也不存在于summary中。 对于一个\( u = 16 \)的集合\( \lbrace 2,3,4,5,7,14,15 \rbrace \)情况就是下面这样的： 在proto-VEB(u)中，一个给定值\(x\),那么他应该储存在proto-VEB(u)中cluster的第\( \lfloor{x}/\sqrt{u} \rfloor\)个指针指向的proto-VEB(\( \sqrt{u} \))的第\( x \mod \sqrt{u} \)个值。鉴于此，在分析各项操作之前，先定义几个有用的工具函数：[ high(x) = \lfloor{x} / \sqrt{u} \rfloor ][ low(x) = x \mod \sqrt{u} ] [ index(x, y) = x\sqrt{u} + y ] 判断一个值是否存在PROTO-VEB-MEMBER(V, x) if V.u == 2 return V.A[x] else return PROTO-VEB-MEMBER(V.cluster[high(x)], low(x)) 一个简单的递归查找，很显然，\( T(u) = T(\sqrt u + O(1)\),无疑复杂度为\( O(\lg\lg u) \)。 找最小值从summary中得到最小值i，那么最小值必定存在于\(cluster[i]\)所表示的集合中，在从\(cluster[i]\)表示的集合中得到最小值，结合i值可以得到全局的最小值。伪码： 123456789101112131415PROTO-VEB-MINIMUMN(V) if V.u == 2 if V.A[0] == 1 return 0 else if V.A[1] == 1 return 1 else return NIL else min-cluster = PROTO-VEB-MINIMUM(V.summary) if min-cluster == NIL return NIL else offset = PROTO-VEB-MINIMUN(V.cluster[min-cluster]) return index(min-cluster, offset) 复杂度\[ T(u) = 2T(\sqrt u) + O(1) \] 设\( u = 2^m\)\[ T(2^m) = 2T(2^{m/2}) + O(1) \] 设\(S(m) = T(2^m)\),得：\[ S(m) = 2S(m/2) + O(1) \]\[ T(u) = S(m) = \theta(m) = \theta(lg u) \] 找x的后继 从x所在的子集中找后继 找不到的话，先从summary中得到下一个子集的索引，从下一个子集中找最小值。 转换成全局的值。 伪码： 1234567891011121314151617PROTO-VEB-SUCCESSOR(V, x) if V.u == 2 if x == 0 and V.A[1] == 1 return 1 else return NIL else offset = PROTO-VEB-SUCCESSOR(V.cluster[high(x)], low(x)) if(offset != NIL) retuen index(high(x), offset) else succ-cluster = PROTO-VEB-SUCCESSOR(V.summary, high(x)) if succ-cluster != NIL offset = PROTO-VEB-MINIMUM(V.cluster[succ-cluster]) return index(succ-cluster, offset) else return NIL 复杂度:\[ T(u) = 2T(\sqrt u) + \theta(\lg{\sqrt u}) \]\[ = 2T(\sqrt u) + \theta(\lg u) \]用与前文类似的方法可以化得\( T(u) = \theta(\lg u\lg\lg u) \) 插入元素一路向下递归插入，并将summary相应设为1即可。伪码： 123456PROTO-VEB-INSERT(V, x) if V.u == 2 V.A[x] = 1 else PROTO-VEB-INSERT(V.summary, high(x)) PROTO-VEB-INSERT(V.cluster[high(x)], low(x)) 复杂度和PROTO-VEB-MINIMUN一样\[ T(u) = 2T(\sqrt u) + O(1) \]即\(\theta(\lg u)\) 删除元素相对于插入，删除要麻烦一点，因为不能直接从summary中删除元素。要确保相对应的cluser所代表的子集不包含任何元素才能在smmary中置0。探查一个proto-VEB是否只包含一个元素，以目前的结构可以有几种方式，但没有一种快于 \(\theta(\lg u)\)的方式。也就是说PROTO-VEB-DELETE注定要超过 \(\theta(\lg u)\)。这儿先别急着实现proto-VEB的删除操作，先来回顾一下，所有的基本操作我们都已经分析过一遍了。拿最大值、最小值很慢，拿前驱、后继很慢，插入删除也要比预期的慢，似乎除了MEMBER操作，所有的操作都很慢，但是仔细分析发现，找前驱慢是因为取最小值太慢了，找后继慢是因为取最大值太慢了。插入慢是因为要额外对summary执行一次插入，删除慢是因为对这个结构的判空慢，实际上插入和删除慢是因为同一个问题，没法快速知道一个proto-VEB的尺寸和极限值。归根结底，这些操作慢的症结在于，没法快速知道最大值最小值，因为知道最大值最小值以后，尺寸便能在\(\theta(1)\)之内得到了。既然如此，我们不如直接将最大值，最小值直接记录在proto-VEB的结构中。Van Emde Boas Trees的最终模型就得到了，给proto-VEB添加记录最大值和最小值的两个属性。 The van Emde Boas tree先约定，将van Emde Boas tree简称为vEb。 在给proto-VEB加上min和max两个属性之前,还得有一个问题要解决，proto-VEB 要求\(u = 2^{2^k}\)，这个要求显然有点太过苛刻了，现在我们把这个范围放宽到\(u = 2^k\)。放宽要面对的第一个问题就是\(\sqrt u\)不一定是整数了，解决的办法便是，我们的规模不再要求以开平方的规模来缩小了，而是以接近开平方的规模缩小，简言之，原来将proto-VEB(u)分解为\(\sqrt u\)个proto-VEB(\(\sqrt u\)),现在则是将vEB(u)分解成\(\lceil (\lg u)/2 \rceil\)个vEB(\(\lfloor (\lg u)/2 \rfloor\))。直观起见，将\(\lceil (\lg u)/2 \rceil\)用\(\sqrt[\uparrow] u\)表示,将\(\lfloor (\lg u)/2 \rfloor\)以\(\sqrt[\downarrow] u\)表示，\(u = {\sqrt[\uparrow] u} \cdot {\sqrt[\downarrow] u}\). 相较于proto-VEB结构上有以下两个变化： 增加min和max两个属性 对于\(u = 2\)的VEB来说，不需要数组\(A[0..1]\)了，因为min和max足以来记录两个值。 对于\(u &gt; 2\)的VEB来说，min不储存在任何一个cluster中，但是max值要，为什么这么做，可以让在空集合中插入元素和删除集合中唯一元素的操作都为\(O(1)\)。 重新定义一下几个方法：\[high(x) = \lfloor x / \sqrt[\downarrow] u \rfloor \]\[low(x) = x \mod \sqrt[\downarrow] u \]\[index(x, y) = x \sqrt[\uparrow] u + y \] 现在，vEB的结构应该是这样的：一个具体的例子: 最大值和最小值1234VEB-TREE-MINIMUN(V) return V.minVEB-TREE-MAXIMUM(V) return V.max 判断一个值是否存在1234567VEB-TREE-MEMBER(V, x) if x == V.min or x == v.max return TRUE else if V.u == 2 return FALSE else return VEB-TREE-MEMBER(V.cluster[high(x)], low(x)) 后继1234567891011121314151617181920VEB-TREE-SUCCESSOR(V, x) if V.u == 2 if x == 0 and V.max == 1 return 1 else return NIL else if V.min != NIL and x &lt; V.min return v.min else max-low = VEB-TREE-MAXMIUN(V.cluster[high](x)) if max-low != NIL nad low(x) &lt; max-low offset = VEB-TREE-SUCCESSOR(V.cluster[high(x)], low(x)) return index(high(x), offset) else succ-cluster = VEB-TREE-SUCCESSOR(V.summary, high(x)) if succ-cluster == NIL return NIL else offset = VEB-TREE-MINIMUN(V.cluster[succ-cluster]) return index(high(succ-cluster), offset) 前驱略。 插入元素12345678910111213141516VEB-EMPTY-TREE-INSERT(V, x) V.min = x V.max = xVEB-TREE-INSERT(V, x) if V.min == NIL VEB-EMPTY-TREE-INSERT(v, x) else if x &lt; V.min exchange x with V.min if V.u &gt; 2 if VEB-TREE-MINIMUN(V.cluster[high(x)]) == NIL VEB-TREE-INSERT(V.summary, high(x)) VEB-EMPTY-TREE-INSERT(V.cluster[high(x)], low(x)) else VEB-TREE-INSERT(V.cluster[high(x)], low(x)) if x &gt; V.max V.max = x 删除元素1234567891011121314151617181920212223VEB-TREE-DELETE(V, x) if V.min == V.max V.min == NIL V.max == NIL else if V.u == 2 if x == 0 V.min = 1 else V.min = 0 V.max = V.min else if x == V.min first-cluster = VEB-TREE-MINIMUN(V.summary) x = index(first-cluster, VEB-TREE-MINIMUN(V.cluster[first-cluster])) V.min = x VEB-TREE-DELETE(V.cluster[high(X)], low(x)) if VEB-TREE-MINIMUN(V.cluster[high(x)]) == NIL VEB-TREE-DELETE(V.summary, high(x)) if x == V.max summary-max = vEB-TREE-MAXIMUN(V.summary) if summary-max == NIL V.max = V.min else V.max = index(summary-max, vEB-TREE-MAXMIMUN(V.cluster[summary-max])) 综合分析上面的几个操作，除了删除操作以外其它几个操作每一次递归调用都只产生一次新的递归调用。根据前文的\( T(u) = T(\sqrt{u}) + O(1) \)公式，些操作 都是\(O(\lg \lg u)\)。再仔细看下删除操作的第二次递归调用(在第16行)我们会发现,假如这一次递归被调到，那么必然x所在的cluster只包含一个元素，这种情况下第一次递归调用(在第14行)只花费常数时间(只执行1-3行代码)，换言之，第二个递归调用发生的情况下，第一个递归调用必然能在常熟时间内完成。所以删除操作还是符合公式\( T(u) = T(\sqrt{u}) + O(1) \)。 小结Van Emde Boas Tree空间的大小依赖于\(u\)的大小而不是数据的规模，另外创建一个Van Emde Boas Tree初始化的时间估计不会太少。当然这些都是可以优化的问题。 本文参考： Introduction To Algorithm ——third edition]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>Exercises</tag>
        <tag>van Emde Boas trees</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[未半]]></title>
    <url>%2Fessaies%2Fless_than_half_of_year.html</url>
    <content type="text"><![CDATA[来珠海也近半年了，半年来并没有太大的不顺。大概却正因为这顺利，让我恍然未觉的过了半年。时间过得如此悄无声息，让我战战栗生出了一股惶恐来。每过一月，或又仅有一旬，当我注意到桌上的台历忘了翻动，又或者电脑上的日期让我觉得陌生时，我总觉得我应该静下来好好想想，生活是不是驶往我期待的方向。 我原来想到“半”不免就生出一股沮丧来。半年的时间，便如同朝暮一般，来时的景象，朋友间的相约，路上的拥挤，犹在眼前。冬夏之替，也只如隔一日。但任我觉得只是短短的意象，却又是实打实的半年，我只恨这半年没有留下更多点记忆，能做多点想做的事情。 若单单是这偶尔感由心生的点点悲哀的话，也不会叫我如何的。便是一觉睡来也就揭过，如何能令我这心思粗鄙，心间缺少玲珑的人时时挂怀呢？ 叫我忧心的却另有其它几样小事。 我来时极想做的几件事一件也没能做成，极想看的几本书一本也没有去看。前几日又恰巧读到了知堂的一段笔记——“转瞬仲冬，学术无进，而马齿渐增，不觉恧然”——这是多么和我相像的一种心情。我所虑的又不止于此。我原来像做的事、想看的书，半年之后依旧，只是时间已过半年。我只怕十年八载之后，依旧如现在这般想法，然后感叹十年转瞬。我太怕在安逸中老去，忘却了我来这世界的初衷，相反，我倒更愿意哪怕在困境中前行，却能一直砥砺品行，让自己铭记最初的想法。 知堂那段话让我心生共鸣之外，也令我“不觉恧然”，他那段日记大概十三四岁所记，而这样的道理，我却明白的晚了许多。 除却知堂那段话，却又有一段零碎的梦也触动了我的神经。这段梦是近断时间做的，哪天晚上也记不得了，这梦可说平凡无奇，却又有些怪诞不经。我梦见了不知是回到了小学，还是初中时代，端坐在教室读书，周身同学连我在内，却并没有回归童颜，都是一副大人模样。这样不讲逻辑的事情，出现在梦中，本是在平常不过，但我坚信，它是要叫我明白逝者如斯，不可回追的道理，也是要叫我明白，物是人非，沧海桑田的残酷。 下午，我再无法抑制这种情感的上升，于是打开了编辑器。编辑器中有一条“未半”的标题、一条“2012-12-1607：30”的时间戳、一句“我来珠海也近半年了”的开头。十七号写下一个“未半”的标题，一是心里感叹半年过得太快，但距离半年尚差几日，可以说是“未半”。再则，若是倒过来看，“半”也就成了“未”，掺杂点未来的意为，也能带股生气来。今日已是二十五，半年也足足有了，无所谓“未半”了。我于是又慎重的关了编辑器，拿出笔和纸，记下上文。 十二月二十五日于莲山巷。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[斐波那契堆的C++实现]]></title>
    <url>%2Falgorithm%2Ffibonacci-heaps-in-cpp.html</url>
    <content type="text"><![CDATA[时间过的真是快，都是七月份写的代码了，两个多月了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256//-------------------------------------------------------------------------//filename: fibonacciHeaps.h//Author: Adoo//date: 2012/7/16//Description:Implement Fibonacci Heaps by C++//-------------------------------------------------------------------------#ifndef FIBONACCIHEAP_HPP#define FIBONACCIHEAP_HPP#include&lt;algorithm&gt;template&lt;typename T&gt;class FibonacciHeap&#123;public: struct node&#123; T value; node* parent; node* child; node* left; node* right; bool mark; int degree; node(T t_value=T()):value(t_value),parent(NULL),child(NULL), left(this),right(this),mark(false),degree(0) &#123;&#125; &#125;;public: FibonacciHeap():min(NULL),size(0)&#123; &#125; node* insert(T value)&#123; node* pn= new node(value); if(min==NULL) min=pn; else&#123; //insert the new node to circular doubly list; insertToList(min,pn); if(min-&gt;value &gt; pn-&gt;value) min=pn; &#125; size+=1; return pn; &#125; bool empty()&#123; return NULL==min; &#125; node* minmum()&#123; return min; &#125; node* extract_min()&#123; //As soon as the min node been extract,the node is no relation with the object; //User who extrat the node should release it; node* z=min; if(z!= NULL)&#123; while( z -&gt;child != NULL)&#123; node* pn = extract_node(z-&gt;child); insertToList(min,pn); &#125; if (z == z-&gt;right)&#123; min=NULL; &#125; else&#123; min = z-&gt;right; z = extract_node(z); consolidate(); &#125; size -= 1; &#125; return z; &#125; void merge(FibonacciHeap &amp; fib) &#123; if (this-&gt;min != NULL) &#123; if (fib.min != NULL) &#123; min-&gt;right-&gt;left = fib.min-&gt;left; fib.min-&gt;left-&gt;right = min-&gt;right; min-&gt;right = fib.min; fib.min -&gt;left = min; if(min-&gt;value &gt; fib.min-&gt;value) min = fib.min; &#125; size += fib.size; &#125; else min = fib.min; fib.min = NULL; &#125; bool decrease_key(node* x, T value) &#123; if(x-&gt;value &lt; value) return false; x-&gt;value = value; node* p= x-&gt;parent; if (p != NULL &amp;&amp; x-&gt;value &lt; p-&gt;value) &#123; x=extract_node(x); insertToList(min, x); cascading_cut(p); &#125; if(x-&gt;value &lt; min-&gt;value) min = x; return true; &#125; void delete_node(node* pn)&#123; decrease_key(pn, numeric_limits&lt;T&gt;::min() ); pn = extract_min(); delete pn; pn = NULL; &#125; ~FibonacciHeap()&#123; //release resource while (min != NULL &amp;&amp; min != min-&gt;right) &#123; node* tmp=min; min=min-&gt;right; extract_node(tmp); release_node(tmp); &#125; release_node(min); min = NULL; &#125;private: void release_node(node * x) &#123; if(x != NULL) &#123; while (x-&gt;child != NULL) &#123; node* tmp=extract_node(x-&gt;child); release_node(tmp); &#125; delete x; x= NULL; &#125; &#125; void insertToList(node* pos, node* pn )&#123; if(pos!=NULL)&#123; pos-&gt;right-&gt;left=pn; pn-&gt;right=pos-&gt;right; pos-&gt;right=pn; pn-&gt;left=pos; pn-&gt;parent=pos-&gt;parent; if (pos-&gt;parent != NULL) pos-&gt;parent-&gt;degree += 1; &#125; &#125; node* extract_node(node* pn)&#123; //提取结点，对结构来说安全。 //但只是简单的用其右兄弟代替它。 if (pn == NULL) return NULL; if(pn-&gt;parent != NULL)&#123; pn-&gt;mark=false; if (pn-&gt;right != pn) pn-&gt;parent-&gt;child = pn-&gt;right; else pn-&gt;parent-&gt;child = NULL; if (pn-&gt;parent-&gt;parent != NULL) pn-&gt;parent-&gt;mark=true; pn-&gt;parent-&gt;degree -=1; pn-&gt;parent=NULL; &#125; if (pn-&gt;left != pn)&#123; pn-&gt;left-&gt;right = pn-&gt;right; pn-&gt;right-&gt;left = pn-&gt;left; pn-&gt;left=pn; pn-&gt;right=pn; &#125; pn-&gt;mark=false; return pn; &#125;; void consolidate()&#123; using std::log; if(min == NULL) return; const float base = 2; const float arg = static_cast&lt;float&gt;(size); const int max=log(arg)/log(base) + 1; node **A=new node*[max]; for(int i=0; i!=max; ++i)&#123; A[i]=NULL; &#125; node *pn=min; int degree= pn-&gt;degree; while (pn != A[degree])&#123; if(A[degree] != NULL)&#123; //若遇到度数相同的结点，则将A中的该结点链接到迭代器结点上。 if (A[degree]-&gt;value &lt; pn-&gt;value)&#123; std::swap(A[degree],pn); &#125; if (pn-&gt;child == NULL)&#123; A[degree]=extract_node(A[degree]); pn-&gt;child = A[degree]; A[degree]-&gt;parent = pn; pn-&gt;degree +=1; &#125; else&#123; A[degree] = extract_node(A[degree]); insertToList(pn-&gt;child, A[degree]); &#125; A[degree]=NULL; &#125; else&#123; A[degree]=pn; pn=pn-&gt;right; &#125; degree= pn-&gt;degree; &#125;; min=NULL; for (int i= 0; i!= max; ++i)&#123; if (A[i] != NULL) if (min==NULL) min=A[i]; else if (A[i]-&gt;value &lt; min-&gt; value) min=A[i]; &#125; delete A; &#125; void cascading_cut(node *x) &#123; node* p = x-&gt;parent; if (p != NULL) &#123; if(p-&gt;mark == false) p-&gt;mark = true; else&#123; extract_node(x); insertToList(min, x); cascading_cut(p); &#125; &#125; &#125; node* min; int size;&#125;#endif]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>Fibonacci heaps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[载酒买花年少事，浑不似，旧心情]]></title>
    <url>%2Fessaies%2Flonely.html</url>
    <content type="text"><![CDATA[当我打开记事本想写点什么的时候，写一个怎样的题目却让我犯难。难在我并无什么特别的要求，标题党？我不需要夺人眼球。做点概括？我也并没有要具体写点什么东西。我想大概这篇短文并不需要一个标题。不过，鉴于这个世界有这么多长着脑袋却并没有什么用处的脑残们，我认为我的这篇短文也配拥有一个标题，尽管它或许并没有太大的用处。 好在我并不是太纠结的人。随意从桌头抽出一本书，然后随意翻开一页，从里面取一句，足矣。老实说，我不太喜欢宋词——长短句，浅唱低吟，听着好听，但更像是为诉苦叫春量身定做的，你若读这两种题材的词句，总能分外打动人心。不过，说来世界总是奇妙的，随便挑捡的这句话，却也能称了我的心情。 写这篇短文我打算了很久，迟迟不能动笔的原因在于，我每天在上班之前十五分钟的想法，被八个钟头的编程抹去。而晚上，有太多事情排不上号，而这甚至连事情都算不上。一天的大部分时间里，我大概和我面前的那台机器一般无二，但沉重的心情总在梦醒时分汹涌而来。我不是感情细腻的家伙，也尽管一再坚信自己能忍耐寂寞、孤独与不被承认。但却越来越发觉，这个世界存在着人类挣脱不掉的孤独，你安心忍耐也好，你拼命挣扎也罢，它总能抓住机会爆发。 会有这么一段日子，我们有太多想做的事情，却没有时间去做了。上半年为还这样告诫自己：“诸般烦恼，只因想的太多，做的太少。”一个背身的功夫，有太多的事情，不是不去做，而是你迟缓的脚步再难跟上时间的步伐。时间慢慢会教会人，或者说逼迫人做一些取舍，你只能叹息，还是叹息。时间也会做出一些决定，你或者接受，或者反抗了之后接受。 生活总会有许多意想不到的困难，我当然明白这一切，待再回头时不过是一抹轻笑，并不能算得了多大的难处。只是假如硬要在浮华的世界中寻找清静，却并不容易真的得到内心的安宁。 大概每个人都需要一个哑巴辛格当朋友，他总用睿智的眼神告诉你他能理解你所说，却从不言语。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[斐波那契堆(Fibonacci Heaps)]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E5%A0%86fibonacci-heaps.html</url>
    <content type="text"><![CDATA[概览斐波那契堆是由一组最小堆有序树组成，其中的每棵树都必须符合最小堆属性。简单点，斐波那契堆是由一组有点特别的树组成。除了两个与元素删除有关的操作（EXTRACT-MIN和DELETE）之外，它的其它操作都能在常数时间内完成。可以看下斐波那契堆和二叉堆的运行时间对比表： 结构说白点，斐波那契堆由一组有根树组成，不过这些有根树都得是二项堆。大致结构如下： 有一个min指针指向了这些树根中关键字最小的一个。 对于每一个结点来说，除了关键字之外，至少还得有left、right、parent、child四个指针、一个mark标记和一个degree计数，四个指针好说，分别用来指向左右兄弟、父亲和任意一个孩子。至于mark标记则是用来标识一个非根结点是否已经失去了一个孩子（这样的结点，不能在夺其子女了，可能要进行一些其它的特别操作），实际上涉及到mark的操作并不多。degree则是用来统计该结点有几个儿子。丰满起来的斐波那契堆就成了这样： 基本操作斐波那契堆包含MAKE-HEAP、INSERT、MINIMUM、EXTRACT-MIN、UNION、DECREASE-KEY、DELETE等几项基本操作。建堆、插入、合并、和获得关键字最小的结点这四个操作比想象的还要简单。建堆只需简单的初始化一下min指针和记录结点数目的成员n即可；插入操作则是直接将结点插入到根链表中，这相当于进行一个循环双向链表的插入操作；合并操作直接将两个斐波那契堆得根链表合二为一；获得最小关键字的结点，更不必说，直接返回min指针即可。因此，对于MAKE-HEAP、INSEST、MINIMUN、UNION这四个操作就不多费笔墨。主要关注一下EXTRACT-MIN和DECREAS-KEY两个操作，而一旦实现了这两个操作，DELETE的实现则变得轻而易举。 EXTRACT-MINEXTRACT-MIN除了要提取出最小关键字的结点之外，其实还要对斐波那契堆的结构进行整理。如果不进行整理的话，那么斐波那契堆就完全成了一个双向循环链表了。整理到什么程度？直到根链表中所有的结点的degree值都不同！很奇怪之处在于，算导上对于为什么以所有根结点的degree不同为指标，居然只字未提。不过就我观察，其原因可能在于，当根结点的degree都不同的时候，此时的斐波那契堆就成了一个二项堆或者近似二项堆。 EXTRACT-MIN可以分为三步走： 将min的所有孩子取出加入到根链表中去； 从根链表中移除min结点； 整理斐波那契堆并获得新的min指针； EXTRACT-MiN的伪码为： 1234567891011121314EXTRACT-MIN(H) z = H.min if z != NIL for each child of z add x to the root list of H x.p = NIL remove z from the root list of H if z == z.right H.min = NIL else H.min = z.right CONSOLIDATE(H) H.n = H.n - 1; return z 其中CONSOLIDATE函数正是用来整理斐波那契堆的，它创建一个数组A来暂存根结点，并在遍历根链表的过程中将根结点degree相同的树合并。 其伪码如下（其中，且，具体证明见书本）： 1234567891011121314151617181920212223242526272829CONSOLIDATE(H) let A[D(H.n)] be a new array for i = 0 to D(H.n) A[i] = NULL for each node w in the root list of H x = w d = x.degree while A[d] != NULL y = A[d] if x.key &gt; y.key exchange x with y HEAP-LINK (H, y, x) A[d] = NIL d = d + 1 A[d] = x H.min = NIL for i = 0 to D(H.n) if A[i] != NIL if H.min == NIL create a root list for H contaning just A[i] H.min = A[i] else insert A[i] into H's root list if A[i].key &lt; H.min.key H.min = A[i]HEAP-LINK(H, y, x) remove y from the root list of H make y a child of x, incrementing x.degree y.mark = false 看一个实例的演示图或许更加清楚明白： Decreasing a key将一个关键字变小，有两种情况发生，一种是这个关键字变小以后还是比它的父结点关键字大，这时候什么都不用做；但是如果关键字变小后比它的父结点关键字要小的话，这时候可以将这个结点所在的子树直接移植到根链表中去。但是不管不顾的乱移植，有可能带来各种怪异的树结构，典型的就是变成了一根棍子。于是，可以采取一种折中的方式，当一个非根结点失去第二个孩子的时候，也将被移植到根链表中。这可以保证根链表中的每棵树都是一个近似二项堆。伪码如下： 123456789101112131415161718192021DECREASE-KEY(H, x, k) if k &gt; x.key error "new key is greater than current key" x.key = k if y != NIL and x.key &lt; y.key CUT(H, x, y) CASCADING-CUT(H, y) if x.key &lt; h.min.key H.min = xCUT(H, x, y) remove x from the child list of y, decrementing y.degree add x to the root list of H x.p = NIL x.mark = falseCASCADING-CUT(H. y) z = y.p if z != NIL if y.mark == false y.mark = true else CUT(H, y, z) CASCADING-CUT(H, z) 删除操作则完全可以利用DECREASE-KEY配合EXTRACT-MIN两者完成，先将要删除结点的关键字减小为无穷小，则提取最小关键字的结点就可以达到目的。 总结总的来说，斐波那契堆可以在常数时间内进行进行插入、合并、减小关键字等操作，但删除搜索等操作并不是其擅长。斐波那契堆并没有太多需要时刻保持的属性，这使得对于插入、合并、减小关键字等操作变得轻而易举。但实际上它将很多的工作留在了提取最小元素时来完成，所以这个操作实现起来复杂，运行起来耗时。 斐波那契堆将一些事情集中起来在某些操作上来处理，这就产生了一些被优化的操作，所以斐波那契堆就变成了一个优点很鲜明的数据结构。尽管如此，但斐波那契堆对于工程实践来讲，可能太过于复杂了，算导上就说： From a practical point of view, however, the constant factors andprogramming complexity of Fibonacci heaps make them less desirable thanordinary binary(or k-ary) heaps for most applications, except for certainapplications that manage large amounts of data. 它说呢，鉴于斐波那契堆的复杂性和常数因子可能较大，除了某些管理大数据的应用，人们还宁愿用二叉堆。话说回来，它又说了，说斐波那契堆还是有蛮多理论研究价值的。 参考：introduction to algorithm –third edition]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>algorithm</tag>
        <tag>fibonacci heaps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 基础入门笔记(5)]]></title>
    <url>%2Fdevelop%2Fpython%2Fpython-%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B05.html</url>
    <content type="text"><![CDATA[Picklepython 支持一些常见模式的文件处理方式，通过read 、readline或 write 函数来读写文件，同时它还支持几种模式的读写方式，这些并没有什么特别的，略去不说。 不过python的文件处理还有一个非常有用的功能——Pickle。 Pickle是python标准库提供的一个模块，它能将任意对象存储到一个文件中， 并还能从这个文件中恢复这个对象，比如： 12345678910111213import picklefruitlist=['apple','mango','carrot']filename='file.ob'f=open(filename,'wb')#将对象 fruitlist 存储到文件file.ob中pickle.dump(fruitlist,f)f.close()del fruitlist#从文件中读取对象f=open(filename,'rb')storedlist = pickle.load(f)print(storedlist)f.close() 异常处理（Exceptions）python 中也采用try…catch 类似的语句来捕获错误。看一个例子： 12345678910try: text= input('Enter something --&gt; ')except EOFError: print('Why did you do an EOF on me?')except KeyboardInterrupt: print('You cancelled the operation.')else: print('You entered &#123;0&#125;'.format(text)) finally: print('This statement must be printed') 把有可能引发错误的语句放在 try 块中，except子句则用来处理有可能发生的错误和异常。 except子句可以处理单一的错误或异常，也可以是一组包括在圆括号内的错误/异常。 如果没有给出错误或异常的名称，它会处理所有的错误和异常。 如果一个错误或异常没有被处理，那么python 将会终止程序并打印出错误信息。 else 子句在没有错误或异常出现的情况下才会被执行。 finally子语句则保证不管是有无异常出现它都会执行。我不禁意淫，如果C++中的异常处理也有这样一个语句块就美妙了 ——把资源释放的代码放到这个语句块中间那是再好不过了。 可以用 raise 语句来抛出异常，如 raise EOFError。 raise 语句类似C++ 中的 throw 语句。同样能被raise的异常和错误必须是直接或间接继承自 Exception类。 后记a byte of python 是本不错的 python介绍书。对，是一本介绍书，而不是入门书。 够精简，也够易懂，你大可以花大半天一口气看完这本书，使你对python 有一个大致的了解。 看完这本书，python对不对你的胃口，应该就清楚了。这之后再慎重的决定要不要更深入的学习一下 python 。老实说，这本书我是认为不值得写什么笔记的，但它却让我完全喜欢上了python ，让我决定要深入学习一下它。但近来琐事缠身，是抽不出时间来系统的学习python 的。 至于何时能安排出比较系统的时间来学习 python？一两个月之后，又或许是半年之后，亦未可知。 于是才有了写点笔记的打算，留待真正开始学习python的时候能够快速的温习一下。 参考：a byte of python –v1.92(for python 3.0)]]></content>
      <categories>
        <category>A byte of python</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 基础入门笔记(4)]]></title>
    <url>%2Fdevelop%2Fpython%2Fpython-%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B04.html</url>
    <content type="text"><![CDATA[作为一门面向对象语言，类和对象是 python的一个重要的概念。关于什么是面向对象和什么是面向对象过程，这里不做赘言。面向对象基本思想上python 并没有和C++有太大异同，这里主要对一些语法和细节上的东西做一些记录。但 python 与 C++在对象的范围上有很大不同， python的对象定义更广义——python认为万物皆对象，即便类也是一个对象。 在 python中数据成员被称为字段(fields)，而函数成员被称为方法。依照我一贯的理解，数据成员用来描述对象的属性，而函数成员可以被看作对象的行为。 python中对象的字段既可以是其它类型的对象也可以是与自己相同类型的对象。这种对象的自包含看上去很奇怪，理论上这一点是无法实现的——如果一个A类型的对象包含了另一个A类型的对象，那么被A类型包含的那个对象也应该包含一个A类型的对象，这种包含关系将无止境。而python之所以支持，这不得不说 python的另一特性——在 python中变量实质上是一个对对象的引用，而不是对象本身。 下面定义了一个简单的类,之后的文字将围绕这个例子来展开。 12345678910111213class Person: population=0 #标记1 def __init__(self,name): self.name=name #标记2 Person.population +=1 def __del__(self): Person.population-=1 def sayHi(self): print("I'm",self.name) @staticmethod #标记3 def howMany(): print('The population is',Person.population) 类变量和实例变量Person类中标记1定义了一个类变量，所谓类变量是指这个变量是属于类的，等同于C++中类的静态数据成员。类变量的引用应通过类名进行,如Person.population . 实例变量指的是这个变量是属于实例的，如标记2所在行中的name。在类的成员函数中所有的类变量应通过类名引用，而所有的成员变量应通过self引用,否则将定义一个新的变量或引起引用错误。 __init__方法和__del__方法__init__方法用来对对象的初始化，一些初始化操作应该放在这个方法中。它与C++中的构造函数作用类似。__init__方法在实例化一个新对象被实例化时调用。另外实例化一个新对象时，实参列表是被传给__init__调用。如Person 类的对象创建应当是这样的： p=Person(‘Adoo’)——__init__除 self外只有一个参数。 __del__方法则在一个对象被删除时调用，因为垃圾收集器的原因这个方法的调用时机并不能被确定。如果想显式调用它，那么用一条del 语句删除相应的对象。 方法(Methods)python中成员函数的第一个参数是一个特殊的参数，它引用对象本身，一般将之命名为self 。这个self 其实完全相当于C++ 中的 this 指针。self在成员函数的调用时与C++中this一样不需要被显示赋值，编译器会自动将调用成员函数的对象作为第一个参数。如obj.func(arg)这样的调用实际上被转化为类似obj.func(object1,arg)的调用了。 howMany函数实际上是一个静态方法，它属于类的方法而不是属于对象的的方法，这好比C++中的静态函数。定义方式，可以注意标签3。这里howMany是没有参数的，但假如它有参数的话，它的第一个参数也不会被当作对象的引用，它没有self引用。一个静态方法的定义除了可以在函数之前加@staticmethod 标签，还可以通过这样的形式： 123def howMany(): print('The population is',Person.population)howMany=staticmethod(howMany) 需要注意的几点： 类中的所有成员默认是公有的，但是所有以双下划线开头命名的成员被认为是为私有成员。 关于继承，私有成员不会被继承。python支持单继承也支持多继承。在类名后面用一对圆括号将基类名括起来，表示该类是一个继承自基类的类。如果是多继承则将基类之间用逗号隔开。 还是关于继承，如果继承类没有定义自己的__init__方法，那么会继承基类的__init__方法，如果继承类定义了__init__方法，那么在继承类的__init__方法中基类的__init__方法并不会被自动调用，必须显示调用它，这是与C++不同的。 参考：a byte of python –v1.92(for python 3.0)]]></content>
      <categories>
        <category>A byte of python</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 基础入门笔记(3)——内建数据结构]]></title>
    <url>%2Fdevelop%2Fpython%2Fpython-%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B03.html</url>
    <content type="text"><![CDATA[Python 有四个内建的数据结构——list、tuple、dictionary、set。 列表（List）list 是一个可以在其中存储一系列项目的数据结构。list的项目之间需用逗号分开，并用一对中括号括将所有的项目括起来，以表明这是一个list 。下例用以展示 list 的一些基本操作： ```python #定义一个 list 对象 shoplist： shoplist= [&apos;mango&apos;,&apos;apple&apos;,&apos;bananaa&apos;] #获得一个 shoplist 的长度 print(&apos;Shoplist have&apos;,len(shoplist),&apos;items&apos;) #访问shoplist中的对象 print(&apos;The 3rd item in shoplist is&apos;,shoplist[2]) #往 shoplist 中插入对象 shoplist.append(&apos;pear&apos;) #从 shoplist 中删除一个项目 del shoplist[0]#对 shoplist 进行排序 shoplist.sort() #遍历整个shoplist中的项目 print(&apos;These items are :&apos;,end=&apos; &apos;) for item in shoplist : print(item,end=&apos; &apos;) 输出结果为： ```python Shoplist have 3 items The 3rd item in shoplist is bananaa These items are : apple bananaa pear 关于上面的代码有几点要注意的是: 可以往 shoplist 中加入任何类型的对象，也就是说，并不要求一个 list中的项目具有相同类型。你甚至可以往 shoplist 中插入一个list。 排序函数作用于本身，而不是返回一个副本，这与字符串类型是不同的，因为字符串不可修改。 print 函数的end关键字参数用来指定输入完成之后的输出，默认是换行符，上面的代码用空格符替代换行符。 元组(Tuple)Tuple 在用法与概念上与 list 没有多大差别，可以将 tuple 看做是一个只读版list。也就是说tuple一经定义便不能被修改——不能添加和删除对象，也不能修改tuple中的对象。 tuple中的项同样应该用逗号分开，并用圆括号将这些项目括起来以表是是一个tuple。这个圆括号是可选的，也就是说可以用以下两种方式定义一个tuple: ```python tuple1=&apos;apple&apos;,&apos;banana&apos; tuple2=(&apos;apple&apos;,&apos;banana&apos;) 不过省掉那对圆括号不见得是什么好的习惯。另外当tuple只有一个项时，第一项之后必须有一个逗号，该情况下应该这样定义mytuple=(&#39;apple&#39;,)。这似乎是一个古怪的约束，但是假如没有这个逗号，不带括号定义的tuple就变成了mytuple=&#39;apple&#39;这明显具有二义性。 字典(Dictionary)字典可以看做是一组键-值(key-value)对的集合。键必须是唯一的，而每一个键关联着一个值。key必须是一个不可变的对象(如：tuple、数值型、字符串)。还要注意的是，在字典中的键值对并没有以任何方式进行排序。 一个字典的定义应该照这样的格式d={key1 : value1, key2 : value2, key3:vlue3}。键和值之间用冒号分隔，而键值对之间用逗号相隔，再用大括号将所有的键值对括起来。一些基本操作如下： ```python #字典的定义 ab= { &apos;Swaroop&apos; : &apos;swaroop@swaroopch.com&apos;, &apos;Larry&apos; : &apos;larry@wall.org&apos;, &apos;Matsumoto&apos; : &apos;matz@ruby-lang.org&apos;, &apos;Spammer&apos; : &apos;spammer@hotmail.com&apos; } #通过键来获取值 print(&quot;Swaroop&apos;s address is&quot;,ab[&apos;Swaroop&apos;]) #删除一个键值对 del ab[&apos;Swaroop&apos;] #遍历字典 for name, address in ab.items() : print(&apos;contact {0} at {1}&apos;.format(name,address)) #往字典中增加一个键值对 ab[&apos;Adoo&apos;]=&apos;liuxiaodongxiao@hotmail.com&apos; #判断字典中是否存在某键,也可以用 if ab.has_key(&apos;Adoo&apos;) if &apos;Adoo&apos; in ab: print(&quot;Adoo&apos;s address is&quot;,ab[&apos;Adoo&apos;]) 输出的结果为： Swaroop&apos;s address is swaroop@swaroopch.com contact Matsumoto at matz@ruby-lang.org contact Larry at larry@wall.org contact Spammer at spammer@hotmail.com Adoo&apos;s address is liuxiaodongxiao@hotmail.com 序列(Sequences)上面介绍的三种内建数据结构都是序列，索引操作是序列的一个基本操作。通过下标操作可以直接访问序列中的对象。上面虽然已经演示了下标操作——队列和元组用数字下标，字典用关键字下标。 序列的下标是从0开始的，上面的例子中只使用了下标为正数的情况，其实下标还可以为负数，如-1,-2,-3…。负数下标表示的意义为反方向的位置，如shoplist[-1]返回的是shoplist的倒数第一个项目。 序列不但支持负数下标还支持双下标，这对双下标表示一个区间。如shoplist[0:3]返回的是一个hoplist中从下标为1到下标为3之前的子序列副本。注意这个区间是一对半闭半开的区间。这种操作被称作切片操作(slicing operation)。如果切片操作的第二个下标超出了序列的范围，那么切片操作会到序列的末尾终止。切片操作中的两个下标都有默认值，第一个的默认值为0，第二个的大小为序列的长度。 还可以给切片操作提供第三个参数，第三个参数代表切片操作的步长，它的默认值是1。步长代表了项与项之间的间距，比方name[0:10:3],返回的就是name中下标为0，3，6，9组成的子序列。 集合(set)集合是无序简单对象的聚集。当你只关注一个对象是否存在于聚集中，而不管它存在的顺序或在出现的次数时，则适宜用集合。基本功能：判断是否是集合的成员、一个集合是不是另一个集合的子集、获取两个集合的交集等等。实例： ```python #定义一个集合,要使用set函数 s=set([&apos;briza&apos;,&apos;russia&apos;,&apos;india&apos;]) #判断对象是否在集合中 if &apos;india&apos; in s: print(&quot;india is in ?&quot;,&apos;india&apos; in s)sc=s.copy()#往集合中添加对象 sc.add(&apos;china&apos;) #从集合中删除对象 sc.remove(&apos;russia&apos;) #求两个集合的交集，也可以使用 s.intersection(sc) print(s &amp; sc) 输出的结果： india is in ? True {&apos;briza&apos;, &apos;india&apos;} 参考：a byte of python –v1.92(for python 3.0)]]></content>
      <categories>
        <category>A byte of python</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>python</tag>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 基础入门笔记(2)——函数、模块和包]]></title>
    <url>%2Fdevelop%2Fpython%2Fpython-%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B02%E5%87%BD%E6%95%B0%E3%80%81%E6%A8%A1%E5%9D%97%E5%92%8C%E5%8C%85.html</url>
    <content type="text"><![CDATA[函数、模块和包对于代码的复用都有非常重要的意义，当然面向对象中的类其实在代码的复用性上也有举足轻重的地位。前天睡前看了《a byte of python》中关于函数、模块和包的这个部分，今天又查了查官网文档以及网上的其它一些资料，把一些疑惑给解决。现在写一下关于这部分的笔记，用以加强记忆同时以备后用。 函数python 中用关键字def来定义函数。一个完整的函数定义应该以关键字def开始后面紧跟着函数名和用括号括起来的形参列表，并以一个冒号作为该行的结尾，紧跟着则是函数的代码块。实例： 1234567def printMax(a , b): if a&gt;b: print(a,'is maximin') elif a==b: print(a,'is equal to',b) else: print(b,'is maximum') Python同样支持为参数提供一个默认值，函数在调用时有默认值的形参是可选的，也就是说这样的参数可以不用给它提供实参。这在很多情况下都非常有用，比方一个窗口的创建函数——拥有很多形参来设定窗口的属性，但通常创建一个窗口可能只有两三个属性需要特别设定，其它都可以用默认值。Python的默认参数与C++的默认参数我感觉是一样的。都要求提供默认值的形参处于形参队列的末尾，换句话说，提供默认值得形参之后不能有不提供默认值的形参。其原因在于在调用函数时，用实参对形参赋值一般都是按位置顺序进行的。 说到“实参对形参赋值一般是按位置顺序进行的(这样的参数叫做位置参数，译自positional arguments)”，则不能不提一提关键字参数（Keyword Aruguments）。所谓关键字参数是指，可以显示的按形参名赋值实参，而并非根据形参的位置顺序。比方printMax(b=5,a=10)。当然，这个例子并没有体现出关键字参数的价值，其价值在于可以明确指出参数的角色。比方有一个文件内容拷贝函数copyFile(to,from) ——将文件 from 中的内容拷贝到文件to中。使用类似的函数的时候，使用者必须记住参数的顺序，但如果支持关键字参数的话，则不必关心位置顺序，将正确的文件名赋值给正确的形参就OK。 python 中可变形参(VarArgs Parameters)的概念非常清晰，在一个函数之前加上*号或者**号就表示这个形参代表了个数不确定的参数，如 12345def sum(*numbers): result=0 for number in numbers : result+=number return resultprint( sum(1,2,3,4,5) ) 上面的代码将会输出：15。 函数sum的形参number之前有*号标记，表明number是一个可变形参，实际代表的参数数目由调用时传入的实参数目决定。原理很简单，一个可变形参，如numbers, 会将从它那一点开始的所有位置实参(positional arguments)收集为一个 numbers列表。形参之前用两个星号**标记，同样表示一个可变形参，只是双星号的可变形参是将将从它自己开始的位置实参都收集为一个字典(dictionary)。队列(list)和字典(dictionary)都是python提供的基本数据结构。有趣的一点是 python中的可变形参并不一定要放在形参队列的末尾，这就带来了一种副产品Keywords-only parameters，请看: 12345def sum(*numbers,desc): result=0 for number in numbers : result+=int(number) print(desc,result) 但上面的例子中的 desc形参只能以关键字参数的方式进行调用了。调用方法如下： 1234#正确的调用sum(1,2,3,4,5, desc='The sum of my salary is：')#错误的调用，实参'The sum of my salary is：'也会被收入numbers中sum(1,2,3,4,5,'The sum of my salary is：' 如果一个函数没有提供显示的返回语句，python 会隐式的提供一条返回语句return None 。None 是 python 中的一个特殊类型，表示没有任何东西。 模块python既支持python语言写的模块同时也支持多种其它语言写的模块。这儿只看最简单的python写的模块，而不管其它。一个扩展名为.py的文件其实就是一个python模块。模块能被其它程序导入并使用它的功能，例如下面对准库的使用： 1234#file: C:\Users\Adoo-\Desktop\using_sys.pyimport sysprint('The command line arguments are:')for i in sys.argv: print(i)print('\n\nThe PYTHONPATH is', sys.path) 输出结果： 123456The command line arguments are:C:\Users\Adoo-\Desktop\using_sys.pyThe PYTHONPATH is [&apos;C:\\Users\\Adoo-\\Desktop&apos;, &apos;C:\\Python32\\Lib\\idlelib&apos;, &apos;C:\\windows\\SYSTEM32\\python32.zip&apos;, &apos;C:\\Python32\\DLLs&apos;, &apos;C:\\Python32\\lib&apos;, &apos;C:\\Python32&apos;, &apos;C:\\Python32\\lib\\site-packages&apos;] 上例中用一条import语句来告诉python我们想使用sys模块。对于一个使用用python编写的模块而言，当python执行 import 语句时,python 解释器会从sys.path中列出的路径中查找，如果找到了就会执行模块中包含的语句，然后这个模块就可以用了。模块的初始化操作只会在第一次被导入时执行。模块被导入后就可以通过点操作符来使用模块中的函数或变量，如sys.argv或sys.path。 要注意，要使用一个模块，必须确保这个模块所在的路径包含在sys.path中。所以，要么将你的模块复制到sys.path列出的路径中的一个去，要么把你的模块路径加入到sys.path中。执行文件所在的当前路径会被自动添加到sys.path中。 form … import 语句：用 from sys import argv语句可以直接导入sys模块中的argv变量，而且只导入argv.此时sys中的argv可以直接使用，而不用通过sys.argv的方式引用。使用from sys import *语句可以导入sys中的所有公有的和非双下划线开头的名字，不过这肯定不是一种好的习惯——容易造成名字冲突，如C++中的using namespace 语句。 模块中内置一个__name__属性。如果一个模块是被import 的, 那么__name__的值通常为去除模块扩展名的文件名。如果模块式独立运行的(也就是说它是主模块)__name__的值将是’__main__&#39;。 导入一个模块相对来说比较费时，所以 Python提供了一种以.pyc为扩展名的按字节编译的文件.当模块被第一次导入时，如果python具有当前路径的写入权限，.pyc文件会被创建在与模块文件相同路径下。有.pyc文件将会非常有利，当下次从其它程序再导入这个模块时，会快得多。因为导入模块的一些必要处理已经做好了。另外.pyc文件也是平台无关的。 dir()函数返回包含指定模块中所有名字的队列（list），注意用 import 语句导入的名字也在其中。在不提供参数给dir()的情况下，将返回包含当前模块的所有名字的队列。dir()函数其实可以作用于任何对象。 可以用一个del 语句删除一个变量或者名字，被del删除的名字或变量，在之后的语句里将不可以被访问。 包包其实就是用文件夹将模块组织起来，不过文件夹下必须要一个__init__.py文件，只有文件夹下有一个名为__init__.py的文件，该文件夹才会被当作一个包看待。但__init__.py文件可以是空的。 可以用 from…import…语句来导入包中的相关模块。要注意的一点是，假如有一个名为package的包，那么from package import *语句并不会如你想象的导入包中所有模块。它只导入在__init__.py中__all__属性中所列出的模块。例如，当__init__.py中__all__的定义如下： 1__all__ = ['mould1','moudle2','moudle3'] 那么，from package import * 只会导入mould1、moudle2和moudle3三个模块。 参考：a byte of python –v1.92(for python 3.0) 以及pyhon.org关于python3.2的很小部分文档。以及这篇博客：http://pydoing.blogspot.com/2011/02/python-package.html]]></content>
      <categories>
        <category>A byte of python</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>python</tag>
        <tag>代码组织</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[都废]]></title>
    <url>%2Fessaies%2FTropic-of-Cancer.html</url>
    <content type="text"><![CDATA[《废都》，便是迷醉于欲望之中，却又无法抽身自救的那么一群人组成。即便是尼姑庵的慧明亦脱不出肉欲 、权欲的高墙。大概世道如此，现实并不是人们掉进了欲望的天坑，反而是，欲望便如已然合围的高墙，人生而就在墙内。不是陷入了，而是逃不出。 便如《废都》演变到最后，这些人或死了、又或走了。死了的人固然逃出了欲望的樊笼，走了的人却尚未完成自救。诚然、庄之蝶最终放弃了背负了的声名，好似看淡了一切，悄然踏上了驶往南方的火车。而实质却是截然相反的，他并没有逃脱那一切，因他没有做任何一丁点抗争，不过是走到了绝地后的另谋他路罢了。他与周敏最终坐上了同一辆离开西京的火车，离开西京并不是他们幡然醒悟了，而是他们都面临了同样的困境——在追逐欲望的过程中面临了难以挽回的局面。周敏费尽心机也没有保全他在杂志社的工作，而庄之蝶更是跌进了谷底，失去了一切。他们是在这样一种情况下离开的，无需割舍任何一点东西。所以他们今天或许离开了西京，但却保不准哪天要入了南京了。 庄之蝶外头有那么多女人，却又未必真得了爱情。庄之蝶身材矮小，其貌不扬，要说他的那些女人们三下两次的便都和他上了床是爱情，我是不信的。与其说，她们是爱上了庄之蝶，不如说她们爱上的是“大作家庄之蝶”。反过来看呢，庄之蝶也不过仅是爱上了这些年轻美妙的肉体。阿灿的自毁容貌或许叫庄之蝶内疚与感动了，却也止步于此。唐婉儿最终的处境或许也叫庄之蝶煎熬难受了，不过是因为庄之蝶还有一颗良善之心罢了。我想庄之蝶与唐婉儿、柳月、阿灿之间是并没有一场爱情的，顶多也只是有很多场偷情。 看罢《废都》，羡慕完庄之蝶的艳福之后、我又对他非常不耻。不耻周敏对他执师之礼，他却上了人家有实无名的老婆？不耻他间接害死了朋友龚靖元。不耻他亏待了赵京五… 我始终不能明白，庄之蝶是有一颗良善之心的，又为何总做出上述不耻之事?末了，我却明白了，世道如此啊。这威武圣朝，现世亿万民众，或达官显贵，或平民布衣，莫不在这万丈红尘中翻滚，莫不为利欲如此行事。便拿害死了龚靖元说事，乘龚靖元之危买得了他的收藏或许是不道义的。但你见同赵京五谋划这事的时候，赵京五有丝毫内疚？诓骗压价龚小乙的时候，赵京五有丝毫手软？赵京五不是魔头，实在是这种事情在这个时段在这个地方太过平常，所有局中人都为警觉到严重的后果而已。 庄之蝶是坏人吗？不！我想庄之蝶是个好人，这世道能有一副热肠、能有一颗良心已经是殊为不易。 临近文末，我仿佛听到了庄之蝶丈母娘的喋喋呓语：都废了、都废了、都废…]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python 基础入门笔记(1)]]></title>
    <url>%2Fdevelop%2Fpython%2Fpython-%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B01.html</url>
    <content type="text"><![CDATA[内建类型python 中提供的内建类型大概与C++中提供的相仿，却更简洁。 数值方面的内建类型有整型、浮点型、和复数类型三种。在C++中虽然也有复数类型，但却是由标准库提供的。另外，python中整数的表示就是整形，没有如C++中的长整型短整形之说。浮点数的表示也没有浮点型和双精度型的区分。 字符串则可以分为字符串(string)和原生字符串(raw string)两种类型。可以如同C++ 一般用一对双引号来指定一个字符串，如 “This is astring”。在python中单引号(‘)与双引号(“)拥有相同的功能——一对单引号也可以表示一个字符串，如&#39;This is a string&#39;。 对于一个多行的字符串，可以用转义字符来表示，例如&#39;This is the first line.\nThis is the second line.&#39;，但是python同时提供了一种更友好的方式，用三引号(‘’’或”””)来表示一个多行的字符串，如： 12345''' this is a multi-line string.this is the second line."what your name ?" I asked.he said "My name is ***"''' 上面介绍有单引号、双引号、三引号三种引号。当用其中一种来指定一个字符串时，可以在字符串中直接使用另外两种引号，例如上面的多行字符串中可以直接使用&quot;，而无需写成 /&quot;。这是因为字符串可以找到正确的结尾，而不会被提前截断。 字符串无需再赘言，原生字符串可以在字符串之前加上一个r或者R来表示，例如r&#39;\nThis is a raw string&#39;。原生字符串不会对字符串进行任何特殊处理，例如r&#39;\nThis is a raw string&#39;中的\n不会被转义处理，而是直接代表\和n两个字符。 python 没有char类型。 变量python的变量命名规则与C++类似。定义上却有很大不同，定义一个python变量，直接给它赋值就可以了，并不需要声明它的数据类型，变量的类型决定于初始化它的对象类型。C++11中的auto关键词有类似作用，不过实质上是不一样的。实例： 12345s=''' this is a multi-line string.this is the second line.'''print(s)i=5print(i) python中一切事物皆为对象，即便是内建类型也是对象，这是与C++不同的。 代码书写约定python隐式约定每一物理行表示一行语句，所以python中的一行语句写完不需以分号结束，虽然在语句末尾加上分号也无伤大雅，但画蛇添足的事多做无益。但是如果要将多行语句写在同一物理行，那么则必须用逗号分开。如果某行语句过长，想写在两行，则可以使用连接符\\。实例： 123456#将多条语句写在同一物理行i=5; print(i);i=i+1;print(i)#将一行语句写在多个物理行。s='this is a string. \\This continue the string'print(s) 当行中使用了圆括号、方括号或波形括号的时候，不需要用\\来连接多行,这种情况被称为隐式行连接。 缩进：每行开始的缩进在python中相当重要，python中并不用大括号或者begin、end类似的关键词来界定语句块，缩进才是它的标准。换言之，行首的缩进量决定了语句的分组，同一层级的语句必须要有相同的缩进量。python支持空格符和制表符来表示缩进，但确保只使用其中一种来表示缩进，千万不要混搭使用。 表达式python的一些操作符大体上与C++一致，下面罗列几种与C++有差异的操作符。 乘法运算*，对字符串也能进行乘法运算，如&#39;a&#39;*3 返回&#39;aaa&#39;. 求幂运算符**，x**y 表示求x的y此幂，例如2**3的返回值为8. 除法运算/，与C++不同,整数之间的除法会返回小数，如1/2返回小数0.5而不是0. floor division(地板除？)运算符// ，返回x//y结果中的整数部分。如6//5返回1. 按位异或操作符\^,如3\^2返回1，5\^3返回6。 按位反转操作符\~，一元运算。\~x返回-(x+1)，也就是说\~5的结果为-6. not运算符，一元运算，求逻辑非。 and运算符，求逻辑与，对应C++中&amp;&amp; or运算符，求逻辑或，对应C++中|| 运算符的与表达式的更多介绍: http://www.python.org/\~gbrandl/build/html/reference/expressions.html 运算符在表达式的优先级列表: http://www.python.org/\~gbrandl/build/html/reference/expressions.html ###控制流 python有一种分支结构语句——if语句。但不存在switch语句。两种循环结构语句——while和for语句，没有do …while语句。有点奇妙的是所有者三种语句都提供一个可选的else分支语句，没错不仅if语句有else分支，while与for也有else分支。 if语句中可以将一个嵌套的if…else…if…else语句合并成if…elif…else语句，后者可以很好的替代switch语句。if语句的实例： 12345678number=22guess=int(input("Enter a number:"))if guess==number: print("you guessed it")elif guess &lt; number : prinnt("no, it is a little higher than that")else: print("no it is a little lower than that") 实际上相当于： 123456789number = 22guess = int(input("Enter a number:"))if guess==number: print("you guessed it")else: if guess &lt; number : print("no, it is a little higher than that") else: print("no it is a little lower than that") 要注意两点： 判断表达式不需要括号; 每一个分支语句之前需要冒号。 python中循环结构的一个比较鲜明的特点就是多了一个else分支，这个else在循环完成后执行。 while循环的实例： 12345678910count=5flag=Truewhile flag: if count!=0: print("count: &#123;0&#125;".format(count)) count -=1 else: flag=Falseelse: print("The while loop is over.") for循环的实例： 1234for i in range(1,5): print("i:&#123;0&#125;".format(i))else: print("the for loop is over") 从语法上来讲，for与while给了我一些不同的感觉，虽然都是循环控制语句，但给人的感觉是while更趋向于条件控制的循环，而for则更倾向于迭代循环。 python中也有break与continue语句与C++中的没有区别。要注意的是如果循环是以break语句跳出的话，那么else分支也会被跳过。 注：这篇笔记我主要重点记录一些 python在语法上与C++的一些异同点，以及我认为自己需要留意的地方，所以他仅仅是一篇笔记。 参考：a byte of python –v1.92(for python 3.0) 以及pyhon.org关于python3.2的很小部分文档。]]></content>
      <categories>
        <category>A byte of python</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[B-树的C++实现]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2Fb-%E6%A0%91%E7%9A%84c%E5%AE%9E%E7%8E%B0.html</url>
    <content type="text"><![CDATA[与之前实现哈希表、红黑树…这些数据结构和算法不同，B-trees的实现不再追求模仿STL，因此没有实现b-trees自己的迭代器。这些天温习之前的笔记的过程中意识到了一个问题，所有这些的数据结构毕竟只是作为练习之用，而不是出于作为以后使用的库的目的。故应当以逻辑清晰为第一要务。B-trees的实现是转变的一个开始，以后关于算法导论中的算法和数据结构的实现力求立足与算法本身而不是C++的淫技。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264//*******************************************//B-trees.cpp 2012/4/18 by Adoo//@brief: 本文件为b-trees的C++实现。//*******************************************#include&lt;iostream&gt;#include &lt;deque&gt;template&lt;typename Type&gt;class b_trees&#123;private: //结点的定义 struct node&#123; node()&#123; leaf=true; &#125; std::deque&lt;Type&gt; keys; std::deque&lt;node*&gt; children; bool leaf; &#125;;public: //创建一颗空树(构造函数) explicit b_trees(int deg=10):root(new node),degree(deg)&#123;&#125;; ~b_trees()&#123; delete_tree(root); &#125;; //查找操作 std::pair&lt;node*, int&gt; search(Type key) &#123; node *pnode=root; while(true)&#123; auto iter=pnode-&gt;keys.begin(); while (iter != pnode-&gt;keys.end() &amp;&amp; *iter &lt; key) ++iter; int i=iter- pnode-&gt;keys.begin(); if(iter != pnode-&gt;keys.end() &amp;&amp; key== *iter ) return std::make_pair(pnode,i); else&#123; if(pnode-&gt;leaf)&#123; return std::make_pair(nullptr,0); &#125; else pnode=pnode-&gt;children[i]; &#125; &#125; &#125; //插入操作； node* insert(Type key)&#123; node* pnode=root; if (pnode-&gt;keys.size() == 2*degree-1)&#123; root=new node; root-&gt;leaf=false; root-&gt;children.push_back(pnode); splite_child(root, 0); pnode=root; &#125; while(! pnode-&gt;leaf)&#123; int i=0; while (i != pnode-&gt;keys.size() &amp;&amp; pnode-&gt;keys[i] &lt; key) ++i; if (pnode-&gt;children[i]-&gt;keys.size() == 2*degree-1) &#123; splite_child(pnode,i); if(pnode-&gt;keys[i] &lt; key) ++i; &#125; pnode=pnode-&gt;children[i]; &#125; auto iter=pnode-&gt;keys.begin(); while(iter != pnode-&gt;keys.end() &amp;&amp; key &gt; *iter) ++iter; pnode-&gt;keys.insert(iter, key); return pnode; &#125; // 删除操作 bool erase(Type key)&#123; node* pnode=root; int i=0; //step1 while( !pnode-&gt;leaf )&#123; auto iter=pnode-&gt;keys.begin(); while (iter != pnode-&gt;keys.end() &amp;&amp; *iter &lt; key) ++iter; i=iter- pnode-&gt;keys.begin(); if(iter != pnode-&gt;keys.end() &amp;&amp; *iter == key) break; else &#123; if(pnode-&gt;children[i]-&gt;keys.size() == degree-1) pnode=grow_keys(pnode, i); else pnode=pnode-&gt;children[i]; &#125; &#125;; //step2 if( !pnode-&gt; leaf)&#123; return inter_erase(pnode, i); &#125; //step3 else&#123; auto iter = pnode-&gt;keys.begin(); while (iter != pnode-&gt;keys.end() &amp;&amp; *iter &lt; key) ++iter; if(iter == pnode-&gt;keys.end() || *iter != key ) return false; else&#123; pnode-&gt;keys.erase(iter); return true; &#125; &#125; &#125;private: void splite_child(node* pnode, int i)&#123; //该函数分裂x的孩子中下标为i的孩子 node *x=pnode-&gt;children[i]; node* new_node=new node; new_node-&gt;leaf=x-&gt;leaf; new_node-&gt;keys.insert(new_node-&gt;keys.begin(), x-&gt;keys.begin()+degree, x-&gt;keys.end()); Type key=*(x-&gt;keys.begin()+degree-1); x-&gt;keys.erase(x-&gt;keys.begin()+degree-1, x-&gt;keys.end()); if(! x-&gt;leaf)&#123; new_node-&gt;children.insert(new_node-&gt;children.begin(), x-&gt;children.begin()+degree, x-&gt;children.end() ); x-&gt;children.erase( x-&gt;children.begin()+degree,x-&gt;children.end()); &#125; pnode-&gt;keys.insert(pnode-&gt;keys.begin()+i, key ); pnode-&gt;children.insert(pnode-&gt;children.begin()+i+1, new_node); &#125; node* grow_keys(node* pnode, int i)&#123; //*该函数假设pnode的下标为i的孩子仅有degree-1个关键字 //*函数执行后保证那个孩子至少有degree个关键字，并返回处理后的结点。 //如果有的话向左边相邻的兄弟借一个关键字。 if(i&gt;0 &amp;&amp; pnode-&gt;children[i-1]-&gt;keys.size() &gt; degree-1)&#123; Type tmp_key = pnode-&gt;children[i-1]-&gt;keys.back(); pnode-&gt;children[i-1]-&gt;keys.pop_back(); pnode-&gt;children[i]-&gt;keys.push_front(pnode-&gt;keys[i]); pnode-&gt;keys[i] = tmp_key; //设置好相关的孩子指针 if( ! pnode-&gt;children[i-1]-&gt;leaf)&#123; node *tmp_node= pnode-&gt;children[i-1]-&gt;children.back(); pnode-&gt;children[i-1]-&gt;children.pop_back(); pnode-&gt;children[i]-&gt;children.push_front(tmp_node); &#125; return pnode-&gt;children[i]; &#125; //如果左边兄弟没有，那么向右边相邻的兄弟借 else &#123; if(i&lt; pnode-&gt;keys.size () &amp;&amp; pnode-&gt;children[i+1]-&gt;keys.size() &gt; degree-1 ) &#123; Type tmp_key = pnode-&gt;children[i+1]-&gt;keys.front(); pnode-&gt;children[i+1]-&gt;keys.pop_front(); pnode-&gt;children[i]-&gt;keys.push_back(pnode-&gt;keys[i]); pnode-&gt;keys[i] = tmp_key; //设置好相关的孩子指针 if( ! pnode-&gt;children[i+1]-&gt;leaf)&#123; node *tmp_node= pnode-&gt;children[i+1]-&gt;children.front(); pnode-&gt;children[i+1]-&gt;children.pop_front(); pnode-&gt;children[i]-&gt;children.push_back(tmp_node); &#125; return pnode-&gt;children[i]; &#125; else&#123; //若是左右两个相邻兄弟都无关键字可借，那么要进行合并结点操作。 if(i!=0) return merge_node(pnode, i-1); else return merge_node(pnode, i); &#125; &#125; &#125; node* merge_node(node* pnode, int i)&#123; //该函数合并pnode-keys[i] 左右两边的的两个子节点。 //该函数不做任何验证，请保证两个要合并的结点的关键字数目确实是 degree-1 node* target=pnode-&gt;children[i]; target-&gt;keys.push_back(pnode-&gt;keys[i]); target-&gt;keys.insert( target-&gt;keys.end(), pnode-&gt;children[i+1]-&gt;keys.begin(), pnode-&gt;children[i+1]-&gt;keys.end()); if(! target-&gt;leaf)&#123; target-&gt;children.insert( target-&gt;children.end(), pnode-&gt;children[i+1]-&gt;children.begin(), pnode-&gt;children[i+1]-&gt;children.end()); &#125; delete pnode-&gt;children[i+1]; pnode-&gt;keys.erase(pnode-&gt;keys.begin()+i); pnode-&gt;children.erase(pnode-&gt;children.begin()+i+1); node* result=pnode-&gt;children[i]; if(pnode==root &amp;&amp; pnode-&gt;keys.size()==0) &#123; root=pnode-&gt;children[0]; delete pnode; result = root; &#125; return result; &#125; bool inter_erase(node* pnode, int i)&#123; if(pnode-&gt;leaf)&#123; pnode-&gt;keys.erase(pnode-&gt;keys.begin()+i); return true; &#125; else&#123; if( pnode-&gt;children[i]-&gt;keys.size() &gt; degree-1)&#123; //case1: 左孩子关键字富余的话递归下降到左孩子 pnode-&gt;keys[i]= pnode-&gt;children[i]-&gt;keys.back(); inter_erase( pnode-&gt;children[i], pnode-&gt;children[i]-&gt;keys.size()-1); &#125; else&#123; if( pnode-&gt;children[i+1]-&gt;keys.size() &gt; degree-1)&#123; //case1: 右孩子关键字富余的话递归下降到左孩子 pnode-&gt;keys[i]= pnode-&gt;children[i+1]-&gt;keys.front(); inter_erase(pnode-&gt;children[i+1], pnode-&gt;children[i+1]-&gt;keys.size()-1); &#125; else&#123;//case3: 左右孩子关键字都不富余，那么可以走合并的路子 pnode = merge_node(pnode, i); inter_erase(pnode, degree-1); &#125; &#125; &#125; &#125; void delete_tree(node *x)&#123; if(x-&gt;leaf)&#123; delete x; x=NULL; return; &#125; else&#123; for(auto iter= x-&gt;children.begin(); iter!= x-&gt;children.end(); ++iter) &#123; delete_tree(*iter); &#125; &#125; &#125;private: node* root; int degree;&#125;;]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>B-trees</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论——B-trees]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAb-trees.html</url>
    <content type="text"><![CDATA[B-trees(叫“B树”还是“B-树”？我还是用它的英文名吧)，是一种为磁盘或其它辅存设备而设计的平衡树。它与红黑树有些类似，但是在节省IO操作上比红黑树表现的更好。很多数据库系统会用B-trees或它的变形来存储信息。 B-trees的特点是，一个结点可以有n个关键字，这些关键字把一段数据划分成n+1段，对应n+1个孩子，如下图所示： B-trees的定义一棵 B-trees T具有如下属性(设其根结点为T.root): Every node x has the following fields: x.n, the number of keys currently stored in node x, the x.n keys themselves, \( x.key_1, x.key2, \dots, x.key{x.n}\)stored in nondecreasing order, so that\( x.key_i \leq x.key2 \leq \dots \leq x.key{x.n}\), x.leaf , a boolean value that is TRUE if x is a leaf and FALSEif x is an internal node. Each internal node x also contains x.n+1 pointers\( x.c_1, x.c2, \dots, x.c{x.n+1} \) to its children. Leafnodes have no children, so their \( c_i \) fields are undefined. The keys \( x.key_i\) separate the ranges of keys stored in eachsubtree: if \(k_i\) is any key stored in the subtree with root\(x.c_i\), then\( k_i \leq x.key_1 \leq x_2 \leq x.key2 \leq \dots\x.key{x.n} \leq k_{x.n + 1} \) All leaves have the same depth, which is the tree’s height h. There are lower and upper bounds on the number of keys a nodecan contain. These bounds can be expressed in terms of a fixedinteger t ≥ 2 called the minimum degree of the B-tree: Every node other than the root must have at least t - 1 keys.Every internal node other than the root thus has at least tchildren. If the tree is nonempty, the root must have at least onekey. Every node can contain at most 2t - 1 keys. Therefore, aninternal node can have at most 2t children. We say that a nodeis full if it contains exactly 2t - 1 keys. 创建一棵空B-trees12345B-TREE-CREATE(T) x = ALLOCATE-NODE() x.leaf = TRUE x.n = 0 T.root = x 搜索操作:搜索操作与二叉搜索树的搜索有点类似，两点不同之处在于：一是结点中可能有多个key，二是往下走的时候有可能有多个子路。这些不同只在于选路的时候多做点判断罢了。下面为伪码： 123456789B-TREE-SEARCH(x, k)i =1while i ≤ x.n and k &gt;x.keyi i = i + 1if i ≤ x.n and k == x.keyi return (x, i)if x.leaf return NILelse return B-TREE-SEARCH(x.ci , k) 插入操作参照二叉搜索树的插入操作，其实B-trees的整体插入思路也类似。但是要注意一点，如果要插入的目标结点已经满了(即关键字的数目为2t-1)，这个时候并不能直接插入，因为直接插入就会破坏B-trees的结点性质。解决之道为，将这个已经满了的结点以其第t个关键字为界一分为二，并把第t个关键字抽取出来插入到父结点相应位置。并不能等到确定了要插入的目的结点再决定分不分裂，而是在下降的过程中遇到满结点就应当分裂，这样就可以保证要分裂的时候父结点总不是满的。 分裂结点的伪码： 1234567891011121314151617B-TREE-SPLIT-CHILD(x, i) z = ALLOCATE-NODE() y=x.ci z.leaf = y.leaf z.n = t - 1 for j = 1 to t - 1 z.keyj = y.keyj+t if not y.leaf for j = 1 to t z.cj = y.cj+t y.n = t - 1 for j = x.n + 1 downto i + 1 x.cj+1 = x.cj x.ci+1 = z for j = x.n downto i x.keyj+1 = x.keyj x.keyi = y.keyt x.n = x.n + 1 插入结点的伪码： 1234567891011B-TREE-INSERT(T, k) r =T.root if r.n = 2t - 1 s = ALLOCATE-NODE() T.root=s s.leaf = FALSE s.n = 0 s.c1 = r B-TREE-SPLIT-CHILD(s, 1) B-TREE-INSERT-NONFULL(s, k) else B-TREE-INSERT-NONFULL(r, k) 在非满根结点插入关键字的伪码(供上面B-Tree-INSERT 使用的一个辅助函数)： 12345678910111213141516B-TREE-INSERT-NONFULL(x, k) i = x.n if x.leaf while i ≥ 1 and k &lt; x.keyi x.keyi+1 =x.keyi i = i - 1 x.keyi+1 = k x.n=x.n+1 else while i ≥ 1 and k &lt; x.keyi i =i - 1 i = i + 1 if x.ci .n == 2t - 1 B-TREE-SPLIT-CHILD(x, i) if k&gt; x.keyi i = i + 1 B-TREE-INSERT-NONFULL(x.ci , k) 删除操作删除操作要比插入操作更复杂一点，因为删除一个关键字的时候，这个关键字不但可以在叶子结点，也可以在内部结点。算法导论的叙述虽然很严密与细致,但却对解题思路的骨架并不突出。这一段笔记我试着抛开算导，完全按我自己的思路来组织，而不是被他牵着鼻子走。（稳妥起见，你应该同时参照原书）： 从B-trees中删除关键字key无非两种情况，从一个叶子结点中删除或是从一个非叶子结点中删除。我很难想到一种好的办法可以直接删除一个非叶子结点中的关键字，又维持B-trees的属性。转念一想，能否把从非叶子结点中删除转化为从一个叶子结点中删除呢？当然能的，既然是一棵树，如果我们把问题从其所在的结点转移到其子结点，那么问题最终总能转移到叶子结点上。在具体考虑如何把从非叶子结点中删除关键字转化为从叶子结点中删除关键字之前，我们先要论证一下从叶子结点中删除一个关键字是否足够简单。如果从叶子结点中删除一个关键字比从非叶子结点中删除一个关键字更加复杂，那么就得不偿失了。 从叶子结点中删除一个关键字也可以分为两种情况: 该叶子结点中的关键字的数目大于t-1,此时可以直接进行删除; 叶子结点中的关键字数目恰巧等于t-1,这时直接删除会破坏B-trees的属性，而且破坏之后再进行修正也看得出来不是容易事。 到这里我们遇到了窘境，如果叶子结点中关键字的数目等于t-1,那么从中删除一个关键字很复杂，那么如果我们避免这种情况出现呢？便如同进行插入操作时有意的为分裂结点的操作，避免出现其父结点是满的情况一样。到此为止，我们有了初步的算法模型骨架，分为三步： 定位要删除的关键字所在的结点; 将删除问题下降到叶子结点; 从叶子结点直接删除关键字。 再完善其具体细节就可以得到以下算法模型： 由根结点出发定位被删除关键字所在的结点，在整个下降过程中，应保证每一次下降的目的结点的关键字的数目至少为t(保证下降到叶子的时候关键字的数目大于t-1)。如果下降过程中遇到关键字的数目为t-1的目的结点x，那么可以具体如下做： 如果x有一个相邻的兄弟y且其关键字的数目大于t-1，，那么可以从父结点下降一个合适的关键字给ｘ，并从y上升一个关键字给父结点，并妥善设置好相关孩子指针。 如果x的两个相邻的兄弟关键字的的数目都为t-1，那么将x与其任意一相邻的兄弟合并，并从父结点下降相关关键字到合并的结点中间。 如果key所在的结点是内部结点，设该结点为x，那么将问题下降到其子一级并保证第1点，递归处理其子一级。具体做法： 若key的前驱所在结点的最少有t个关键字，那么可用其前驱替换掉key，问题就从删除key转变为删除key的前驱，并且下降了一级。 若key的后继所在的结点最少有t个关键字,那么同体可以用key的后继替换key，问题得到转换并下降一级。 如果key的前驱和后继所在的结点关键字数目都为t-1,那么令x合并这任意两个相邻的结点之一，并将key降下来，作为中间关键字，问题也得到下降。 如果是叶子，直接删除。 参考：introduction to algorithm –third edition]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>B-trees</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论——平摊分析]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E5%B9%B3%E6%91%8A%E5%88%86%E6%9E%90.html</url>
    <content type="text"><![CDATA[平摊分析(Amortized Analysis)将数据结构的不同操作放到一起来考虑，而不是仅对某种操作的单一考虑。在平摊分析中，不会涉及概率问题。平摊分析可以用来证明，在一系列操作中，即使某个操作代价很大，但平均代价仍是很小的。本文记录三种平摊分析最常用的技术。 聚集分析(Aggregate analysis)在聚集分析中，要证明n个操作(可以是不同种类的操作)构成的操作序列在最坏情况下用时T (n),因此每个操作的平均时间为T(n)/n，在平摊分析中，平均代价被指派为平摊代价。看下面一个栈操作的实例。 对于栈操作，PUSH，POP的时间复杂度都是O(1)。我们给栈添加一种新的操作——MULTIPOP(S,k)，如果栈中对象足够，它会出栈k个对象，否则弹出栈中全部对象。这个操作的复杂度为O(n)。其伪码如下： 1234MULTIPOP(S, k) while not STACK-EMPTY(S) and k ≠ 0 do POP(S) k = k - 1 由PUSH, POP, 和 MULTIPOP构成的一个长度为n的序列操作作用在一个空栈上，最坏情况下的时间复杂度为多少？当然，你可以说是\(O(n^2)\)。的确没错，毕竟这一序列操作可由n个MULTIPOP组成，由此得出\(O(n)*n = O(n^2)\)。但我们还能将这个上限向下压。 MULTIPOP的复杂度为O(n)，但它真实的时间花费其实是由伪码中第2句决定的——MULTIPOP内部执行了多少次POP操作。当我们把上述问题综合考虑的时候，问题出现了戏剧性的转变。对于一个空栈来说，调用POP的操作最多等于PUSH的操作。可见上述的n个操作可以有更矮的上界O(n)。而三种操作的平摊代价为\(O(n) / n = O(1)\)。 记账方法(The accounting method)在记账方法中，给不同的操作分配不同的平摊代价。有些操作的平摊代价大于实际代价，就把多余的部分当作存款，供那些实际代价大于平摊代价的操作使用。需要保证的是序列操作的平均代价总和应该要不小于实际代价的总和。仍然用上面栈的例子，我们给栈的三种操作分派的平摊代价如下： PUSH 2, POP 0, MULTIPOP 0. 这是什么意思呢？假设我们把栈数据结构看做餐厅叠放一堆盘子，每次压盘子入栈需要付费1美元，弹出盘子也需要1美元。但是如果我放盘子的时候付费2美元，1美元用来支付入栈的费用，另1美元放在盘子上，告诉收钱的家伙，如果弹出盘子的时候，盘子上的那一美元就是付盘子弹出的费用。这样事情就简单了，任何出栈相关的花费都可以看为0，因为每一个盘子进栈的时候已经预付了足够它出栈的费用。所以POP和MULTIPOP都可以指派平摊代价为0. 所以由PUSH, POP, 和 MULTIPOP构成的一个长度为n的序列操作作用在一个空栈上的总平摊代价为O(n),而它的实际代价也是。 势能方法(he potential method)势能方法其实与记账方法相通，不同之处在于势能方法不是把账记在单个的对象上，而是记全记在数据结构上。当然按书上的说法来讲就是“势”，当某个操作支付的多时可以为这个数据结构积蓄势能，积蓄的势能则可以释放来支付后续的操作。 势能方法的工作流程如下. 对一个初始的数据结构\( D_0 \)执行n次操作。用\( D_i \)来表示执行第i次操作后的数据结构。函数\( \Phi(D_i) \)代表数据结构\(D_i\)拥有的势能。如果用\( c_i \)表示第i个操作的实际代价的话，那第i步操作的平摊代价就相当于实际代价加上由于这一步操作所增加的势能。所以第i步操作的平摊代价：。 n 步操作的总平摊代价则为： 如果使得\( \Phi(D_n) \geq \Phi(D_0) \)为真，那么我们就可以用总的平摊代价表示总的实际代价的一个上界。 再次用上面的栈例子作为实例，一开始时空栈，而且\( \Phi(D_0) = 0 \)(势能为0)。于是有\( \Phi(D_n) \geq \Phi(D_0) = 0 \)。因n的大小是不确定的，这个表达式要说明的是在一系列操作的过程中，势能可以有增有减，但绝不能为负数。 如果第i个操作是个PUSH操作，那么第i个操作带来的势差为:\( \Phi(Di) - \Phi(D{i-1} = (s + 1) - s = 1) \)。那么平摊代价PUSH操作的平摊代价就为： ![公式5][fromula5] 同理也可以求得POP操作的平摊代价为0. 如果第i步操作为MULTIPOP(S, k)。令k’= min(k,s)[^注1]，其中s表示栈中元素的个数。那么\( \Phi(Di) - \Phi(D{i-1} = -k’) \)。它的平摊代价就为： [^注1]: 在这儿k’= min(k,s)，直接表达的意思是不能令栈中的对象数目为负，而就势能方法来说，它表述了一点原则就是，这一次操作不能令栈的势能为负。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>Amortized Analysis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[赫夫曼编码]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E8%B5%AB%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81.html</url>
    <content type="text"><![CDATA[赫夫曼编码(huffman codes)是一种非常有用的数据压缩方法，通常能将数据压缩20%~90%。从具体问题出发，假设我们有一包含10000个字符的文件，这些字符仅由6个不同的字符组成，就设这6个字符分别为“abcdef”，下面的表给出了这6个字符在整个文件中的占比，和两种不同的编码方式。 ————– a b c d e f Frequency (in thousands) 45 13 12 10 9 5 Fixed-length codeword 000 001 010 011 100 101 Variable-length codeword 0 101 100 111 1101 1100 上例中固定长度的编码方式最少需要三位。那么整个文件的长度大小为300,000bits，而对于可变长度的编码方式其使用大小为： (45 1 + 13 3 + 12 3 + 16 3 + 9 4 + 5 4) · 1,000 = 224,000bits 使用第二种编码方式能比第一种方式节约大约25%的空间。上述变长编码的方式实际上是一种名为前缀编码的编码方式。 前缀编码如果某种编码方案中，没有一个编码会是其它编码的前缀，则称这种编码方案为前缀编码。有一条已证明的结论，任何由字符编码技术所获得的最佳压缩数据，也可以由前缀编码来获得。 前缀编码的编码很容易，只需将文件中的字符用对应的编码表示即可。解码也容易完成，因为其性质，可以直接从头至尾按编码与字符的对应关系翻译即可。 在解码过程中，为了方便和提高效率，可以用一颗二叉树来提供帮助。在这棵二叉树中，0表示往左走，1表示往右走。字符则被放置在树的叶子上。所以从根节点到叶子的路径表示了该字符的编码。这样一颗树对于解码时很有帮助的。下图是上面的例子中的两种编码对应的二叉树： 赫夫曼编码赫夫曼编码是指赫夫曼提供的一种构建最优前缀编码的方法。其方法是总选取权重最小的两个结点x和y合并成一个结点z,并用z代替它们，再从中选出两个权重最小的结点…如是反复。图解： 伪码:12345678910HUFFMAN(C) n = |C| Q = C for i = 1 to n - 1 allocate a new node z z.left = x = EXTRACT-MIN(Q) z.right = y = EXTRACT-MIN(Q) z.freq = x.freq + y.freq INSERT(Q, z) return EXTRACT-MIN(Q) // retrun the root of the tree 赫夫曼编码的正确性证明赫夫曼编码的正确性需证明贪心算法的两要素： 具有最优子结构 贪心选择性质 本来按照之前些笔记的思路该记下证明过程的。但今天就不写了，我免不了要吐槽几句。一直以来，我是很不喜欢也很少做笔记的，我更愿意的方式是在书旁边的空白处写点理解感想之类的，潦潦草草，信手涂鸦。大一大二的时候因为看技术方面的书籍多是从图书馆借来。特别是《C++ primer》这本书，被我借了两年，期间续借了又续借。刚开始看书的时候，是很期待从上面看到点什么前辈心得的，当然上面除了很少处的一两段短线之外，并没有什么其它前辈手迹。我有这种心理，因此遗憾之余也并没有介意在书上留下点东西。期间我涂涂画画写了不少东西，起初我不以为意，但后来还了书后，这本书恰巧又被我的同学ZWL借去。我从他手中偶然看到这本书，又随手翻了翻我以前写在其中的小记，个中有不少错误之处，有的是因为笔误，有的是因为刚开始看时理解的浅薄，这令我无比汗颜。我于是想最好还是不要在借来的书上乱写。到不是为了爱惜书籍，虽然，太多人很高尚的认为不要在图书馆中借来的书上写画，但我仍固执的以为，书被翻烂了写烂了才最能体现它的价值。我所顾忌的一是恐误了后来人，二是那些心得，虽然写了，却再难翻看了。 再到后来会偶尔用本子记下一点心得，但确实麻烦难了。因为我看书一直以来的习惯决定了，那些个笔记心得难成体系，太随意了，太散了。如果不是附在原文旁边，我自己翻看，也没觉得有多大用处。另外一点在于，我向来对于笔记本这些东西保存不善，指不定哪天丢了，或撕了——我喜欢用质量差的作业本写字，那些漂亮的笔记本反而让我写不习惯，因此我的笔记本和作业本还有草稿本完全是一路货色。 到看算法导论的时候，我开始萌生了要系统记一记笔记的想法。我原来写这个笔记的初衷在于，一是要囊括要点，二是能写一些书本之外的理解，更重要的是我想这些笔记能够简明易懂，使我以后不用频频翻看原书。不过发现自己的水平也就能勉强读懂这本书，原来的目的自然只达到了十之一二。 这本书的笔记我还是会将它写完，但有些无谓的地方将不会多浪费笔墨。 每个人都有自己的做事原则，我的原则是做一件事，要有一个明确的理由，放弃一件在做的事也要有一个明确的理由。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>huffman codes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贪心算法]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95.html</url>
    <content type="text"><![CDATA[与动态规划相同贪心算法通过做出一系列选择来构建出问题的最优解，不同的是贪心算法并不会全局考虑各种选择，它只做当前看起来最佳的选择。如君所见，贪心算法企图用每一步的最优解来构建出整个问题的最优解。这并不能保证总能构建出最优解，但它通常能做到。我们可以先看一个具体的问题——活动安排问题。 活动安排问题有一系列活动\( S = {a_1, a_2, \dots, a_n} \)，它们都要用到同一个舞台，而舞台一次只能举办一个活动。那么要如何安排才能举办最多的活动呢？ 假设活动\(a_i\)的开始时间用\(s_i\)表示，结束时间用\( f_i \)表示, 有\( 0 \leq s_i &lt; f_i &lt; \infty \). 也就是说\( a_i \)占用舞台的时间段为\( [s_i, f_i] \)。那么安排的活动之间必须满足一个条件，那就是各自的时间段之间没有重叠的部分。 一个具体的例子（将这些活动按结束时间排好了序）： i 1 2 3 4 5 6 7 8 9 10 11 \(s_i\) 1 3 0 5 3 5 6 8 8 2 12 \(f_i\) 4 5 6 7 9 9 10 11 12 14 16 对于这样一个问题，因为能够比较快速的发现其最优子结构，我们会很容易想到用动态规划来解决。——假设\(a_i\)是最优解中的一个元素，那么以\(a_i\)为界可以将问题分成为两个子问题，一个是活动结束时间在\(a_i\)的开始时间之前的所有活动，另一个则是活动开始时间在\(a_i\)结束时间之后的所有活动。可以证明最优解包含这两个子问题的最优解组成的，具体证明可见原书。 令\( S_{ij} \)代表活动开始时间在\(a_i\)结束之后而活动结束时间在\(aj\)开始之前的所有活动的集合，用\( c[i, j] \)来代表的\(S{ij}\)的最优解，那么我们可以获得递归公式： 如果用贪心算法的话，则不用考虑那么多种选择，只需考虑贪心选择——当前最佳的选择。在这个问题上，我们可以总是优先安排结束时间最早而又不与之前安排的任务有冲突的活动，这即是一种贪心选择。但最大的问题在于贪心选择是否是最佳选择？在这里，确实是的，你可以用算导中提到的“粘贴替代”的方法轻易的证明。 迭代与递归两种版本的伪码递归版： 123456RECURSIVE-ACTIVITY-SELECTOR(s, f, k, n) m = k + 1 while m &lt;= n and s[m] &lt; f[k] m = m + 1 if m &lt;= n return &#123;a&lt;sub&gt;m&lt;/sub&gt;&#125; ∪ RECURSIVE-ACTIVITY-SELECOR(s, f, m ,n) 迭代版： 123456789GREEDY-ACTIVITY-SELECTOR(s, f) n = s.lenght A = &#123;a&lt;sub&gt;i&lt;/sub&gt;&#125; k = 1 for m = 2 to n if s[s] &gt; = f[k] A = A ∪ &#123;a&lt;sub&gt;m&lt;/sub&gt;&#125; k = m return A C++的实现123456789101112131415161718192021template&lt;typename Container&gt; int greedy_activity_selector(Container input, Container&amp; result)&#123; //*input 应当是一个容器，每个元素为一个pair对， //*每个pair对包含一个活动的开始时间和结束时间 result.clear(); auto a=input.begin(); //a 存储贪心选择； result.push_back(*a); auto iter=a; ++iter; while(iter!=input.end()) &#123; if(iter-&gt;first &gt;= a-&gt;second) &#123; result.push_back(*iter); a=iter; &#125; ++iter; &#125; return result.size();&#125; 贪心算法的基本内容贪心算法并不能解决所有最优解问题。 贪心选择性质(greedy-choice property)和最优子结构(optimal substructure)是贪心算法的两个关键点。如果一个问题具备以上两种属性，那么就能设计出适合这个问题的贪心算法。 greedy-choice property: we can assemble a globally optimalsolution by making a locally optimal (greedy) choice. In other words,when we are considering which choice to make, we make the choice thatlooks best in the current problem, without considering results fromsubproblems. 贪心策略VS动态规划就动态规划来说，我们在每一步做出选择，但是这些选择往往会依赖与子问题的解。而贪心算法，总是做出当前看似最佳的选择，它可能会依赖于之前做过的选择，但绝不会依赖于尚未做出的选择或者子问题。一次动态规划通常采用自下而上的方式，不断解决小问题以供大问题使用，而贪心算法则采用自顶而下的方式不断缩小问题的规模。 一般来讲，对于一个有贪心策略解法的问题，也常常有一个更复杂的动态规划解法。也由于动态规划和贪心策略都利用了最优子结构这一性质，往往容易在贪心算法足以解决问题的情况小使用了动态规划。或者在需要动态规划解决的地方使用贪心策略，这需要我们自行甄别。 0-1背包和部分背包问题 The 0-1 knapsack problem is the following. A thief robbing astore finds n items; the ith item is worth \( v_i \) dollarsand weighs \(w_i\) pounds, where \(v_i\) and \(w_i\) are integers.He wants to take as valuable a load as possible, but he can carry atmost W pounds in his knapsack for some integer W. Which items shouldhe take? (This is called the 0-1 knapsack problem because each item musteither be taken or left behind; the thief cannot take a fractionalamount of an item or take an item more than once.) In the fractional knapsack problem, the setup is the same, butthe thief can take fractions of items, rather than having to make abinary (0-1) choice for each item. You can think of an item in the 0-1knapsack problem as being like a gold ingot, while an item in thefractional knapsack problem is more like gold dust. 两个背包问题都有最优子结构，但0-1背包不能用贪心策略来解决，而部分背包可以。对于部分背包来说，因为可以只拿部分，所以不用考虑背包会不会不能塞满，所以总是先拿剩余物品中每镑最值钱的东西会导致全局最优解。而0-1背包则不然，因为物体不能只拿部分，所以可能会导致背包不能完全被利用。下图为一个实例。 图解： The greedy strategy does not work for the 0-1 knapsack problem.(a) The thief must select a subset of the three items shown whoseweight must not exceed 50 pounds. (b) The optimal subset includesitems 2 and 3. Any solution with item 1 is suboptimal, even thoughitem 1 has the greatest value per pound. (c) For the fractionalknapsack problem, taking the items in order of greatest value perpound yields an optimal solution. 0-1背包不能用贪心策略来求解，但动态规划确实使用它的。 参考： introduction to algorithm –third edition]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>greedy algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最优二叉查找树]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E6%9C%80%E4%BC%98%E5%84%BF%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91.html</url>
    <content type="text"><![CDATA[假如我们要设计一个简单的程序将一段英文翻译成法语，那么就需要为每个英语单词找到对应的法语单词，简单的做法是在单词库中对每个单词进行遍历查找。更快一点的做法是，我们可以将单词库建成一颗平衡二叉搜索树——用英文单词做Key,对应的法语单词做附属信息。第二种方法，虽然可以保证每个单词的查询时间控制在O(lgn),不过却也有不合理之处。由于单词出现的频率有高有低，于是一些常用单词离根节点很远，而一些很生僻的单词却在根节点附近。可见用一颗平衡二叉搜索树来做这个问题并不是非常高效，在这儿就引出了另一种二叉查找树——最优二叉查找树。 问题定义假设给定一组有序的序列\( K = \)，在查找的过程中被查找的键是\(k_i\)的概率是\(p_i\)。同时因为有一些单词是K中不存在的,因此我们用n+1个虚拟键来表示这些不存在于K中的键，分别为\(d_0, d_1, d_2, \dots, d_n\)。其中\(d_0\)代表所有比\(k_1\)小的键,\(d_n\)表示 所有比\(k_n\)大的键,对于\(i = 1, 2, \dots, n-1 \),虚拟键\(d_i\)表示所有位于\( ki 和 k{i+1} \)之间的键。对于每一个\(d_i\),我们有一个概率\(q_i\)。 对于每次搜索，非成功，即失败，所以有： 因为对于每个关键字和虚拟键的概率都是已知的，所以我们可以求出一颗二叉搜索树的期望值： \(dpth_T\)代表结点在树种的深度。而我们的目标就是要建立起一颗搜索期望值最小的二叉树——也就是最优二叉搜索树。 动态规划的解法很显然，假如\(k_i\)是最优二叉搜索树的根节点，那么它的左子树和右子树必然是最优二叉搜索树。由此可见，这个问题拥有最优子结构。 要注意到，当一棵树成为另一棵树的子树的时候，由于每个结点的深度增加了1，所以搜索期望代价增加量为所有结点的概率总和： 所以对于一棵根结点为\(k_r\)包含有结点\(k_i, \dots, k_j\)的最优二叉搜索树，我们有： \[ e[i, j] = p_r + e(r[i, r-1] + w(i, r-1)) + (e[r+1, j] + w(r+1, j)).\] 注意到：\(w(i, j) = w(i, r-1) + p_r + w(r + 1, j)\)，所以： \[ e[i, j] = e[i, r - 1] + e[r + 1, j] + w(i, j) \]. 如此一来，我们可以建立起递归式了： \( e[i, j] \)记录了最优二叉查找树中的期望搜索代价，为了可以建立起二叉搜索树的结构，我们需要一个\( root[i, j] \)来记录根结点\( k_r \)的下标。 在下面的伪码中，用表\( e[i \dots n, 0 \dots n] \)来存储\( e[i, j] \)。第一维需要到\( n + 1 \)而不是\( n \)因为有子树只包含虚拟键\( d_n \)，我们需要计算和存储\( e[n+1, n] \).第二维需要从0开始是因为有子树只包含虚拟键\(d_0\),我们需要计算和存储\( e[1, 0] \). 此外，除了用表\( root[i, j] \)来记录根结点\(k_r\)的下标外，我们还需要一个表\( w[1 \dots n+1, 0 \dots n] \)，来记录\( w(i, j) \)以提高效率——这样就不必每次都从头计算\( w(i, j) \)了。对于\( 1 \leq i \leq n \). 且\(j \geq i\), 我们有： \[ w(i, j) = w(i, j - 1) + p_j + q_j \] 伪码：1234567891011121314151617OPTIMAL-BST(p, q, n) let e[1 .. n + 1, 0 .. n], w[1, n + 1, 0 .. n], and root[1..n, 1..n] be new tables for i = 1 to n + 1 e[i, i - 1] = q&lt;sub&gt;i-1&lt;/sub&gt; w[i, i - 1] = q&lt;sub&gt;i-1&lt;/sub&gt; for l = 1 to n for i = 1 to n - l + 1 j = i + l - 1 e[i, j] = ∞ w[i, j] = w[i, j -1] + p&lt;sub&gt;j&lt;/sub&gt; + q&lt;sup&gt;j&lt;/sup&gt; for r = i to j t = e[i, r - 1] + e[r + 1, j] + w[i, j] if t &lt; e[i, j] e[i, j] = t root[i, j] = r return e and root C++的实现12345678910111213141516171819202122232425262728293031323334353637383940414243#include&lt;iostream&gt;#include&lt;numeric&gt;#include"LSC.h"double optimal_bst(float *p , float* q, int n , int **root) &#123; double **e=dob_array&lt;double&gt;(n+2,n+1); double **w=dob_array&lt;double&gt;(n+2, n+1); for (int i=1; i != n+2; ++i) &#123; e[i][i-1]=q[i-1]; w[i][i-1]=q[i-1]; &#125; for(int l=1; l!=n+1 ; ++l)&#123; for(int i=1; i !=n+2-l; ++i)&#123; int j=i+l-1; e[i][j]=std::numeric_limits&lt;double&gt;::max(); w[i][j]=w[i][j-1]+p[j-1]+q[j]; for(int r=i; r != j+1; ++r)&#123; double t=e[i][r-1]+w[i][j]+e[r+1][j]; if(t&lt;e[i][j])&#123; e[i][j]=t; root[i-1][j-1]=r; &#125; &#125; &#125; &#125; double result= e[1][5]; delete_dob_array&lt;double&gt;(e,n+2); delete_dob_array&lt;double&gt;(w,n+2); return result;&#125;int main()&#123; float q[6]=&#123;0.05, 0.10, 0.05, 0.05, 0.05, 0.10&#125;; float p[5]=&#123;0.15, 0.10, 0.05, 0.10, 0.20 &#125;; const int size=5; int **root =dob_array&lt;int&gt; (size, size); std::cout&lt;&lt;optimal_bst(p,q, size,root)&lt;&lt;std::endl; std::cin.get(); delete_dob_array(root,size);&#125; 上面用到的两个函数dob_array和delete_dob_array是在前一篇笔记最长公共子序列中实现的。 此外，我们可以定义一个函数来输出一下树的结构，也就是课后练习15.5-2： 12345678910111213141516171819void print_optimal_bst(int **root, int i , int j)&#123; if(i&gt;j) return; else&#123; int r=root[i-1][j-1]; std::cout&lt;&lt;"k"&lt;&lt;r&lt;&lt;std::endl; std::cout&lt;&lt;"k"&lt;&lt;r&lt;&lt;"'s lefe child is "; if(r-1&lt;i) std::cout&lt;&lt;"d"&lt;&lt;r-1&lt;&lt;std::endl; else print_optimal_bst(root, i, r-1); std::cout&lt;&lt;"k"&lt;&lt;r&lt;&lt;"'s right child is "; if(r+1&gt;j) std::cout&lt;&lt;"d"&lt;&lt;r&lt;&lt;std::endl; else print_optimal_bst(root, r+1, j); &#125;&#125;]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最长单调子序列问题]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E6%9C%80%E9%95%BF%E5%8D%95%E8%B0%83%E5%AD%90%E5%BA%8F%E5%88%97%E9%97%AE%E9%A2%98.html</url>
    <content type="text"><![CDATA[Exercises 15.4-5 Give an \(O(n^2)\)-time algorithm to find the longestmonotonically increasing subsequence of a sequence of nnumbers。 Let X is the sequence of the sequence of n numbers. Let Y is the sorted number of the sequence of that n numbers. Find the LCS of the X and Y. 这种解法的核心在于问题的转化。求一个序列的最长单调子序列，先由其排序得一个有序的序列。于是问题可以转化为求原序列和有序序列的最长公共子序列。 一开始没想出来，网上搜到Rip’s Infernal Majesty的博客，茅塞顿开。 算法导论接下来的一题要求用O(nlg n)-求出最长子序列.。 Exercises 15.4-6: ⋆ Give an O(n lg n)-time algorithm to find the longestmonotonically increasing sub-sequence of a sequence of n numbers.(Hint: Observe that the last element of a candidate subsequence oflength i is at least as large as the last element of a candidatesubsequence of length i - 1. Maintain candidate subsequences bylinking them through the input sequence.) 我头脑愚笨，加上今天确实有些头昏，有答案都没看懂，哎，贴出Rip’s Infernal Majesty的答案，留待来日慢慢回味。 We can solve the longest increasing subsequence problem using onlyarrays and binary search. It processes the sequence elements in order,for each new X[i], maintaining a candidate sequence S by:• if X[i] is larger than the last element in S, add X[i] into S.• otherwise, find the smallest element that is larger than X[i], S[k]&lt; X[k] and X[i] ≤ S[k+1], replace S[k+1] with X[i].After finishing processing all n numbers, the length of S is is lengthof LIS of X. LIS(X, n) 1 L = 0 2 for *i* = 1, 2, … n 3 binary search for the largest positive *j* ≤ L such that X[M[*j*]] &lt; X[*i*] (or set *j* = 0 if no such value exists) 4 P[*i*] = M[*j*] 5 if *j* == L or X[*i*] &lt; X[M[j+1]] 6 M[*j*+1] = *i* 7 L = max(L, *j*+1) The algorithm stores values in two arrays:• M[j] — stores the position k of the smallest value X[k] suchthat there is an increasing subsequence of length j ending at X[k]on the range k ≤ i (note we have j ≤ k ≤ i here).• P[k] — stores the position of the predecessor of X[k] in thelongest increasing subsequence ending at X[k].L is the length of the longest increasing sequence. The actual longestsequence can be found by backtracking through the P array: the lastitem of the longest sequence is in X[M[L]], the second-to-last item isin X[P[M[L]]], etc. Thus, the sequence has the form…, X[P[P[M[L]]]], X[P[M[L]]], X[M[L]].Because the algorithm performs a single binary search per sequenceelement, its total time can be expressed using as O(n log n). 问题来自算法导论，参考博客：Rip’s Infernal Majesty]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>LIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最长公共子序列]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%AD%90%E5%BA%8F%E5%88%97.html</url>
    <content type="text"><![CDATA[概念序列的子序列，可以由从这个序列中去掉0个或多个元素而得来。所以子序列可以是由其父序列中不连续的元素组成，但相对顺序不能改变。公共子序列指的是,假如序列Z既是X的子序列，又是序列Y的子序列，那么称Z为X和Y的公共子序列。两个序列最长的公共子序列就被称之为最长公共子序列。最长公共子序列，又被称之为最长公共子串，译自英文名Longgest Common Subsequence，可以缩写为LCS。求最长公共子序列是一个很有用的问题，它可以用来分析两段序列的相似度，比方可以用来分析DNA串的相似度，也可以分析两段文字的相似度，来判断是否剽窃，等等。 举一个实例来说，假如有序列X和序列Y，那么他们的最长公共子序列为。 动态规划法求最长公共子序列求最长公共子序列最直接最暴力的一种方法当然是枚举出两个序列所有的子序列,然后从中找出所有的公共子序列，再选出所有公共子序列中最长的那个。不过这种粗暴的做法是很低效的，假如两个序列的长度分别为m和n,因为它们分别有\(2^m\)和\(2^n\)个子序列，那么这个算法的时间复杂度将是指数级别的\(O(2^{m+n})\)，对于长一些的序列这种方法是不实际的。撇开这种方法不谈，我们将关注另一种方法——用动态规划策略来求最长公共子路径问题。 第一步：描述问题的最优子结构之前一篇笔记有总结到，动态规划算法的运用有两个必要条件，一是问题包含最优子结构，二是有重叠子问题。第一步我们要做的便是证明LCS问题确实包含有最优子结构。定理15.1说明LCS包含有最优子结构，原书的证明已经清楚明了，下面引用原书的定理15.1证明： Theorem 15.1: (Optimal substructure of an LCS)Let \( X = \) and \( Y = &lt; y_1, y_2, \dots,y_n &gt; \) be sequences, and let \( Z = \) beany LCS of \( X and Y \). If \( x_m = y_n \), then \( z_k = x_m = yn \) and \( Z{k-1} \)is an LCS of \( X{m-1} and Y{n-1} \). If \( x_m \neq y_n \), then \( z_k \neq xm \ implies that \( Z \) is an LCS of \( X{m - 1} and Y \). If \(x_m \neq y_n \), then \( z_k \neq yn \) implies that \( Z \) is an LCS of \( X and Y{n -1}\). Proof (1) If \(z_k \neq x_m\), then we could append\( x_m = y_n \) to \( Z \) to obtain a common subsequence of\( X and Y \) of length \( k + 1\), contradicting the suppositionthat Z is a longest common subsequence of \( X and Y\). Thus, wemust have \( z_k = x_m = yn\).Now, the prefix \( Z{k-1} \) is alength-\( (k - 1) \) common subsequence of \(X{m -1} and Y{n-1}\).We wish to show that it is an LCS. Suppose for the purposeof contradiction that there is a common subsequence W of \(X{m-1}\)and \( Y{n -1}\) with length greater than \(k - 1\). Then, appending\(x_m = y_n \) to W produces a common subsequence of X and Ywhose length is greater than k, which is a contradiction. (2) If \(x_k \neq xm \), then Z is a common subsequence of\( X{m - 1} and Y \). If there were a common subsequence W of\( X_{m - 1} and Y \) with length greater than k, then W would alsobe a common subsequence of \( X_m and Y\), contradicting the assumptionthat Z is an LCS of X and Y. (3) The proof is symmetric to (2). 第二步：一个递归解由定理15.1可以看出，找序列X和序列Y的LCS,我们有可能需要找出X和\( Y{m - 1} \)的LCS，以及\( X{n-1}和Ym \)的LCS。而这两个子问题，都拥有一个共同的子子问题,便是求\( X{n-1} 和 Y_{m-1} \)的LCS。依次类推，还有很多其他的子问题会共有许多其他的子子问题。这就满足了动态规划的第二点条件，拥有重叠的子问题。 定义c[i, j]为\( X_i 和 Y_j \)的LCS长度，根据定理15.1可以得出下面的递归式： 第三步：计算LCS的长度利用第二步的递归式15.9，可以很容易写出计算LCS长度的递归求解程序，但这种方式并不比我们一开始提到的最简单粗暴的方法快（有可能还要慢），它同样是指数级的复杂度。 一二步已经验证了动态规划策略的可行性，于是我们将用动态规划来求解LCS的长度。下面的伪代码程序维护由两个表，表c和表b。表c用来记录c[i,j]的值，表b则用来方便LCS的构造，它会记录一些信息，指引我们在构件最优解的时候，如何选择最优子问题，下面是伪码： 123456789101112131415161718LCS-LENGTH(X, Y) m = length[X] n = length[Y] for i = 1 to m c[i, 0] = 0 for j = 0 to n c[0, j] = 0 for i = 1 to m for j = 1 to n if xi = yj c[i, j] = c[i - 1, j - 1] + 1 b[i, j] = "↖" else if c[i - 1, j] ≥ c[i, j - 1] c[i, j] = c[i - 1, j] b[i, j] = "↑" else c[i, j] = c[i, j - 1] b[i, j] = "←" return c and b 假设有序列X = 〈A, B, C, B, D, A, B〉和 Y = 〈B,D, C, A, B, A〉。那么通过执行LCS-LENGHT表c和表b存储的信息将如下： 说明：右图是将表b和表c的信息合二为一的显示，d第i行和第j列所指方块，记录了c[i,j]和b[i,j]中的信息。我们通过那些箭头来获得问题的最优子问题的路径，路径上的”↖”表示\( X_i = Y_i \),所以为LCS上的一个字母。 第四步：构建LCS通过表b我们可以很快的构建出\( X = &lt;x_1, x_2, \dots, x_m 和 Y = &gt; \)的LCS。可以从b[m,n]开始跟踪路径，当b[i,j]为”↖”时，输出当前字母。考虑到时从后往前追踪的，所以求出来的LCS将是反向的，所以在我们下面的递归伪码中，将先递归再输出。以下为伪码： 123456789PRINT-LCS(b, X, i, j) if i == 0 or j == 0 return if b[i, j] == "↖" PRINT-LCS(b, X, i - 1, j - 1) print xi else if b[i, j] == "↑" PRINT-LCS(b, X, i - 1, j) else PRINT-LCS(b, X, i, j - 1) C++ 的实现我先实现了一个简单的动态二维数组的分配代码，作为基础工程。 12345678910111213141516171819202122//create a dynamic doble arraytemplate&lt;typename Type&gt;Type** dob_array(int x, int y)&#123; Type **b=new Type*[x]; for(int i=0; i!=x; ++i) &#123; b[i]=new Type[y]; &#125; return b;&#125;//delete the dynamic double arraytemplate&lt;typename Type&gt;void delete_dob_array(Type** p_to_p, int x)&#123; for(int i=0; i!= x; ++i) &#123; delete [] p_to_p[i]; &#125; delete p_to_p;&#125; 下面为主体代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051int lsc_lenght(std::string str1, std::string str2, int** count, int**path)&#123; const int x=str1.size(); const int y=str2.size(); for(int i=1; i!=x; ++i) &#123; count[i][0]=0; &#125; for(int j=0; j!=y; ++j) &#123; count[0][j]=0; &#125; for(int i=1; i!=x+1; ++i) &#123; for(int j=1; j !=y+1; ++j) &#123; if(str1[i-1]==str2[j-1]) &#123; count[i][j]=count[i-1][j-1]+1; path[i][j]=0; &#125; else&#123; if(count[i-1][j] &gt;count[i][j-1]) &#123; count[i][j]=count[i-1][j]; path[i][j]=-1;&#125; else&#123; count[i][j]=count[i][j-1]; path[i][j]=1;&#125; &#125; &#125; &#125; return count[x][y];&#125;void print_lcs(int **path, std::string str, int x, int y)&#123; if(x==0 || y==0) return; switch(path[x][y]) &#123; case -1: print_lcs(path,str ,x-1,y);break; case 0:&#123; print_lcs(path,str,x-1,y-1); std::cout&lt;&lt;str[x-1]; &#125; break; case 1:print_lcs(path, str, x,y-1); break; default:return; &#125;&#125; 测试代码： 12345678910111213141516171819202122232425262728//一个产生随机字符串的函数。string get_random_str(int size)&#123; string base_str="aAbBcCdDeEfFgGhHiIjJkKlLmMnNoOpPqQrRsSTtUuVvWwXxYyZz"; string result; int i=size; while(i&gt;0)&#123; result+=base_str; i-=52; &#125; std::random_shuffle(result.begin(), result.end()); result.resize(size); return result;&#125;int main()&#123; const int size=800; //初始化测试数据； string str1=get_random_str(size); string str2=get_random_str(size); // 表的下标从1开始，所以要多分配1 int **path=dob_array&lt;int&gt;(size+1 , size+1); int **count=dob_array&lt;int&gt;(size+1 , size+1); lsc_lenght(str1, str2, count, path); print_lcs(path, str1,size,size); delete_dob_array(path, size); delete_dob_array(count,size); std::cin.get();&#125; 思考前面所述的求LCS的方式是自下而上的，但在这个问题中，并不一定每一个子问题都会有用到，特别是当两段序列的相似度很高的时候，则更加明显。这一点可以从上面的那个图中可以看出来。我于是想用自顶而下的动态规划方式，比一比两者的效率。自定而下的代码如下： 123456789101112131415161718192021222324252627282930313233//自定而下求最长公共子序列int memorized_lsc_len(const char* str1, const char* str2 , int str1_len, int str2_len, int** count, int**path)&#123; int result=0; if(str1_len==0 || str2_len==0) return 0; if(count[str1_len][str2_len]&gt;0) return count[str1_len][str2_len]; if( str1[str1_len-1] == str2 [str2_len-1]) &#123; result=memorized_lsc_len(str1,str2, str1_len-1, str2_len-1,count, path) ; count[str1_len][str2_len]=result+1; path[str1_len][str2_len]=0; &#125; else &#123; int result1=memorized_lsc_len(str1,str2, str1_len-1 , str2_len, count, path); int result2=memorized_lsc_len(str1, str2 , str1_len, str2_len- 1, count , path); if(result1&gt;result2) &#123; result=result1; path[str1_len][str2_len]=-1; &#125; else &#123; result=result2; path[str1_len][str2_len]=1; &#125; count[str1_len][str2_len]=result; &#125; return result;&#125; 我的测试方式是，两段代码分别对随机而得的两个个字符串进行操作。不过比较遗憾的是，我的机器内存不大，总共就2G,我大体得到了规模在1万以下的结论。规模在1万以上的时候，我的机器就并不呢功能胜任了，因为内存的使用已经达到了90%以上，每次得到的数据偏差较大，已经不准确。 当两个字符串长度在0~500的时候，自下而上的方式，速度要快的比较明显。然而当长度超过500的时候，自顶而下的方式便开始具有比较不错的优势，大约有25%左右。不过我的数据两只测到8000。另外很明显的一点是自顶而下的方式，消耗更多的内存。 我这样认为，当字符串较短的时候，因少计算的子问题带来的时间节省并不足以弥补递归所带来的开销，另外特别是有由于随机而得的短字符串，LCS长度也很小，能少计算的子问题并不多。当字符串长度增大时，这种少计算子问题的优势会有所体现，特别是当两个字符串相似度很高的时候。当然，当字符串长度增长的时候，所多用的内存也会增加。 要注意的一点是，测试的时候要把程序的栈空间调大一些，不然自顶而下的方式，可能很快就爆栈了。 参考： introduction to algorithm –third edition]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>dynamic programming</tag>
        <tag>LCS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划基础]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%9F%BA%E7%A1%80.html</url>
    <content type="text"><![CDATA[前一篇笔记有过一个动态编程的实例——rod cutting。这篇笔记主要了解动态规划的基础理论和弄清楚何时运用动态规划。对于何时来运用动态规划来寻得问题的解，取决于两个重要因素：最优子结构和重叠子问题。 最优子结构(Optimal substructure)如果一个问题的最优解包含了它子问题的最优解，那么这个问题具有最优子结构。当一个问题包含有最优子结构时，往往暗示着这个问题应该使用动态规划来解决（当然，也可能意味着贪心算法是一种好的的解决办法，这一点会在16章讨论到）。 可以依照一个共同的模式来发现最优子结构： You show that a solution to the problem consists of a makeing a choice. … You suppose that for a given porblem, you are given the choice that lead to an optimal solution. … Given this choice, you determine which subproblem ensue and how to best charatcerize the resulting space of subproblems. … You show that the solutions to the subproblems used within an optimal solutionsto the problem must themselves be optimal by using a “cut and paste” technique. … 用无权最短路径和无权最长路径两个例子，来演示这个模型。 假设有图 G=(V,E)，且u,v∈V. 无权最短路径：找出u到v的无权最短路径。假定u,v是不同点(相同就没什么好讨论了)。我们先假设w是u→v最短路径p上的一个点(第二步，做一个选择，并假设它导致最优解)，于是最短路径p可以分为两段子路径,子路径\(p_i\)为u→w;子路径\(p_2\)为w→v(第三步，描述子问题空间)。显然，\(p_1\)与\(p_2\)也必须是各自子路径的最短路径，不然最短路径\(p &lt; p_1 + p_2\)的长度,这与\(p = p_1 + p_2\)矛盾。于是第四点得证。也就是说这个问题有最优子结构。 无权最长路径：找出u到v的无权最长路径，当然这条路径不能包含环路。同样的办法先假设w是u→v最长路径p上的一个点，因此可以得出子路径\(p_1个p_2\)，有\(p = p_1 + p_2\)。那么这时\(p_1和p_2\)一定是u→w与w→v的最长子路径吗？不是的，我们看下图这种情况： u→w的最长路径为：u→v→s→w. w→v的最长路径为： w→u→v. 假如\(p_1和p_2\)是u→w与w→v的最长子路径，那么p=u→v→s→w→u→v。这个时候p显然不是最长路径，因为环路形成了。所以这个问题不包含最优子结构。 感觉上两个问题非常类似，但是为什么结果却截然相反呢？区别在于第一个问题的子问题是相互独立，而第二个问题的子问题之间却互有依赖关系——p1和p2如果被独立看待，就有可能产生环路。 重叠子问题(Overlapping subproblems)使用动态规划求解的第二个必要因素是子问题必须“很小”。也就是说递归算法不能总是产生新的子问题，动态规划求解的意义在于，它记录子问题的解，使得子问题可以只计算一遍，如果总是产生新的子问题，那么也就失去了使用动态规划的意义，因为记录下的子问题的解，不被再用到。 这儿可以比较一下动态规划和分治思想，两者虽然都是将问题分割为子问题，但又有很大的不同，分治思想的主要目的在于减小问题的规模，而动态规划则主要为了减少重复的计算。因此，动态规划适用于子问题重叠且独立的情况。 动态规划一般采用自下向上的模式，其实自顶而下也是一种选择，如rod cutting中就有这种解法。常规的自顶向下有很差的效率，加入“备忘录”记录之后，其实与自下而上复杂度是一样的。也就是说动态规划中采用自顶向下和自下而上的复杂度是一样的，但通常自下而上，用有更高的效率，因为它采用的是迭代的方法，而自顶而下用的则是递归。但是，当问题中的一些子问题是完全不用求解的时候，那么自顶而下可能是一种更好的选择。 动态规划算法的运行时间取决于两个因素的积：一是有多少个子问题，二则是每一个子问题我们有多少选择。 总结：动态规划算法的运用有两个必要条件，一是问题包含最优子结构，二是有重叠子问题。第一点保证求解的正确性，第二点则是代价问题。简而言之，我认为当问题含有独立重叠的子问题时，往往意味着该使用动态规划。子问题独立，应该可以保证存有最优子结构。 参考：算法导论第三版]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>dynamic programming</tag>
        <tag>DP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划笔记（1）——Rod cutting]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89rod-cutting.html</url>
    <content type="text"><![CDATA[动态规划（dynamic programming）,与“分治思想”有些相似，都是利用将问题分为子问题，并通过合并子问题的解来获得整个问题的解。于“分治”的不同之处在于，对于一个相同的子问题动态规划算法不会计算第二次，其实现原理是将每一个计算过的子问题的值保存在一个表中。 动态规划一般被用于解决“最优解”问题。编写动态规划算法可以按照以下四个步骤(引自原文)： Characterize the structure of an optimal solution. Recursively define the value of an optimal solution. Compute the value of an optimal solution, typically in a bottom-upfashion. Construct an optimal solution from computed information. 前三步可以求出最优解的值，如果仅是为了求出最优解的值，第四步可省略。第四步用来获得最优解，这种时候通常要在第三步时维持一些额外的数据信息。 Rod cutting简单的理论之后，看一个切棒子(Rod cutting的撇脚翻译)具体问题。问题如下：给你一根长n英尺的棒子和一份关于该棒子的价目表如下（其中 i = 1,2,3,…,n），请问如何将这根棒子卖出最高的价格，可以对棒子进行切割。 常规的解法假设最优的切割方法是切为 k 段, 1 &lt;= k &lt;= n, 切割的方式为： \[ n = i_1 + i_2 + /dots + i_k \]. 则其总价格为： \[ rn = p{i1} + p{i2} + /dots + p{i_k} \]. 不像杂乱的切法，我们可以想象这样一种切法，每一刀切下去之后将棒子分为左右两段，而下一刀总从右段下手，依此类推。那么： 根据上述公式，可以很容易的写出相应的代码： 1234567CUT-ROD(p, n) if n == 0 return 0 q = -∞ for i = 1 to n q = max(q, p[i] + CUT-ROD(p, n - i)) return q 这段代码提供两个参数。p是一个数组，它存储着一份价目表，而n则表示要切割的棒子的长度。当n不大时上述的算法或许简单管用，但是一旦n稍大，运行时间将会成几何倍数增加。为什么会这样慢？其一，是因为其复杂度达到\(O(2^n)\),另外则由于递归的次数太多了(多达\(2^{n-1}\)次)。 仔细观察不难发现，上述算法做了太多的重复工作，比方Cut-Rod(p,n),要递归调用Cut-Rod(p,n-i), 其中 i=1,2,…,n。但对于其中Cut-Rod(p,n)中递归调用的 Cut-Rod(p,n-1)又要重复计算 Cut-Rod(p,n-i-1)。 对于上述情况动态规划就能派上用场了。 用动态规划算法来切棒子动态规划的想法很简单，利用一个表来存储子问题的解。只有表中没有这个子问题的解的时候，才真正去求这个子问题的解并将该解保存到表中，否则直接用表中的解。 一般有自顶向下和自下而上两种记忆法来实现动态规划。 自顶而下： 1234567891011121314151617MEMOIZED-CUT-ROD(p, n) let r[0...n] be a new array for i = 0 to n r[i] = -∞ return MEMOIZED-CUT-ROD-AUX(p, n, r)MEMOIZED-CUT-ROD-AUX(p, n, r) if r[n] &gt;= 0 return r[n] if n == 0 q = 0 else q = -∞ for i = 1 to n q = max(q, p[i] + MEMOIZED-CUT-ROD-AUX(p, n - i, r)) r[n] = q return q 自上而下： BOTTOM-UP-CUT-ROD(p, n)12345678let r[0..n] be a new arrayr[0] = 0for j =1 to n q = -∞ for i = i to j q = max(q, p[i] + r[j -i]) r[j] = qreturn r[n] 上述的方法都只求出了最优的值，其解决方案并没有记录下来。也就是说对于切棒子这个问题来说，只求出了最大的总价格，至于怎么切才能卖出这样的价钱并没有解决。要想获得切法，则需要一个额外的数组来存取一些分割信息。 具体扩展后的伪码如下： 1234567891011EXTENDED-BOTTOM-UP-CUT-ROD(p, n) let r[0..n] and s[0..n] be a new arrays r[0] = 0 for j = 1 to n q = -∞ for i = 1 to j if q &lt; p[i] + r[j -i] q = p[i] + r[j-i] s[j] = i r[j] = q return r and s 上面代码中数组s用s[i]记录了长度为i的棒子的最优切法的第一部分长度，这一点让我颇受启发。利用数组s可以轻易输出最优解法： 12345PRINT-CUT-ROD-SOLUTION(p, n) (r, s) = EXTENDED-BOTTOM-UP-CUT-ROD(p, n) while n &gt; 0 print s[n] n = n -s[n]]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>dynamic programming</tag>
        <tag>rod cutting</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Qt Quick 笔记（2）——用户界面相关]]></title>
    <url>%2FQt%2Fabout-ui.html</url>
    <content type="text"><![CDATA[Nested ELements在QML中的 UI 元素是以树形结构组织的,因此“Elements are often nested”——也就是说，一个元素可以包含很多个其它元素。 一个例子： 123456789101112131415import QtQuick 1.1 Rectangle&#123; width: 400 ; height: 300 color:"gray" Rectangle&#123; x:50; y: 50 width:300; height: 200 color: "lightblue" Rectangle&#123; x:50 ; y: 50 width: 200 ; height: 100; color:"red" &#125; &#125;&#125; 上例中浅蓝色和红色的矩形都是“Nested Element”，通过右边的显示效果可以看出，每一个“Nested Element”设定的位置都是相对于父元素的，而不是绝对位置。 Graphical Elements三种要讨论的元素： Colors, gradients and images。通过这三种元素可以创建起具有吸引力的 UI 。 Colors:可以用三种方式来设置： 直接用一个颜色名字的字符串来表示：例如 “red”,”blue””,lightblue”… 直接用一个6位的十六进制字符串来表示：例如#ff00ff，六位中每两位代表三原色中的一种，其顺序为红绿蓝。 使用一个函数来进行设置。如：Qt.rgba(0, 0.75, 0 , 1)。其中四个参数的范围应该都在0到1之间。前三个参数表示三原色，后一个参数表示不透明度。 三种方法的实例： ```qml import QtQuick 1.1 Item{ width:150; height: 50 Rectangle{ width:50; height: 50 color: “red” } Rectangle{ x:50 ; y:0 width: 50 ; height:50; color: “#00ff00” } Rectangle{ x:100 ; y: 0 width: 50 ; height: 50; color:Qt.rgba(0,0,1,1) } } Images可以看下面一个关于图像的实例，这个实例将呈现一幅图片，并且在点击图片的时候会将图片放大两倍并以右下角为轴心旋转45度。 ```qml import QtQuick 1.1 Rectangle { width: 200 ; height: 200 color: &quot;gray&quot; Image{ anchors.centerIn: parent source: &quot;../捕获.PNG&quot; transformOrigin: Item.Center MouseArea{ anchors.fill: parent onClicked: { parent.scale=2 parent.rotation=45 } } } } Image的长宽由图像决定。其路径用source来设定，可以用绝对路径也可以使用相对路径，当然网路图片也是可以的。”../”表示父级目录。用scale来设定放大的倍数，用tansformOrigin 来设定旋转的轴心。rotation可以用来设定旋转的度数。 Gradient实例： ```qml import QtQuick 1.1 Rectangle { width: 200 ; height: 400 gradient: Gradient{ GradientStop{ position: 0.0 color: &quot;blue&quot; } GradientStop{ position: 1.0 color: &quot;black&quot; } } } 如上例所示，可以用一个gradient属性来设置渐变。用Gradient来作为其值。Gradient可以包含一个或更多的GradientStop 。每一个GradientStop包含一个position属性和一个color属性。position属性的值，只能从0到1。 设置gradient属性后，color属性将被覆盖掉。 官方推荐使用渐变的图片来代替gradient，因为gradient会占用大量的cpu，并且渐变的效果可能并没有你期望的那么生动。 文本qml中的文本既可以用来呈现文本，同时也能进行文本的输入。 用 Text 来简单呈现文本： ```qml import QtQuick 1.1 Rectangle { width: 200 ; height: 100 color: &quot;gray&quot; Text{ text: &quot;&lt;h1&gt;我本将心向明月，奈何明月照沟渠。&lt;/h1&gt;&quot; font.family: &quot;楷体&quot; color:&quot;white&quot; } } Text 支持简单的文本呈现，同时它也支持富文本的显示。如上例中我就用了&lt;h1&gt;…&lt;/h1&gt;这对标签。 用 TextInput 来接受文本的录入： ```qml import QtQuick 1.1 Rectangle{ width: 300; height: 200; color:&quot;black&quot; TextInput{ color: &quot;white&quot; width: 200; font.pixelSize: 16 text:&quot;举杯邀明月，对影成三人...&quot; } } 一个很简单的文本输入控件，没有任何的装饰。如果没有设置它的宽度的时候，其宽度会随着字串的长度而改变。 Anchors我们知道可以用x与y属性来确定元素相对于其父亲的位置。使用Anchors则是另外一个重要的布局手段，Anchors 主要用来定位和对齐元素。 位置示意图：(另外还有centerIn和fill) 一个实例：直接关联到其父 ```qml import QtQuick 1.1 Rectangle { width: 200 ; height: 150 color: &quot;lightblue&quot; Rectangle{ width: 50; height: 50 color:&quot;gray&quot; anchors.centerIn: parent } } 也可以关联到其父亲的Anchors,此时这样写:anchors.right: parent.right不需要(也不能)这样：anchors.right : parent.anchors.right Anchors 也可以用来对边缘留白,示意图如下： 用法则与上面的 right ,left 之类的如出一辙。 摘录一段关于 Anchors 的忠告，以及使用策略。 Hints and Tips – Anchors Anchors can only be used with parent and sibling items Anchors work on constraints some items need to have well-defined positions and sizes items without default sizes should be anchored to fixedorwell-defined items Anchors creates dependencies on geometries of other items creates an order in which geometries are calculated avoid creating circular dependencies e.g., parent!child!parent Margins are only used if the corresponding anchors are used e.g.,leftMarginneedsleftto be defined Strategies for Use – AnchorsIdentify item with different roles in the user interface: Fixed items make sure these have id properties defined unless these items can easily be referenced as parent items Items that dominate the user interface make sure these have id properties defined Items that react to size changes of the dominant items give these anchors that refer to the dominant or fixed items 参考资料：Qt Quick for C++ Developers]]></content>
      <categories>
        <category>QT</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>qml</tag>
        <tag>QT</tag>
        <tag>qt quick</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Qt Quick 笔记（1）：初识 Qt Quick]]></title>
    <url>%2Fdevelop%2Fcpp%2Fqt%2F%E5%88%9D%E8%AF%86-qt-quick.html</url>
    <content type="text"><![CDATA[废语开篇在大二的时候思索着学习一界面库，为此煞费脑经。其中有试过十来天的Qt学习,不过最后为WPF而沦陷，确实WPF界面与逻辑的分离让我很是向往。不过可惜的是WPF并不原生支持与C++的交互，以致我不得不学习一些C# 。又四处求医问药——获得native code与manage code交互的良方。这之间寻寻觅觅，虽然也算终于达成所愿——可以用C++与WPF 来完成一些小程序编写了。但是这注定是一种非主流的配置，主流与否，我虽然不在意。只是结果并不如我想的那般理想。用C++与WPF来开发并没有带来效率的提升以及逻辑的简化——这些成本都被转移到了他们之间的交互上，更大的成本其实在于学习的代价——C#、C++/cli 、P/invoke… 有意思的是似乎转了一圈，又要回到QT上来。为什么要回到QT? 没有太多理由——公司用的最主要的界面库就是Qt。当然这一切并未有让我有哪怕些须遗憾。我一直坚信，所有的弯路都有其价值。何况win8确切会支持C++与xaml的交互——我已经尝试了一下。但是对于相关的系统学习可能要推后一些了。而Qt会是接下来不短一段时间的主旋律了。不过可喜之处在于，Qt Quick 甚合我意。 What is Qt Quick ？看一下诺基亚的介绍： Qt Quick is a UI creation technology designed to enable developers and UIdesigners to work together to create animated, touch-enabled UIs and applications. 简而言之，Qt Quick将界面与逻辑很好的分离。更多… Qt Quick有以下组成部分： QML: 一种用来撰写界面的声明式语言，很简单，很像CSS. Qt Viewer: 用来加载qml文件。 Qt Declarative Module:一个 Qt 库中的新模块，用它可以很好的使得QML与 C++交互。 What is QML?qml是一种被设计为用来描述用户界面的声明式语言：包括用户界面的摸样和以及行为。在qml的世界中，UI元素被组织成树形结构，UI元素可以包含其许多子元素，但却只有一个父亲。 一个简单的例子： 12345import QtQuick 1.1Rectangle&#123; width: 200; height: 150 color: "lightblue"&#125; 上面的代码声明了一个矩形，并设定了它的长宽以及颜色，其效果图如下。 import可以用来导入相关模块，这儿要使用Qt quick的功能，自然要导入相关模块。后面跟的1.1是版本号。规定版本号的优势在于可以只导入对应的版本。因此程序中只能使用对应版本的功能。这样一来就可以使得程序不受旧版本或新版本的影响。在新版本发布后也保存了对旧版本的支持。 声明了一个Rectangle元素，紧接着的{}表示在其中的属性都属于描述Rectangle。可直接用属性的名字和值来设定属性：name: value。属性之间用换行符或分号来分隔。注释的方式与C++相同，可以用 “//”与“/* … */ ”两种形式。 QML中的元素（elements）可以分为可视化元素和不可见元素： 所有的可视化元素都继承自item, 它们一般都有关于位置和尺寸的属性。像Recatangle 、Text 、InputText… 不可见元素有states、transitions… 元素拥有一些属性，同时属性用以描述元素。当然，也可以对元素扩展一些自定义的属性。]]></content>
      <categories>
        <category>QT</category>
      </categories>
      <tags>
        <tag>qml</tag>
        <tag>QT</tag>
        <tag>qt quick</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[又到离别时]]></title>
    <url>%2Fessaies%2Fculture-eunuch.html</url>
    <content type="text"><![CDATA[捡起《北回归线》脱落的最后一页看完，不免有一些默然。这没有什么值得奇怪的地方 ，看过的很多书都曾有这样的感觉。但这一次却又有一点不一样，它更像是一种静默中 的歇斯底里。有一种不吐不快，吐了也不能畅快的无力。这他妈的发慌发堵的感觉。 老实说，看之前我已经做好了领略它到底有多淫秽，多龌龊的打算。毕竟它原是一本西 方的禁书，毕竟它原是一本在一群精力旺盛的兵痞间传阅的黄书，它理当应该很黄色， 应该能让这群士兵在无人的角落都成为单手“炮兵”。一直到看完最后一个字，我才大呼 受骗，这哪可能被当做黄书。它不但不淫秽，简直很纯洁。后来我又醒悟过来，既然是 中文版，必然在出版之前已经完成“净身”。 受儿时的各类古装局，特别是满清局毒害，使我有这样一个认识：向来执刀给人净身的 人需是太监。我不在意我这个认知是否正确，便如同我不关心出版《北回归线》中文版 的人民出版社是不是太监一般。让我在意的是，我在这其中得出的一个结论——有些东西 ，便如同男人裆下那玩意，即便它有多令人恶心、淫秽、邪恶…它依然是那么重要，缺之 不可。展现一副裸体不应该是什么禁忌，将一副男性裸体断根或女性裸体切除乳房才有 违人道。我猜测《北回归线》在中国便受到了如此酷刑。 《北回归线》是一具生疮流脓的裸体，出版者大概以为这样一个样子太过可怖，因此切 除了他狰狞的阳具，却不知如此一来更丑陋且显虚伪。 我用支离破碎的时间，看完了这本情节凌乱的书。即使刚刚看完，我却不能将之前后串 联起来。但我能确信的是这确实是一本好书。这并不是一句人云亦云的恭维话，也不是 为了掩盖自己见识浅薄智力低微而闪烁其词的含糊语。看这本书的过程中，便似有一般 小锤悬于心脏之上，它不时就会在你的心房或心室敲打一下，让你不禁颤抖。 我问自己要不要完整的反刍式的将这本书再看一遍？我想，算了吧。我深知，书中能体 味到的，远不啻如此。虽然我看到的不过皮毛，甚至不足十之一二，虽然这也确实是一 本值得一看的书。合上书本，我并不打算再看一遍了。一如书中所说： 他们所处的世界同每一个地方一样，发生的事情多半是屎尿垃圾，同任何一个垃圾桶 一样脏，只是他们能有幸盖上桶盖。 这个世界黑暗的角落太多，揭露丑陋、人性、黑暗的作品或作者更不胜枚举。但能点亮 希望光芒的呢？我明白我想要重读的不是展现黑暗的世界，不是冷漠的一瞥，不是感叹 绝望的挣扎。我想要反复阅读的是能道出希望之所在的作品。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[扩展数据结构]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E6%89%A9%E5%B1%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.html</url>
    <content type="text"><![CDATA[在一般的应用中，极少有可能要构建一种全新的数据结构，大部分情况下会使用一些已有的数据结构，或者已有的数据结构进行扩展，以使得其能支持特殊的功能。当然即便是扩展也需要做一些工作。 动态顺序统计(Dynamic order statistics)关于顺序统计这个问题，在中位数和顺序统计量介绍了在O(n)时间内获取一组数据中第i小的数据。在算导第十四章介绍了另外一种方式来求第i小的数据，它的算法复杂度为O(lgn)，但却要依赖于另外一种数据结构顺序统计树(order statistic tree)。 顺序统计树，是从红黑树扩展而来。相较于红黑树，一个顺序统计树的结点x，比一个红黑树的结点要多拥有一个字段size 。size为以x为根结点的子树所包含的所有结点的数目(也包括x本身)。一棵顺序统计树如下图所示： 不难得出一条结论： x.size=x.left.size+x.right.size+1 在一棵顺序统计树中，可以很轻便的求该树中第 i小的结点： 12345678OS-SELECT(x, i) r = x.left.size + i if i == r return x else if i &lt; r return OS-SELECT(x.left, i) else return OS-SELECT(x.right, i - r) 如上面的伪码所示，先求出 x 结点的排位r,因x不小于其左子树的所有结点，所以r = x.left.size + 1。 若r等于i自不必说。 若r大于i，说明所找的数，排在x之前，应从排在x之前的数中找第i小的数。即，从x的左子树中找第i小的数。 若r小于i，则应该在比r大的数中找第i-r小的数，即在x的右子树中找第i-r小的数。 同样也可以在O(lg n)的时间内求得指定结点的排位： 12345678OS-RANK(T, x) r = x.left.size + 1 y = x while y != T.root if y == y.p.right r = r+ y.p.left.size + 1 y = y.p return r 因为size记录的是以当前结点为根结点的子树所包含的所有结点的数目(也包括当前节点本身)，所以左侧伪码通过统计从x到根结点这条路径中本身为右孩子的结点本身以及它们的的左孩子的size来求得x的排位。 顺序统计树以红黑树为基础进行扩展,所以红黑树的原有操作我们都可以继承下来。但是它增加了一个字段size,对于红黑树的删除和插入操作，我们不得不进行一些轻微的升级，以使得size字段总能记录正确的信息。关于红黑树的插入操作，我们可以分为两部分： The first phase goes down the tree from the root, inserting the newnode as a child of an existing node. The second phase goes up thetree, changing colors and ultimately performing rotations to maintainthe red-black properties. 对于维持size字段： in the first phase, we simply increment x.size for each node x onthe path traversed from the root down toward the leaves. The new nodeadded gets a size of 1. The additional cost of maintaining thesize fields is O(lg n). In the second phase, the only structural changes to the underlyingred-black tree are caused by rotations, of which there are at mosttwo. Moreover, a rotation is a local operation: only two nodes havetheir size fields invalidated. The link around which the rotation isperformed is incident on these two nodes. Referring to the code forLEFT-ROTATE(T, x) in Section 13.2, we add the following lines: 12 y.*size* = x. *size* 13 x.*size* = x.left.*size* + *x.right.size* + 1 The change to RIGHT-ROTATE is symmetric. 近似的原理，我们可以用来在删除操作中维持size字段，此处略。 如何扩展数据结构一般我们可以以下面四条规则作为指引来扩展一个数据结构： Choosing an underlying data structure Determining additional information to be maintained in the underlyingdata structure. Verifying that the additional information can be maintained for the basic modifying operations on the underlying data structureDeveloping new operations. 一句很好的话: As with any prescriptive design method, you should not blindly followthe steps in the order given.]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>Order Statistic tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在没有父指针情况下的红黑树插入操作]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E5%9C%A8%E6%B2%A1%E6%9C%89%E7%88%B6%E6%8C%87%E9%92%88%E6%83%85%E5%86%B5%E4%B8%8B%E7%9A%84%E7%BA%A2%E9%BB%91%E6%A0%91%E6%8F%92%E5%85%A5%E6%93%8D%E4%BD%9C.html</url>
    <content type="text"><![CDATA[13.3-6Suggest how to implement RB-INSERT efﬁciently if the representation for red-black trees includes no storage for parent pointers. Solution:一个结点中没有父指针的红黑树与一个结点中有父指针的红黑树的差别在于， 前者不能轻易回溯至其父节点。而对于插入操作的实现，又需要多次回溯父节点。如果能解 决这个问题，问题将迎刃而解。对于插入操作的实现，我的方法是：用栈保存从根节点至插 入结点路径中所有的结点。当然在恢复红黑属性的过程中要注意栈的维护，具体细节，看下 面伪码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748RB-INSERT(T, z) y = T.nil x = T.root Stack S while x != T.nil y = x if z.key &lt; x.key x = x.left else x = x.right PUSH(S, x) z.p = y if y == T.nil T.toot = z else if z.key &lt; y.key y.left = z else y.right = z z.left = T.nil z.right = T.nil z.color = RED RB-INSERT-FIXUP(T, z, S)RB-INSERT-FIXUP(T, z, S) p = TOP(S) POP(S) p_p = TOP(S) while p.color == RED if p == p_p.left y = p_p.right if y.color == RED p.color = BLACK y.color = BLACK p.color = RED z = p p = p_p POP(S) p_p = TOP(S) else if z == p.right temp = z z = p p = temp LEFT-ROTATE(T, z) p.color = BLACK p_p.color = RED RIGHT-ROTATE(T, p_p)]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>reb black tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++实现红黑树，仿STL封装]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2Fc%E5%AE%9E%E7%8E%B0%E7%BA%A2%E9%BB%91%E6%A0%91%EF%BC%8C%E4%BB%BFstl%E5%B0%81%E8%A3%85.html</url>
    <content type="text"><![CDATA[在[Chapter 13 Red-Black trees(红黑树)][]这篇笔记中对红黑树的各种操作都有较详尽的伪码，相信使用C++来实现也并不是难事，我要做的是，在实现的基础上要进行一定的封装。当然风格嘛，自然参照STL，最终的结果就是要实现一个STL风格的红黑树模板。 在C++泛型编程中两个重要的概念即是容器和迭代器。我的目的则是要实现一个与STL中的其他容器类似，但是以红黑树为基础的容器RB_Tree。当然，实际上STL中的map、multimap、set、multiset其基础结构就是红黑树。在这儿、我主要尝试自己封装一个红黑树试试。 无论如何,从实现来讲，一个rb_node的类模板是需要的，不过它将作为 RB_Tree类中的一个嵌套类，因为RB_Tree容器的使用者并不需要知道，rb_node实现。rb_node的实现： 123456789101112template&lt;typename Type&gt;struct RB_Tree&lt;Type&gt;::rb_node&#123; Type _value; rb_node *_left; rb_node *_right; rb_node *_parent; RB_Color _color; rb_node() :_value(Type()),_left(NULL),_right(NULL),_parent(NULL),_color(red) &#123;&#125;; &#125;; 其次，要定义一个供RB_Tree容器使用的迭代器，为了拥有iterator_trait它将继承自std::iterator，当然完全可以自己通过宏定义来实现iterator_trait ，但毫无疑问继承的话可以写更少的代码.声明如下： 1234567891011121314151617template&lt;typename Type&gt;class RB_Tree&lt;Type&gt;::node_iterator: public std::iterator&lt;std::bidirectional_iterator_tag ,rb_node&gt;&#123;public: node_iterator(rb_node* n): _node(n)&#123;&#125;; Type&amp; operator* () const; rb_node* operator –&gt;()const; node_iterator operator++ (); node_iterator operator++(int); bool operator ==( node_iterator r_iter); bool operator !=( node_iterator r_iter); rb_node* pointer(); //…省略很多种运算符重载 private: rb_node* _node;&#125; 最后就是RB_Tree这个容器了类了，大体上是这样： 1234567891011121314151617template&lt;typename Type&gt;class RB_Tree&#123;private: struct rb_node; class node_iterator;public: typedef node_iterator iterator; typedef const node_iterator const_iterator; RB_Tree(); ~RB_Tree(); iterator begin(); iterator end(); iterator insert(Type value); iterator eraser(iterator iter);private: rb_node* _root;public: static rb_node* _nil; 具体的实现代码，你可以下载RB_Tree.hpp 当然还应该定义更多的接口，比方重载一个模板函数insert能够接受一对迭代器，将迭代器中间的数据插入到红黑树中，等等。 值得注意的是，该封装实现，是以学习以及练习为目的的，所以有很多本应有但确没有实现的接口。另一个原因则是这段时间太过忙碌。 如果将上面提到的迭代器类与之前在仿STL的二叉搜索树的C++实现中的迭代器比较，其实发现，它们提供的是一样的操作，所以完全可以将红黑树和二叉搜索树的结点类抽象出来，让迭代器类针对其抽象类实现，这样一来这一个迭代器模板类就会适用于几乎整个由二叉搜索树派生而来的数据结构了，将会大大提高代码的复用性。当然这个工作我没有做。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>red black trees</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chapter 13 Red-Black trees (红黑树)]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2Fchapter-13-red-black-trees-%E7%BA%A2%E9%BB%91%E6%A0%91.html</url>
    <content type="text"><![CDATA[之前的二叉搜索树提供了一系列算法复杂度为O(h)的基本操作：SEARCH,MINIMUM, MAXIMUM, INSERT, DELETE SUCCESSOR andPREDECESSOR。无疑，当树的高度比较小的时候这些操作有很好的效率，然而当二叉树总是“一条脚站立”时，树的高度就会很高，此时它效率并不会比链表快。红黑树即是一种从二叉搜索树上发展而来的“平衡”搜索树，它能保证在最坏情况下上述操作的复杂度为O(lgn) . 红黑树的属性( Properties of red-black trees)红黑树的每个结点需要在二叉搜索树的基础上多添加一个字段color,用以表示结点的颜色(红或黑)。一棵红黑树必须满足以下五点属性： Every node is either red or black. The root is black。 Every leaf (NIL) is black. If a node is red, then both its children are black. For each node, all paths from the node to descendant leavescontain the same number of black nodes. 当然还有一点最基本但不言自明的属性：红黑树首先是一棵搜索树，所以之前关于二叉搜索树的属性也同样适用于红黑树。“胁迫”红黑树满足于上述的五点属性，其目的完全在于得到一棵更加平衡的二叉树，也就是下面这条定理： Lemma 13.1 A red-black tree with n internal nodes has height at most 2 lg(n + 1). 要证明这条定理并不难，具体可以见 Introduction to algorithm –third edition第309页。 一棵红黑树的表示可以如图(a)；但是为了节省空间，我们可以设定一个哨兵来代替全部叶子，如图 (b)的结构；为了简练，我们可以不画出叶子以及根结点的父亲。 对于SEARCH, MINIMUM, MAXIMUM, SUCCESSOR 和 PREDECESSOR这几个不破坏树结构的操作，我们可以完全使用与实现二叉搜索树的这些操作的方法来实现这些操作，但对于INSERT, DELETE这两个会破坏树结构的操作，则需要有一些小小的变化——操作之后修复红黑属性。 旋转( Rotations )在红黑树中插入或删除指定节点后，事情并没有完全结束。因为红黑树的属性可能被破话，所以我们需要恢复红黑树的属性。恢复红黑树的属性，我们需要对树中的一些结点重新着色和修改一些指针结构。对于修改指针结构我们通过旋转来实现。 旋转分为左旋和右旋，左旋的具体操作为： When we do a left rotation on a node x, we assume that its rightchild y is not T.nil; x may be any node in the tree whose rightchild is not T.nil. The left rotation “pivots” around the link fromx to y. It makes y the new root of the subtree, with x asy‘s left child and y‘s left child as x‘s right child. 示意图： 左旋的伪代码： 12345678910111213LEFT-ROTATE(T, x) y = x.right //set y x.right = y.left //turn y's left subtree into x's right subtree if y.left != T.nil y.left.p = x y.p = x.p //link x's parent to y if x.p == t.nil T.root = y else if x == x.p.left x.p.left = y else x.p.right = y x.left = x //put x on y's left x.p = y 左旋操作在具体的红黑树中的演示： 插入操作红黑树的插入操作与二叉搜索树的插入操作非常相似，毕竟红黑树也是一种二叉搜索树。其伪代码为： 123456789101112131415161718192021RB-INSERT(T, z) y = T.nil x = T.root while x != T.nil y = x if z.key &lt; x.key x = x.left else x = x.right z.p = y if y == T.nil T.root = z else if z.key &lt; y.key y.left = z else y.right - z z.left = T.nil z.right = T.nil z.color = RED RB-INSERT-FIXUP(T, z) 但也有两处小小的不同： 将 z的左孩子与右孩子都设置为 T.NIL 并将 z 的颜色设置为红色(第14-16行)。 由于可能破坏红黑树的红黑属性，所以要进行红黑属性修复操作——调用RB-INSERT-FIXUP函数(第17行)。 在看RB-INSERT-FIXUP的伪代码之前，先考虑一下，当我们在红黑树中插入z结点并将其设置为红色后，红黑树的属性有哪些被破坏了。 属性1(Every node is either red or black. )显然不会被破坏。 属性2(The root is black。)则不确定，当z被插入一棵空树时，z将成为该空黑树的根结点，并且是红色的。 属性3(Every leaf (NIL) is black. )，同样也没有问题，T.NIL始终没有改变。 属性4(If a node is red, then both its children are black.)是又一个有可能被破坏的属性，如果结点z的父亲是红色，那么属性将被破坏了。 属性5（For each node, all paths from the node to descendant leaves contain the same number of black nodes.），也没有问题，因为插入的是一个红色结点，黑高度(Black-height)并不会改变。什么是黑高度？ We call the number of black nodes on any simple path from, but notincluding, a node x down to a leaf the black-height of the node. 所以，红黑树的属性只有在这两种情况下被破坏： T是一颗空树，所以属性2被破坏。 z的父亲是红色，因此属性4被破坏。 这时在来讨论RB-INSERT-FIXUP就更加具体了，RB-INSERT-FIXUP要做的工作就是修复上面两种情况下带来的属性破坏。对于第一种情况，可以很容易的修复，直接将根节点着色为黑就可以了。关键在于对第二种的修复工作。对于第二种情况的修复工作，可以归纳为三种情况： 情况1，z的叔叔是红色。 因为z的父亲和叔叔是红色，所以它的爷爷必然是黑色，其情况如下图所示： 此时我们只需将 z的父亲和叔叔着色为黑，并将z的爷爷着色为红，即可解决节点z和其父亲都为红色带来对属性4的破坏，且不会带来新的属性破坏。但问题并没有就此解决，因为z的麻烦虽然解决，但却转移到了它的爷爷身上，它的爷爷同样面临着可能与它的父亲同为红色的问题。不过没关系，让z的爷爷成为新的z吧，我们再以新z的来修复属性。好在即使问题一直存在，但却不断在向根结点移动，最终，我们可以简单的将根结点设置为黑就能解决了。 情况2，z的叔叔是黑色，且z是右孩子。 对于情况2，对z进行一次左旋，并将z的左孩子设置为新的z就可以快速的将情况2转化为情况3了。 情况3，z的叔叔是黑色，且z是左孩子。 对于情况3，我们对其爷爷进行一次旋转操作，并将其父亲着色为黑，其爷爷着色为红，此时在并不破坏其它属性的情况下，可以解决属性4冲突的问题。 情况2和情况3的示意图如下(当z 的父亲为左孩子的情况)： 一开始，我以为情况1也可以用类似情况3的方法来解决问题，实际上是不行的，在情况1下进行类似情况3的操作后，z的爷爷与它的右孩子将都是红色的。 有了上面的分析，现在要来实现RB-INSERT-FIXUP就比较容易了。伪代码，如下 123456789101112131415161718RB-INSERT-FIXUP(T, z) while z.p.color == RED if z.p == z.p.p.left y = z.p.p.right if y.color == RED z.p.color = BLACK //case 1 y.color = BLACK //case 1 z.p.p.color = RED //case 1 z = z.p.p //case 1 else if z == z.p.right //case 2 z = z.p //case 2 LEFT-ROTATE(T, z) //case 3 z.p.color = BLACK //case 3 z,p.p.color = RED //case 3 RIGHT-ROTATE(T, z.p.p) else(same as then clause whit "right" and "left" exchaged) 删除操作红黑树的删除操作是以二叉搜索树为基础构建的，当然它要复杂一点点，因为在删除完成之后，它还要额外维持红黑属性。 同样，首先要实现一个“移植函数”RB-TRANSPLANT： 123456789RB-TRANSPLANT(T, u, v) if u.p == T.nil T.root = v else if u == u.p.left u.p.left = v else u.p.right = v v.p = u.p RB-TRANSPLANT与二叉搜索树中的 TRANSPLANT基本上没有不同。细微分别之处在于： 使用 T.NIL 代替了TRANSPLANT中使用的NIL 在最后一行代码中，即使 v等于T.NiL也可以给 v.p赋值。 删除操作的代码较之二叉搜索树的删除操作代码，虽然主体相近，但差异也明显： 12345678910111213141516171819202122232425RB-DELETE(T, z) y = z y-original-color = y.color if z.left == T.nil z = z.right RB-TRANSLANT(T, z, z,right) else if z.right == T.nil x = z.left RB-TRANSLANT(t, z, z.left) else y = TREE-MINIMUM(z.right) y-original-color = y.color x = y.right if y.p == z x.p = y else RB-TRANPLANT(T, y, y.right) y.right = z.right y.right.p = y RB-TRANSPLANT(T, z, y) y.left = z.left y.left.p = y y.color = z.color if y-original-color == BLACK RB-DELETE-FIXUP(T, x) 多维持了一个结点y,可以看出，在z只有一个孩子时，y保存的是z的结点，而在 z有两个孩子时，y保存的是代替z 的结点。 另外由于 y的颜色可能改变，用 y-orignal-color保存了y原来的颜色。 还有一个x总是储存着y原来的位置。另外，在第13行，确保 x.p在x等于T.NIL 时也指向y。在前面z只有一个结点的情况中不需要类似13行的操作是因为，那种情况下，如果x等于T.NIL那么T就成为一棵空树了。 最后，根据y-orignal-color是否为空来决定是否进行对红黑树执行属性维护了。 为什么当y-orignal-color的颜色为红的时候不需要进行属性维护呢？原因在于：第一，y记录的是“真正”被删除的节点，在z只有一个节点的情况下，y直接记录z，这自不必说。当z有两个节点的时候，z的位置被y替代，且y继承了z的颜色，所以此时z的删除不会影响任何红黑属性，而真正会影响到红黑属性的是将y从原来的位置移除操作。第二，显然删除一个红色的结点，对整个树的红黑属性，不会有任何影响。 至此，最后的问题就是，怎么通过x来维护T的红黑属性了，也就是如何实现RB-DELETE-FIXUP 子函数的问题了。 想一想，如果我们在移除 y 的时候，可以将y的黑属性外加给x，那么，x的颜色要么是“红-黑”，要么就是“黑-黑”，假使真的可以这样的话，那么红黑树的任何属性就就都不会被破坏了。实际上当然不能如此，但却不妨碍我们这么想：当x的颜色是红色，那么代表它应该是“红-黑”，当x的颜色是黑色，那么代表它应该是“黑-黑”。维护红黑属性的问题就变成了如何在不破坏红黑树属性的情况下拆分x的颜色了。 当 x 为“红-黑”时，我们可以很简单的将x直接设置为黑色就可以了，因为丢掉一个红色，不会带来任何问题，而当x为“黑-黑”时，我们就要分情况讨论了。可以分为四种情况： 情况1：x的兄弟是红色。 因x的兄弟是红色，那么x的兄弟的两个儿子和x的父亲都是黑色。可以通过一次旋转(x是左儿子执行左旋，右儿子则要执行右旋)，并给一些结点改变颜色,来达到将情况1,转换到x 的兄弟是黑色的其它情况，也就是2、3、4三种情况中的一种。如下所示： 上图所示，在没有带来任何其它属性破坏的情况下，一次右旋操作之后，x的兄弟变成黑色了。 情况2：x的兄弟w是黑色，而且w的两个孩子都是黑色。 这种情况下，我们可以从x的身上拿下一个黑色，并且将x的兄弟改变为红色，然后给它们的父亲外加上一个黑色，x成功解除了一个黑色，但它的父亲又成了新的‘x’，继续颜色分离之旅。如下图(白色表示颜色未知)： 情况3：x的兄弟w是黑色，而且w的左孩子是红色,右孩子是黑色。 这种情况下，将w进行一次旋转，并进行相应颜色变换，变转换到了情况4。如下图： 情况4：x的兄弟w是黑色，而且w的右孩子是红色。 此时，只需对x的父亲着色为黑并进行一次旋转，使得w代替它原来父亲的位置并继承其颜色，即可将x身上的一个黑色拿去。且所有的问题都解决了。示意图如下： 此时再来看，RB-DELETE-FIXUP 的伪码就显得很清晰了： 12345678910111213141516171819202122232425RB-DELETE-FIXUP(T, x) while x != T.root and x.color == BLACK if x == x.p.left w = x.p.left if w.color == red w.color = BLACK //case 1 x.p.color = RED //case 1 LEFT-ROTATE(T, x.p) //case 1 w = x.p.right //case 1 if w.left.color == BLACK and w.right.color == BLACk w.color = RED x = x.p else if w.right.color == BLACK w.left.color = BLACK RIGHT-ROTATE(T, w) w = x.p.right w.color = x.p.color x.p.color = BLACK w.right.color = BLACK LEFT-ROTATE(T, x.p) x = T.root else (same as them clause with "right" and "left" exchaged) x.color = BLACK]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>red black trees</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Radix Tree 基数树]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2Fradix-tree-%E5%9F%BA%E6%95%B0%E6%A0%91.html</url>
    <content type="text"><![CDATA[###《算法导论》课后习题 12-2 解答。 Problems 12-2: Radix trees Given two strings \( a = a_0 a_1 \dots a_p and b = b_0 b_1 \dots b_q\),where each \( a_i \) and each \( b_j \) is in some ordered set ofcharacters, we say that string a is lexicographically less thanstring b if either there exists an integer j, where \( 0 \leq j \leq min(p, q) \),such that \( a_i = b_j \) for all \( i = 0, 1, \dots, j - 1\),and \(a_j &lt; b-j\)or \(p &lt; q\) and \(a_i = b_i \) for all \( i = 0, 1, \dots, p\). For example, if a and b are bit strings, then 10100 &lt; 10110 by rule 1(letting j = 3) and 10100 &lt; 101000 by rule 2. This is similar to theordering used in English-language dictionaries. The radix tree data structure shown in Figure 12.5 stores the bitstrings 1011, 10, 011, 100, and 0. When searching for a key\( a = a_0 a_1 \dots a_p \), we go left at a node of depth i if\( a_i = 0 \) and right if \( a_i = 1\). Let S be a set of distinctbinary strings whose lengths sum to n. Show how to use a radix tree tosort S lexicographically in \( \theta(n) \) time. For the example inFigure 12.5, the output of the sort should be the sequence 0, 011, 10,100, 1011. Figure 12.5: A radix tree storing thebit strings 1011, 10, 011, 100, and 0. Each node’s key can bedetermined by traversing the path from the root to that node. There isno need, therefore, to store the keys in the nodes; the keys are shownhere for illustrative purposes only. Nodes are heavily shaded if thekeys corresponding to them are not in the tree; such nodes are presentonly to establish a path to other nodes. Solution:很显然，对于上述的Radix tree进行排序，可以通过中序遍历先序遍历完成。只需在遍历过程中判断key是否存在即可，而上述中可以通过节点是否为白色来判断。 上面的问题虽然解决，但是我觉得这个基数树这个数据结构比较特别和有用，我思考它用在哪个方面比较有优势，却又不能总结出一二，只好求助于维基百科，特摘录一段如下(原文地址)： ApplicationsAs mentioned, radix trees are useful for constructing associativearrays with keys that can be expressed as strings. They findparticular application in the area of IP routing, where theability to contain large ranges of values with a few exceptions isparticularly suited to the hierarchical organization of IP addressesThey are also used for inverted indexes of text documents in information retrieval. 无奈的是，上面列举的几个应用方面我都不太熟悉。只好先标记，留待以后发掘吧。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Problem</tag>
        <tag>radix tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[非递归不用栈遍历搜索二叉树]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E9%9D%9E%E9%80%92%E5%BD%92%E4%B8%8D%E7%94%A8%E6%A0%88%E9%81%8D%E5%8E%86%E6%90%9C%E7%B4%A2%E4%BA%8C%E5%8F%89%E6%A0%91.html</url>
    <content type="text"><![CDATA[Exercises 12.1-3 Give a nonrecursive algorithm that performs an inorder tree walk.(Hint: There is an easy solution that uses a stack as an auxiliarydata structure and a more complicated but elegant solution that usesno stack but assumes that two pointers can be tested for equality.) Solutions:用非递归的方式来遍历二叉树，假如有一个辅助栈的话关键是要注意一下压栈的顺序，这儿主要在不使用辅助栈的情况下遍历搜索二叉树。以中序遍历为例，如果从根节点开始使用迭代的手法来遍历，那么对于迭代到任意一个结点来讲，都需要考虑的第一个问题：它的孩子被迭代的情况：只有左孩子被迭代？两个孩子都已被迭代？还是都未被迭代？根据不同的情况作出不同的判断。如此一来，情况就变的有点繁琐，在这儿可以做一点简化：直接选用迭代的真实开始点作为起点，也就是最左的叶子，或者说最小结点。这样做的好处是，对于迭代到的任意一个结点，我们只需考虑它的右子树是否已经被迭代，而无需考虑左子树，因为其左子树必然已经被迭代过。模型如下： 如果x不是由其右孩子回溯而至(说明其右子树还未被遍历)，那么： 输出x结点。 若x的右结点不为空，将x赋值为x右子树中的最小结点；否则，将x向根结点回溯。 如果x是由其右孩子回溯而至(说明，以x为根结点的子树已经遍历完成)，那么将x向根结点方向回溯。 用伪代码表示如下： 1234567891011121314iter_bst() x=min (x) x’=x; while x ≠ NIL if(x.right ≠ xc) x’=x print x if(x.right ≠ NIL) x=min(x.right) else x=x.p else x’=x x=x.p 实质上，因为对于BST的中序遍历来讲，我们可以直接从最小结点一直求后继，或从最大结点一直求前驱的方式来实现对搜索二叉树的遍历，我在[仿STL的二叉搜索树的C++实现][]中就是这么做的。且，其算法复杂度也是 O(n)。 另外，下面给出对应于上述伪代码的C++代码，当然，要配合仿STL的二叉搜索树的C++实现中的BST类模板才能通过编译。 12345678910111213141516171819202122template&lt;typename T&gt;void BST&lt;T&gt;::print() &#123; node* x=iterator(_root).min().pointer(); node* x_pre=x; while(x!=NULL)&#123; if(x-&gt;_right != x_pre) &#123; x_pre=x; std::cout&lt;&lt;x-&gt;_value&lt;&lt;std::endl; if(x-&gt;_right !=NULL) x=iterator(x-&gt;_right).min().pointer(); else x=x-&gt;_parent; &#125; else &#123; x_pre=x; x=x-&gt;_parent; &#125; &#125; &#125;]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>Exercises</tag>
        <tag>binary search tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[仿STL 的二叉搜索树的C++实现]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E4%BB%BFstl-%E7%9A%84%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E7%9A%84c%E5%AE%9E%E7%8E%B0.html</url>
    <content type="text"><![CDATA[看完导论的Chapter 12 binary search tree后，不忘用C++实现一下这个数据结构，学习算法的时候也锻炼下C++的编码能力。另则，若按照STL的风格来封装搜索二叉树，一是可以培养良好的编程风格，也能好好体会STL的设计思想。 模型：BST模板类中有两个嵌套模板类，一个为节点模板，一个为迭代器的模板。 编写的时候也订了三条原则： 效率优先 接口都通过迭代器操作，不以指针直接进行操作。 节省时间，毕竟是学习之作，并不是所有应该实现的接口我都实现，只实现一些基本的。 如果你看到下面声明的接口中有很多显而易见的不合理之处，比方 BST类居然没有接受一对迭代器的构造函数构造，也没有重载接受一对迭代器版本的insert函数,一个双向迭代器类重载了自增操作符，却没有重载自减操作符…，凡此种种，请不要惊讶以为此行的目的在于对数据结构的学习，以及学习STL的设计思想，而不在于做重复的工作，下面是关于仿STL的二叉搜索树的C++我实现了的部分的声明，如果你想看看实现的源码，请点击我 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//BST.hpp A data structure which be called binary search tree // 2011/12/17 By Adoo// homepage: http://www.roading.org#ifndef BST_HPP#define BST_HPP#include&lt;iterator&gt;// The binary search tree templatetemplate&lt;typename T&gt;class BST&#123;protected: struct node; class node_iterator;public: typedef node_iterator iterator; typedef const node_iterator const_iterator; BST(); iterator begin(); iterator end(); iterator find(T value); iterator insert(T value); template&lt;typename iter_type&gt; iterator insert(iter_type iter); void eraser(iterator iter); void eraser(iterator ibeg, iterator iend); int eraser(T value); ~ BST(); private: node* _root;&#125;;//The node for binary search treetemplate&lt;typename T&gt;struct BST&lt;T&gt;::node&#123; node(); T _value; node *_left; node *_right; node *_parent; // I should implement some override operator at here , but I omit these. &#125;;template&lt;typename T&gt;class BST&lt;T&gt;::node_iterator: public std::iterator&lt;std::bidirectional_iterator_tag ,node&gt;&#123;public: node_iterator(node* n); T&amp; operator* (); node* operator -&gt;(); node_iterator operator++ (); node_iterator operator++(int); node_iterator min(); bool operator ==( node_iterator r_iter); bool operator !=(const node_iterator r_iter); node* pointer();private: node* _node;&#125;;#endif 上述部分的实现,使得我们可以类似使用STL中的容器一样来操作BST了，当然还应该实现更多的函数以及操作符来提供更多的支持，但就上面实现的那些而言，我们已经可以做类似如下的操作了： 12345//用特定的迭代器来遍历 BSTfor(BST&lt;int&gt;::iterator iter=B.begin(); iter != B.end(); ++iter)&#123; cout&lt;&lt;*iter&lt;&lt;" ";&#125; 接受值类型匹配的其它类型的迭代器来作为插入： 12345BST&lt;int&gt; s;for(vector&lt;int&gt;::iterator iter=vec.begin(); iter!=vec.end() ; ++iter)&#123; s.insert(iter);&#125; …总之，目的是让BST使用起来与STL 一样的风格。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>binary search tree</tag>
        <tag>stl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chapter 12 二叉搜索树(Binary Search Tree) 2]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2Fchapter-12-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91binary-search-tree-2.html</url>
    <content type="text"><![CDATA[前驱和后继(Successor and predecessor)所谓前驱和后继(也许这么翻译，并不太正确，姑且这么叫)是指，指定元素在所有元素顺序排列模式下的前一个元素或后一个元素。 要获取一个二叉搜索树中指定结点的后继的直观的办法是，找到所有比指定结点大的结点中最小的。根据二叉搜索树的属性，找比某结点大的元素，可以往两个两个方向走： 往右子树方向走，结点右子树的元素都不小于本身； 往父结点方向走，指定的结点有可能处于其它结点的左子树中。 当指定结点拥有右子树时，那么其后继必存在于其右子树中。因往父结点方向找到的比指定结点大的元素大于指定结点右子树的所有元素。如果指定结点没有右孩子呢？那么沿着父结点的方向找到第一个其做字数包含指定结点的结点，这个结点就是指定结点的后继。 求后继的伪码： 12345678TREE-SUCCESSOR(x) if x.right ≠ NIL then return TREE-MINIMUM (x.right ) y =x.p while y ≠ NIL and x == y.right x = y y = y.p return y 类似的方法可以被我们用来求前驱，这里省略。 插入和删除操作对于插入操作很好解决，从根节点出发，不断比较，一路向下，直到不能再下，就会找到一个合适的位置。下面是伪码： 1234567891011121314151617TREE-INSERT(T, z) y = NIL x = T.root while x ≠ NIL y=x if z.key &lt; x.key x=x.left else x = x.right z.p=y if y == NIL T.root=z // Tree T was empty else if z.key &lt; y.key y.left = z else y.right = z 至于删除操作，则要麻烦一些，因为删除结点后，我们必须维持搜索二叉树的属性。假定，被删除的结点为z,那么有三种情况: z没有孩子； z有一个孩子； z有两个孩子。 对于没有孩子和一个孩子这种情况比较容易解决，有一个孩子可以用孩子替代z，一个孩子都没有则用 NIL。麻烦的在于有两个孩子的情况，此时我们必须找到z在其右子树中(仅仅是右子树范围中，而不是整个树中)的后继来代替z 。在进行具体操作时，导论上则归纳为四点： If z has no left child, we replace z by its right child. When z’s right child is also NIL, z has no children; when z’s right child is not NIL, z has one child. If z has just one child, it is a left child and we replace z by that child . Otherwise z has both a left child and a right child. We find z’s successor y which lies in z’s right subtree and has no left child . We want to splice y out of its current position and have it replace z in the tree. If y is z’s right child (Fig. 12.4c), we replace z by y, maintaining y’s right child. If y is not z’s right child,we first replace y by its own right child, then replace z by y. 我一开始有一点迷惑，为什么要找在右子树中的后继，而不是其真正的后继，好处在哪，更进一步，为什么是后继，而不是其它。 首先，我思考了一下，有怎么样的目标？如果目标单单是维持搜索二叉树的属性的话，那么直接重新建树就好，多么节省脑细胞，显然我们不这样做。我们想找的是一种既能维持搜索二叉树的属性，又手术动得比较小的方式，这无疑比较简单高效，就如我们在做堆的删除工作时，将被删除元素与末尾元素互换的原理一样。 在这之后，我可以总结出这三条： 范围可以缩小，要维持搜索二叉树的属性，只需将范围划定在以 z为根节点的子树中即可，因为其它部分的属性并未被破坏。 进一步缩小范围，可以找到一个点来替代z，这样不必要涉及整个子树。什么样的点最适合替代z?z的后继或前驱。秉着关起门来解决自家问题的原则(参照上一条)，对于后继或前驱的选择，应在z的子树中选择，所以这个替代点便变成了右子树中的后继或左子树中的前驱。 另外，不论是右子树中的后继，还是左子树中的前驱，都有一个优点，都最多只有一个孩子。因为拿掉这个结点而带来的问题容易解决。至于，为什么它们最多只有一个孩子？想一想，左子树中的前驱为左子树中的最大值，它的位置应该在哪？一路向右走到底。同样的思路，可以加之遇右子树中的后继。 以下是删除操作的伪码： 12345678910111213141516171819202122TREE-DELETE(T,z) if z.left == NIL TRANSPLANT(T,z,z.right) else if z.right == NIL TRANSPLANT(T,z,z.left) else y = TREE-MINIMUM(z.right) if y.p ≠ z TRANSPLANT(T,y,y.right) y.right = z.right y.right.p = y TRANSPLANT(T,z,y) y.left = z.left y.left.p = y TRANSPLANT(T,u,v) if u.p == NIL T.root = v else if u == u.p.left u.p.left = v else u.p.right = v if v ≠ NIL v.p = u.p 注意：伪码中的 TRANSPLANT，只修改 v 与 u的父亲之间的关系，而不修改与u孩子的关系。 关于随机构造搜索二叉树，用给定的一列的元素构造二叉树，假使这列元素是有序的，那么将构造成一根“棍子”，为了规避这种最坏情况的发生，可以采用随机构造二叉树的办法，导论上给出证明，随机构造的搜索二叉树的期望复杂度是O(lgn),精力所限，那个证明我就没有细看了。 补：关于删除操作为什么不在被删除结点上赋值 Many texts, including the ﬁrst two editions of this book, have asomewhat simpler method of deleting a node from a binary search treewhen both of its children are present. Instead of replacing node z by its successor y, we delete node ybut copy its key and satellite data into node z. The downside of this approach is thatthe node actually deleted might not be the node passed to the deleteprocedure. If other components of a program maintain pointers to nodesin the tree, they could mistakenly end up with “stale” pointers tonodes that have been deleted. Although the deletion method presentedin this edition of this book is a bit more complicated,it guaranteesthat a call to delete node z deletesnode z and only node z.]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>binary search tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chapter 12 二叉搜索树(Binary Search Tree) 1]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2Fchapter-12-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91binary-search-tree.html</url>
    <content type="text"><![CDATA[何为二叉搜索树？ Such a tree can be represented by a linked data structure in which each node is an object. In addition to a key field and satellite data, each node contains fields left, right, and p that point to the nodes corresponding to its left child, its right child, and its parent, respectively. If a child or the parent is missing, the appropriate field contains the value NIL. The root node is the only node in the tree whose parent field is NIL. binary-search-tree property:Let x be a node in a binary search tree. If y is a node in the left subtree of x, then key[y] ≤ key[x]. If y is a node in the right subtree of x, then key[x] ≤ key[y]. 遍历操作可以用三种方式来遍历搜索二叉树：前序遍历(preorder tree walk)、中序遍历(inorder tree walk)、后续遍历(postorder tree walk)。其名字的由来，缘于根节点被呈现的次序，是在最前中间、还是最后。 对于搜索二叉树来讲，由于其固有的特性（binary-search-tree property），中序遍历是按节点大小顺序方式遍历二叉树的。看一个递归版本的中序遍历代码： 12345INORDER-TREE-WALK(x) if x ≠ NIL then INORDER-TREE-WALK(left[x]) print key[x] INORDER-TREE-WALK(right[x]) 因根结点不小于所有左子树的节点，且不大于所有右子树的节点，所以上面的中序遍历的伪代码，输出的结果将按照从小到大排列。虽然递归用来表现算法简单明了，但在实际应用中为了更好的效率，我们可能更希望有一个迭代版。关于迭代版，会在做本节的习题12.1-3 时在来实现，另外，在用C++实现二叉搜索树这个数据结构的时候，也会采用迭代版。 搜索以及求最大最小节点的操作 根据二叉搜索树属性，这些都是很简单的操作，以下为这些操作的伪码： 1234567891011121314151617//搜索ITERATIVE-TREE-SEARCH(x, k) while x ≠ NIL and k ≠ key[x] if k &lt; key[x] then x = x.left else x = x.right return x// 最小值TREE-MINIMUM (x) while left[x] ≠ NIL x = x.left; return x//最大值TREE-MAXIMUM(x) while x.right≠ NIL x=x. right return x]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>Binary Search Tree</tag>
        <tag>算法导论</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solution of CLRS 11.1 exercises]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2Fsolution-of-clrs-11-1-exercises.html</url>
    <content type="text"><![CDATA[Exercises 11.1-2 A bit vector is simply an array of bits (0’s and 1’s). A bit vector oflength m takes much less space than an array of m pointers. Describe howto use a bit vector to Represent a Dynamic Set of Distinct Elements with noSatellite Data. Dictionary Operations Should Run in O(1) Time. Solution(I get the result from Rip’s blog, The original text ishere for ease of reference.): Using a bit vector of length m, as our direct-address table to represent thedynamic set.Here m bits tags m slots of the table. The elements in thedynamic set is stored in the direct-address table itself. If slot k isallocated, bit k is 0. If slot k contains no element, bit k is 1. Bit VectorThe free-space list is often implemented as a bit map or bit vector. If ablock is free, the bit is 1. If a block is allocated, the bit is 0. Assumethe following blocks are allocated, the rest free: 2, 3, 4, 5, 8, 9, 10, 11,12, 13, 17, 18, 25, 27 .The free-space bit map wouldbe: 0011110011111100011000000111000000… Adavantages of this approach include:· Relatively simple· Efficient to find the first free blocks or n consecutive free blockson the disk. Bit maps are useful only when it can be kept in main memory. But, as disks getlarger, this is hard to do. 1.3 gigabyte disk with 512 byte blocks would needa bit map of over 310k to track its free blocks. Clustering the blocks inintervals of foul reduces this number to 78k per disk. Exercises 11.1-3 Suggest how to implement a direct-address table in which the keys of storedelements do not need to be distinct and the elements can have satellite data.All three dictionary operations (INSERT, DELETE, and SEARCH) should run inO(1) time. (Don’t forget that DELETE takes as an argument a pointer to anobject to be deleted, not a key.) Solution:可以直接用链表来解决碰撞问题。对于搜索的话可以返回链表的指针，根据题目的条件来看，对于两个用户提供的两个key相同的object我们是无法区分的，因此只能返回一组key相同的objecet让用户用自己的方法来区分。 Exercises 11.1-4 We wish to implement a dictionary by using direct addressing on a huge array.At the start, the array entries may contain garbage, and initializing theentire array is impractical because of its size. Describe a scheme forimplementing a direct-address dictionary on a huge array. Each stored objectshould use O(1) space; the operations SEARCH, INSERT, and DELETE shouldtake O(1) time each; and the initialization of the data structure should takeO(1) time. (Hint:Use an additional stack, whose size is the number of keysactually stored in the dictionary, to help determine whether a given entry inthe huge array is valid or not.) Solution:一直没想出好的办法来解决这个问题，今天看《算法导论教师手册》有这个题的解答。觉得它的数据结构的思路比较巧妙：字典中每个元素带有一个索引，表示关于该元素的的key存储在辅助栈中的位置。而辅助栈用数组实现，因此可以随机访问。辅助栈中存储所有存在于字典中的元素的key ，于是形成了一个所谓validating cycle。要判断从字典中直接读取到的元素是不是需要的数据，只需要取出该元素中的索引，判断这个索引是否有效（大于栈底而小于栈顶），然后通过索引获取栈中的key ,与自己需要的元素的key比较看是否相等即可以。相等表示该数据是要找的数据，否则不是。显而易见，通过这个数据结构模型来进行SEARCH, INSERT都为O(1)。至于DELETE 操作，需要将被删除的数据在栈中的key与栈顶存储的key交换后再删除，同样可以达到O(1)，要注意的是删除过程中，需要更新与原栈顶中key相关元素的索引。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>Exercises</tag>
        <tag>bit vector</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[又到离别时]]></title>
    <url>%2Fessaies%2Fleave.html</url>
    <content type="text"><![CDATA[前几天毕业后的工作已经决定下来，前两天《深度探索C++对象模型》的学习也已经了结。手头事情忙得差不多的时候，一回头不禁感叹，又是一季离别，年后大学也算结束了。当然，或许你是以拿到毕业证作为一段生涯的句点，那自然不是，这只能说认知上有些差别。 说到工作的事，首先要很谢谢熊哥的内荐，免了我舟车劳顿、颠沛奔波的辛苦。虽然程序不少，但是能仅仅打几通电话、收发几封邮件、写两段代码来决定工作，比之奔走求职确实是一件轻松太多的事情。我原来已经拿定主意年后南下找工作，不过既然可以不用奔波，公司又让我满意，我自然安心下来。我虽然一开始就决定明年才开始求职的行程，不过中途经不住各位同学都已经签约的诱惑。有去试过两家公司，一家叫深信服，另一家叫龙通。毫无疑问，这是两次失败的经历。 虽然两次失败的经历对我来说并没有太多的遗憾，但是还是收获有一些经验。深信服是在笔试的时候被刷的，本来笔试被刷，没有什么可谈，无非自己实力欠缺。但我却犯了一些天真的错误。其一是笔试迟到了将近半个小时，不过考官还是让我们进去了，虽然最后时间不缺，但显然对它缺乏重视——实际上我本来不打算参加笔试的。其二在于，我天真的不把它当一场考试，选择题部分，我甚至没有在显眼的地方写上我的答案，仅仅在每个错误的选项旁边，写下四五个字的注释，诸如此类随意的做法，我也不记得试卷上有多少，何况深信服的题量之大，足有十页。考完之后，我还颇有自信，甚至坚持在熊哥和旺X那里过夜，等待面试通知。 如果说深信服得到了一些教训的话，龙通的那次面试则是纯粹浪费时间了，通过笔试后，大概是第四天去长沙参加了龙通的面试，面试我的是两个小伙，估计比我大不了几岁，和其中一个胖点的相谈甚欢(应该是人力，我却一直和他讲技术)，到另外一个瘦点的来面具体技术的时候，却把我镇住了——居然边上网找题目，边问我。问的问题很简单，但我都很慎重的作答。我自信对他所问，都有把握——除了其中两个。一个为函数指针的使用问题，他问我函数指针使用时需不需要解引用，我答他可以不用，当我刚开口要说一说为什么可以用也可以不用时。他似乎一副不必改口的样子，直接告诉我进入下一题，我自然没有抢白解释。另一个问题，他问我用过什么样的进程间通信方式，我答他我只用过套接字。他又问我进程通信有几种方式，这题我当时没答上。其实最让人不能接受的问题在于，当我说出期望薪资是5k的时候，我明显看到那两小子有点轻笑的味道，好像在说我不知天高地厚。姑且不论5k的薪水到底是多是少，要知道他们宣讲的时候说的待遇是4.8k-6.8k，我说5k绝对合理，当然后来在网上查了下龙通签人的薪水，估计他们宣讲时的薪水含有不少水分。后来又问我转不转java，去不去南京，我都表示不会考虑。 起笔之时，并没有打算讲求职琐事，写到此处，才发觉占了大量篇幅，气氛全无… 当跑题跑了数公里之外的时候，我们再校正回来。 再续离别时散席时，总不必表现的太过伤感，再尽兴的聚会，也总有离席散客之时，但倘若缘分尚在，情分依旧，欢聚重逢，把酒高欢的时刻总不会少。 我本来打算想营造点伤感的气氛，但无赖虽然可以预见有一份离别的伤感，但毕竟这份伤感却还未到来，谁叫我这人只能提前享受快乐，却无法预支悲伤。更何况，最近这几个月我又过的太过恰意，一段手上有几本欲罢不能的好书，脚下经常能踢几场酣畅淋漓的爽球，偶尔还可以把酒高歌，有时亦可以静坐垂钓，更甚至，明天凌晨五点的世纪大战，细哥还会电话叫我起床看球。这样的生活，又哪能期待更多。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深度探索C++对象模型》笔记汇总]]></title>
    <url>%2Fdevelop%2Fcpp%2F%E3%80%8A%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2c%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%E3%80%8B%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB.html</url>
    <content type="text"><![CDATA[01. 总结——亦为引言 第1章 关于对象(Object Lessons) 02. C++对象面面观 第2章 构造函数语意学(The Semantics of constructors) 03. 深入C++构造函数 04. 拷贝构造函数(Copy Constructor) 05. 命名返回值优化和成员初始化队列 第3章 Data语意学（The Semantics of Data） 06. C++类对象的大小 07. VC内存对齐准则（Memory alignment） 08. C++对象的数据成员 第4章 Function语意学（The Semantics of Function） 09. C++之成员函数调用 10. C++之虚函数(Virtual Member Functions) 第5章 构造、解构、拷贝 语意学（Semantics of Construction，Destruction，and Copy） 11. 几点类设计原则 12. 构造、复制、析构语意学 第6章 执行期语意学（Runting Semantics） 13. new expression、operator new 和 placement new——三个“妞（new）”的故事（1） 14. new expression、operator new 和 placement new——三个“妞（new）”的故事（2） 15. new expression、operator new 和 placement new——三个“妞（new）”的故事（3） 16. 对象的构造和析构 17. 临时性对象(Temporary Objects) 第7章 站在对象模型的类端（On the Cusp of the Object Model） 18. 模板二事 19. EH &amp; RTTI]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[总结·亦为引言]]></title>
    <url>%2Fdevelop%2Fcpp%2F%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2c%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%2F%E6%80%BB%E7%BB%93%E4%BA%A6%E4%B8%BA%E5%BC%95%E8%A8%80.html</url>
    <content type="text"><![CDATA[《深度探索C++对象模型》终于在昨天写完了最后一篇笔记，前前后后花费了一个 月左右，期间学到了很多，很感激书的作者和译者。之后的日子，可以将精力转 回《算法导论》和一些非技术类的书上来了。 11月11号开始看《深度探索C++对象模型》一书，到二十八号看完，共计花费了十 八天。不过到做完全书的笔记则是昨天的事了。期间也算是反复阅读，中英文版本 对照，虽然不能说事深掘至微末，但也能算掌握了主络，倒是令我自己满意。 期间花费的心力精神自不必说，但收获欢欣也实在不少。得益于 Lippman 的大师技艺，书中很多地方使我有拨云见日的豁然，一些原以为晦涩高超的技巧， 其真实面目暴力且直接。这本书不厚，但可以深掘的东西实在不少，以至于某些 时候，我不得不停下思路，以免难以自拔。 当然，在这个行业来说，这本书毕竟有点“远古”，读这本书的时候，必须保持着 清晰的头脑，不能迷信作者和译者——虽然他们都是值得尊敬的人物。需要抱有怀 疑精神，更需要多动手编码验证一番。原书的疏漏笔误之处着实不少，这要多谢 译者侯捷一一指正。但或许正因为这个原因，无端膨胀了译者的自信，毕竟指点 一个大师的错误是一件如此刺激的事情。这无端膨胀的自信，同样带来了一些问 题——一些原本正确之处，被做了错误的更正。可见，于技术学习来说，谨慎谦虚， 何其重要。]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EH & RTTI]]></title>
    <url>%2Fdevelop%2Fcpp%2Feh-rtti.html</url>
    <content type="text"><![CDATA[异常处理(Exception Handling)C++的 exception handling 有三个主要的子句组成： 一个throw子句。它在程序的某处丢出一个exception，被丢出的exception可以是内建类型，也可以是自定义类型。——抛出exception组件。 一个或多个 catch 子句。 每一个 catch 子句都是一个 exception handler。每个子句可以处理一种类型(也包括其继承类)的exception，在大括号中包含处理代码。——专治各种不服组件。每一个catch子句都可以用来处理某种exception。 一个 try 区段。用大括号包围一系列语句，这些语句有可能抛出exception，从而引发catch 子句的作用。——逮捕各种 exception 组件。 当一个 exception 被抛出后，控制权从函数调用中被释放，寻找一个吻合的catch子句，如果各层调用都没有吻合的catch子句，terminate()将被调用。在控制权被放弃后，堆栈中的每一个函数调用也被出栈，这个过程称为unwinding the stack(关于 stack unwinding ,可以参考《C++ Primer》第四版之 17.1.2 Stack Unwinding)，在每一个函数被出栈之前,其局部变量会被摧毁。 异常抛出有可能带来一些问题，比方在一块内存的lock和unlock内存之间，或是在new和delete之间的代码抛出了异常，那么将导致本该进行的unlock或delete操作不能进行。解决方法之一是： 12345678910111213141516void mumble( void *arena ) &#123; Point *p; p = new Point; try &#123; smLock( arena ); // ... &#125; catch ( ... ) &#123; smUnLock( arena ); delete p; throw; &#125; smUnLock( arena ); delete p; &#125; 在函数被出栈之前，先截住异常，在unlock和delete之后再将异常原样抛出。new expression的调用不用包括在try块之内是因为，不论在new operator调用时还是构造函数调用时抛出异常，都会在抛出异常之前释放已分配好的资源，所以不用再调用delete 。 另一个办法是，将这些资源管理的问题，封装在一个类对象中，由析构函数释放资源，这样就不需要对代码进行上面那样的处理——利用函数释放控制权之前会析构所有局部对象的原理。 在对单个对象构造过程中抛出异常，会只调用已经构造好的base class object或member class object的析构函数。同样的道理，适用于数组身上，如果在调用构造函数过程中抛出异常，那 么之前所有被构造好的元素的析构函数被调用，对于抛出异常的该元素，则遵循关于单个对象 构造的原则，然后释放已经分配好的内存。 只有在一个catch子句评估完毕并且知道它不会再抛出exception后，真正的exception object才会被释放。关于 catch子句使用引用还是使用对象来捕获异常，省略。 执行期类型识别（Runtime Type Identification RTTI） RTTI 只支持多态类，也就是说没有定义虚函数是的类是不能进行 RTTI的。 对指针进行dynamic_cast失败会返回NULL ,而对引用的话，识别会抛出bad_cast exception。 typeid 可以返回const type_info&amp;，用以获取类型信息。 关于1是因为RTTI的实现是通过vptr来获取存储在虚函数表中的type_info* ，事实上为非多态类提供RTTI,也没有多大意义。 2的原因在于指针可以被赋值为0，以表示 no object，但是引用不行。关于3，虽然第一点指出RTTI只支持多态类，但typeid和type_info同样可用于内建类型及所有非多态类。与多态类的差别在于，非多态类的type_info对象是静态取得(所以不能叫“执行期类型识别”)，而多态类的是在执行期获得。 参考：深度探索C++对象模型]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>EH</tag>
        <tag>Inside The C++ Object Model, RTTI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模板二事]]></title>
    <url>%2Fdevelop%2Fcpp%2F%E6%A8%A1%E6%9D%BF%E4%BA%8C%E4%BA%8B.html</url>
    <content type="text"><![CDATA[模板的实例化一个模板只有被使用到，才会被实例化，否则不会被实例化。对于一个实例化后的模板来说，未被调用的成员函数将不会被实例化，只有成员函数被使用时，C++标准才要求实例化他们。其原因，有两点： 空间和时间效率的考虑，如果模板类中有100个成员函数，对某个特定类型只有2个函数会被使用，针对另一个特定类型只会使用3个，那么如果将剩余的195个函数实例化将浪费大量的时间和空间。 使模板有最大的适用性。并不是实例化出来的每个类型都支持所有模板的全部成员函数所需要的运算符。如果只实例化那些真正被使用的成员函数的话，那么原本在编译期有错误的类型也能够得到支持。 可以明确的要求在一个文件中将整个类模板实例化： 1template class Point3d&lt;float&gt;; 也可以显示指定实例化一个模板类的成员函数： 1template float Point3d&lt;float&gt;::X() const; 或是针对一个模板函数： 12template Point3d&lt;float&gt; operator+( const Point3d&lt;float&gt;&amp;, const Point3d&lt;float&gt;&amp; ); 模板的错误报告，使用模板并遇到错误的大概都深有体会，那就是一个灾难。 模板的名称决议一开始先要区分两种意义,一种是C++ 标准所谓的“scope of the templatedefinition”，直译就是“定义模板的范围”。另一种是C++标准所谓的“scope ofthe temlate instantiation”，可以直译为“实例化模板的范围”。 第一种情况： 12345678910111213141516171819// scope of the template definitionextern double foo ( double ); template &lt; class type &gt; class ScopeRules &#123; public: void invariant() &#123; _member = foo( _val ); &#125; type type_dependent() &#123; return foo( _member ); &#125; // ... private: int _val; type _member; &#125;; 第二种情况: 123456//scope of the template instantiation extern int foo( int ); // ... ScopeRules&lt; int &gt; sr0; sr0.invariant();sr0.type_dependent(); 在“scope of the template instantiation ”中 两个foo()都声明在此 scope中。猜猜sr0.invariant() 中调用的是哪个foo()函数，出乎意料，实际调用的是： extern double foo ( double ); 看上去，应该调用： extern int foo( int ); 毕竟，_val 的类型是 int 类型，它们才完全匹配。而 sr0.type_dependent()中调用的却在我们意料之中，调用的是: extern int foo( int ); 诸上所述,看上去或合理或不合理的选择，原因在于: template 之中， 对于一个非成员名字的决议结果是根据这个 name的使用是否与“用以实例化该模板的参数类型”有关来决定name。如果其使用互不相干，那么就以“scope of the template dclaration”来决定name。如果其使用的互相关联，那么就以“scope of the templateinstantiation”来决定name. 对于上面这一段话我的理解比较粗鲁且直接：在模板中，一个非成员名字的决议在于它适不适合在当前决议，当它完全与实例化模板的参数的类型无关的时候，就可以在当前决议下来；如果有关的话，则认为不适合在当前决议下来，将被推迟到实例化这个模板实例化的时候来决议。为什么以与实例化的类型相关不相关来区别适不适合当前决议？一个与实例化类型无关的名字，如果推迟到实例化的时候来决议，将使模板的设计者无所适从，一个模板的设计者能容忍一个与实例化类型无关的名字在他的模板中表现出当前不具有的含义吗？当然不行，那种场面，估计没有一个模板设计者能够hold住。相反，对于一个与实例化类型有关的名字，天生就应该可以根据实例化模板的不同类型表现出不同含义，如果其名字早在模板定义时被决议出来，那就该轮到模板的使用者hold不住了。当然所上完全属一家之言，呸，连一家之言都不算，怎么敢自称“家”。如有不同理解，可当我一派胡言，如果你聊发善心，可以对我赐教一二，当聆听受教。 参考：深度探索C++对象模型]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
        <tag>template instantiation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[临时性对象(Temporary Objects)]]></title>
    <url>%2Fdevelop%2Fcpp%2F%E4%B8%B4%E6%97%B6%E6%80%A7%E5%AF%B9%E8%B1%A1temporary-objects.html</url>
    <content type="text"><![CDATA[何时生成临时对象对于一个下面这样的程序片段： 12T a, b;T c=a+b; 死板一点来讲，它应当产生一个临时对象用来存储a+b的结果，然后以临时对象作为初值调用拷贝构造函数初始化对象c。而实际上编译器更愿意直接调用拷贝构造函数的方式将a+b的值放到c中，这样就不需要临时对象，和它的构造函数和拷贝构造函数的调用了。 更进一步，如果operator +的定义符合NRV优化的条件，那么NRV优化的开启，将使得拷贝构造函数的调用和named object的析构函数都免了。期间详情可以参见”NRV优化”。也就是说对于上面那种情形在我们的代码中是不产生临时对象的。但是对于一个情况非常类似的赋值操作语句c = a+b，却有很大的差别，那个临时变量是不能省的 不能忽略临时对象，反而导致如下过程： 12345678// Pseudo C++ code // T temp = a + b; T temp; a.operator+( temp, b ); // @1 [^注1] // c = temp c.operator =( temp ); // @2 temp.T::~T(); 在代码@1处，表明以拷贝构造函数或NRV方式将结果保存的临时对象中。为什么不能省略那个临时对象，比如直接这样： 12c.T::~T();c.T::T(a+b); 这不是更高效，更简洁的方式吗？不行，其原因在于，拷贝构造函数、析构函数以及赋值操作符都可以由使用者提供，没有人能保证，析构函数加拷贝构造函数的组合和赋值操作符具有相同的含义。所以：T c=a+b总是比c = a + b更有效率。 对于一个没有出现目标对象的表达式a + b,那么产生一个临时对象来存储运算结果，则是非常必要的。 临时对象的生命周期很多时候，产生临时对象是必不可少的，但是何时摧毁一个临时对象才是最佳行为呢？过早或过晚都不太适合，过早有可能使得程序错误，过晚的话又使得资源没有得到及时回收。对于下面的程序： 12string s1("hello "), s2("world "),s3("by Adoo");std::cout&lt;&lt;s1+s2+s3&lt;&lt;std::endl; 显然保存s1+s2结果的临时对象，如果在与s3进行加法之前析构，将会带来大麻烦。于是C++标准中有一条： 临时性对象的摧毁应当作为造成产生这个临时对象的完整表达式的最后一个步骤。 完整的表达式，是指涵括的表达式中最外围的那个。我们再看上面那个字符串相加的表达式，当计算完成，而cout还未调用，此时我们析构掉存储最终结果的临时对象，岂不悲剧。其实上面的规定还有两个例外： 凡含有表达式执行结果的临时性对象，应该保存到Object的初始化操作完成为止。 如果临时性对象被绑定与一个引用，临时对象将残留，直至被初始化的引用的生命结束，或直到临时对象的生命周期结束——视哪一种情况先达到，对应于这种情况： 12::string s1("hello ");::string &amp;s=s1+"world"; [^注1]: 侯捷认为此处为 Lippman 的错误，他认为应该为temp.operator + ( a, b )但我以为是侯捷并没有理解Lippman的意思，回顾一下,《深度探索对象模型》2.3讲到的返回值初始化(Return ValueInitialization)——返回值将作为一个额外的参数提供给函数，来传回函数内部的值，也就是说对于一个 operator + 操作符T T::operator+ (const T&amp; right)将转化为void T::operator+ (T &amp;result ,const T&amp; right)所以temp=a+b是a.operator+( temp, b )还是temp.operator+( a, b )自然不言而喻。]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对象的构造和析构]]></title>
    <url>%2Fdevelop%2Fcpp%2F%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%9E%84%E9%80%A0%E5%92%8C%E6%9E%90%E6%9E%84.html</url>
    <content type="text"><![CDATA[一般而言，构造函数被安插在对象的定义处，而析构函数被安插在对象生命周期结束前： 1234567// Pseudo C++ Code &#123; Point point; // point.Point::Point() 一般被安插在这儿 ... // point.Point::~Point() 一般被安插在这儿 &#125; 当代码有一个以上的离开点的时候，析构函数则必须放在对象被构造之后的每一个离开点之前。因此，尽可能将对象定义在接近要使用的地方，可以减少不必要的构造对象和析构对象的代码被插入到自己的代码当中。 全局对象一个全局对象，c++保证它在main()在第一次使用它之前将其构造，而在main()结束之前，将之析构掉。C规定一个全局对象只能被一个常量表达式(编译期可知)赋初值。而构造函数显然不是一个常量表达式。虽然全局对象在编译期被即被置为0，但真正的构造工作却需要直到程序激活后才能进行，而这个过程就是所谓的静态初始化。我是这样理解，但我不保证正确，因为全局变量，被放在data segment (数据段)，data segment是在编译期已经布置好的，但构造函数的结果在编译期不能评估，因此先将对象的内容设置为0，存储在数据段，而等到程序激活时，这时候就可以通过构造函数对在数据段的全局对象进行初始化了，而这就是所谓的静态初始化。 静态初始化的对象有一些缺点：如果构造函数支持异常机制，那么遗憾的是对象的构造函数的调用，无法被放置与try块中，我们知道一个没有得到catch的异常默认的调用terminate()函数。也就是说一个全局对象在构造过程中抛出异常，将导致程序的终结，而更悲剧的是，你还无法来捕获并处理这个异常。另一点在于，在不同文件中定义的全局变量，构造顺序有规则吗？我不知道。即使有规则，如果不同的构造顺序对程序有影响的话，那么有多琐碎复杂… Lippman甚至建议：根本就不要使用那些需要静态初始化的全局对象。真的非要一个全局对象，而且这个对象还需要静态初始化？那么我的方法是，用一个函数封装一个静态局部对象，也是一样的效果嘛。 局部静态对象(Local Static Object)下面一段代码： const Matrix&amp; identity() { static Matrix mat_identity; // ... return mat_identity; } 因为静态语意保证了 mat_identity 在整个程序周期都存在，而不会在函数identity()退出时被析构，所以： mat_identity的构造函数只能被施行一次，虽然identity()可以被调用多次。 mat_identity 的析构函数只能被施行一次，虽然identity()可以被调用多次。 那么 mat_identity的构造函数和析构函数到底在什么时候被调用？答案是:mat_identity的构造函数只有在第一次被调用时在被施行，而在整个程序退出之时按构造相反的顺序析构局部静态对象。 对象数组(Array of Objects)对于定义一个普通的数组，例如： Point knots[ 10 ]; 实际上背后做的工作则是： 分配充足的内存以存储10个Point元素； 为每个Point元素调用它们的默认构造函数(如果有的话，且不论是合成的还是显式定义的)。编译器一般以一个或多个函数来完成这个任务。当数组的生命周期结束的时候，则要逐一调用析构函数，然后回收内存，编译器同样一个或多个函数来完成任务。这些函数完成什么功能，大概都能猜得出来。而关于细节，不必要死扣了，每个编译器肯定都有些许差别。 参考：Lippman 的两本书《深度探索C++对象模型》和《C++ Primer》。]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[new expression、operator new和placement new——三个妞（new）的故事（3）]]></title>
    <url>%2Fdevelop%2Fcpp%2Fnew-expression%E3%80%81operator-new-%E5%92%8C-placement-new%E4%B8%89%E4%B8%AA%E5%A6%9E%EF%BC%88new%EF%BC%89%E7%9A%84%E6%95%85%E4%BA%8B%EF%BC%883%EF%BC%89.html</url>
    <content type="text"><![CDATA[placement operator newplacement operator new用来在指定地址上构造对象，要注意的是，它并不分配内存，仅仅是 对指定地址调用构造函数。其调用方式如下： point *pt=new(p) point3d;观其名字可知，它是operator new的一个重载版本。它的实现方式异常简单，传回一个指针即 可： 1234void* operator new(site_t,void *p)&#123; return p;&#125; 不必要惊讶于它的简单，《深度探索C++对象模型》中Lippman告诉我们，它有另一半重要的工 作是被扩充而来。我在想，扩充一个类中定义的placement operator new还好说，但是要如何 扩充一个库中提供的placement operator new呢？毕竟它要放之四海而皆准，我原以为这其中 有什么高超的技巧。后来我则坚信根本就没有什么扩充，placement operator new 也并不强 大。 我先明确调用了 placement operator new ： point *pt=(point*)operator new(sizeof(point), p) ;如我所料，输出结果显示（我在point的默认构造函数和placement operator new中间各输 出一句不同的话），此时 point的默认构造函数并不会被调用。然后我通过new expression 的方式来间接调用placement operator new： point *pt=new(p) point();这个时候 point 的默认的构造函数被调用了。可见 placement operator new并没有什么奇特 的地方，它与一般的operator new不同处在于，它不会申请内存。它也不会在指定的地址调用 构造函数，而调用构造函数的的全部原因在于new expression总是先调用一个匹配参数的 operator new然后再调用指定类型的匹配参数的构造函数，而说到底 placement operator new 也是一个 operator new。 通过一个placement operator new构建的一个对象，如果你使用delete来撤销对象，那么其内 存也被回收，如果想保存内存而析构对象，好的办法是显示调用其析构函数。 看一份代码： 123456789struct Base &#123; int j; virtual void f(); &#125;;struct Derived : Base &#123; void f(); &#125;;void fooBar() &#123; Base b; b.f(); // Base::f() invoked b.~Base(); new ( &amp;b ) Derived; // 1 b.f(); // which f() invoked? &#125; 上述两个类的大小相同，因此将Derived对象放在 Base对象中是安全的，但是在最后一句代码 中 b.f()调用的是哪一个类的f()。答案是Base::f() 的。虽然此时b中存储的实际上是一个 Derived对象，但是，通过一个对象来调用虚函数，将被静态决议出来，虚函数机制不会被启用。 参考：Lippman 的两本书《深度探索C++对象模型》和《C++ Primer》。]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[new expression、operator new和placement new——三个妞（new）的故事（2）]]></title>
    <url>%2Fdevelop%2Fcpp%2Fnew-expression%E3%80%81operator-new-%E5%92%8C-placement-new%E4%B8%89%E4%B8%AA%E5%A6%9E%EF%BC%88new%EF%BC%89%E7%9A%84%E6%95%85%E4%BA%8B%EF%BC%882%EF%BC%89.html</url>
    <content type="text"><![CDATA[两个 delete 后的问题最近在网上看到两个关于指针 delete 后的问题。第一种情况： 123int* p = new int;delete p;delete p;// p为什么能delete两次，而程序运行的时候还不报错。 第二种情况： 123int* p = new int ;delete p;*p = 5; //delete后对*p进行再赋值居然也可以（他的平台上运行并没有引发什么错误）？ 在回答这两个问题之前，我们先想想delete p; 这一语句意味着什么？p指向一个地址，以该地址为起始地址保存有一个int变量（虽然该变量并没有进行初始化），delete p之后p所指向的地址空间被释放，也就是说这个int变量的生命结束，但是p仍旧是一个合法的指针，它仍旧指向原来的地址，而且该地址仍旧代表着一个合法的程序空间。与delete之前唯一的不同是，你已经丧失了那快程序空间的所有权。这带来一个什么样的问题？你租了一间储物室（int* p = new int;），后来退租了（delete p;），但你却保存了出入该储物室的钥匙（指针p）没有归还。拥有这片钥匙，你或许什么都不做，这自然没有问题。但是： 你或许出于好心，又跑过去告诉房东，“Hi！这储物室已经退租了（第一种情况）”。哦噢，会发生什么？我们假设此时这个房子已经有了新的租客。愚笨的房东直接相信了你的话，认为这个储物室空着，把它又租给新的人。于是一间只能给一个人用的储物室，却租给了两个人，再之后各种难以预料的情况就会发生。 又或许，你很无耻，你虽然退租，但却想用你的钥匙依旧享有储物室的使用权（第二种情况），结果呢，你存在这间储物室的东西可能会被现在的租客丢掉，而你也可能把他的东西丢掉，腾出空间来放你的。 回到上面的程序上来，毫无疑问的是上面的程序在语法上来讲是合乎规范的，但是暗藏着很大的逻辑错误，不论你对一块已经释放的内存再度delete，还是再度给它赋值，都暗含着很大的危险，因为当你delete后，就代表着将这块内存归还。而这块被归还的内存很可能已经被再度分配出去，此时不论是你再度delete还是重新赋值，都将破坏其它代码的数据，同时你存储在其中的数据也很容易被覆盖。至于报不报错，崩不崩溃，这取决于有一个怎么样的“房东”，聪明且负责的“房东”会阻止你上述的行为——终止你的程序，懒惰的房东，则听之任之。 上述情况下的指针p被称为野指针——指向了一块“垃圾内存”，或者说指向了一块不应该读写的内存。避免野指针的好方法是，当一个指针变为野指针的时候，马上赋值为NULL，其缘由在于，你可以很容易的判断一个指针是否为NULL,却难以抉择其是否为野指针。而且，delete一个空指针，不会做任何操作，因此总是安全的。 不用一个基类指针指向派生类数组？《深度探索C++对象模型》中指出，不要用一个基类指针指向派生类的数组。因为在他的cfront中的vec_delete是根据被删除指针的类型来调用析构函数——也就是说虚函数机制在这儿不起作用了。照这样的思路来说，对一个派生类的数组依次调用其基类的析构函数，显然大多时候不能正确析构——派生类一般大于其基类。但是我感兴趣的一点是，这么多年过去了，这样一个不太合理的设计是否有所改进呢？说它不太合理是，以C++编程者的思路，在这样一种情况下，它应该支持多态，而且在这种情况下支持多态并不需要太复杂的机制和代价。我在vc++2008和vc++ 2010下的结果是：是的，有与cfront不同，它支持多态。 我的测试代码如下： 1234567891011121314151617181920212223class point&#123;public: virtual ~point()&#123; std::cout&lt;&lt;"point::~point()"&lt;&lt;std::endl; &#125;private: int a;&#125;;class point3d:public point&#123;public: virtual ~point3d() &#123; std::cout&lt;&lt;"point3d::~point3d()"&lt;&lt;std::endl; &#125;private: int b;&#125;;int main()&#123; point *p=new point3d[2]; delete[] p; system("pause");&#125; ; 输出的结果，也令人满意： 确实调用了派生类的析构函数，而非基类的析构函数。 即使如此，是否能安心的使用一个基类指针指向派生类数组？我不太安心！——对于基类的析构函数是否为虚函数没有把握。所以最好还是不要把一个基类的指针指向派生类数组。非得这么做？那么我认为delete的时候将之类类型转换为派生类就差不多了，可以这样: 1delete[] static_cast&lt;point3d*&gt;(p); 似乎不必要像Lippman说的这样： 12345for ( int ix = 0; ix &lt; elem_count; ++ix ) &#123; Point3d *p = &amp;((Point3d*)ptr)[ ix ]; delete p; &#125; 参考：Lippman 的两本书《深度探索C++对象模型》和《C++ Primer》。]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[new expression、operator new 和 placement new——三个妞（new）的故事（1）]]></title>
    <url>%2Fdevelop%2Fcpp%2Fnew-expression%E3%80%81operator-new-%E5%92%8C-placement-new%E4%B8%89%E4%B8%AA%E5%A6%9E%EF%BC%88new%EF%BC%89%E7%9A%84%E6%95%85%E4%BA%8B%EF%BC%881%EF%BC%89.html</url>
    <content type="text"><![CDATA[之前虽然一直知道有new expression、operator new和placement new，但对于这三个“new”,却不甚了了，这些天从《深度探索C++对象模型》读到new和delete，特意结合《C++ Primer》写下这篇笔记，以作总结。三个虽然都是“妞”（new），但每个妞都不相同各有各的特点，各有各的风味，本文重点在于总结比较这三个“妞”，但期间也不忘提一提推倒这三个“妞”的哥们——delete。 new expression 和 operator new一个看起来很简单的new expression运算，其实暗含一些步骤，像这样的一次简单运用：int *p=new int (5)实际上包含着两个步骤： 调用一个合适的operator new实体分配足够的未类型化的内存。 调用合适的构造函数初始化这块内存，当然int没有构造函数，但是会进行赋值操作：*p=5。 由此可见：new expression和operator new完全不是一回事，但关系不浅——operator new 为new expression分配内存。 摘录一下 《C++ primer》关于对比new expression 和 operator new的一小段话： 标准库函数 operator new和 operator delete 的命名容易让人误解。与其他operator 函数（如 operator=）不同，这些函数没有重载new或delete expression，实际上，我们不能重定义new或delete expression的行为。 这段话有两个要点： operator new和operator delete不是new expression和delete expression的重载，它们完全是另外的一个独立的东西，具有不同的语意，这与operator +是对+ expression的重载不同。 new expression和delete expression是不能被重载的，可以看出它们与普通的expression 不同。 operator new其实也是可以直接利用的，譬如当我们只想分配内存，而不愿意进行初始化的时候，我们就可以直接用operator new 来进行。用法如下： 1T* newelements = static_cast&lt;T*&gt;(operator new ( sizeof(T) ); 标准库重载有两个版本的operator new，分别为单个对象和数组对象服务，单个对象版本的提供给分配单个对象new expression调用，数组版的提供给分配数组的 new expression 调用： 12void *operator new(size_t); // allocate an objectvoid *operator new[](size_t); // allocate an array 我们可以分别重载这两个版本，来定义我们自己的分配单个对象或对象数组的内存方式。当我们自己在重载operator new时，不一定要完全按照上面两个版本的原型重载，唯一的两个要求是：返回一个void*类型和第一个参数的类型必须为size_t。 还要注意的是，在类中重载的operator new和operator delete是隐式静态的，因为前者运行于对象构造之前，后者运行与对象析构之后，所以他们不能也不应该拥有一个this指针来存取数据。另外，new expression 默认调用的是单参数的operator new——上面声明的那种，而其它不同形式的重载，则只能显式调用了。 delete expression与new expression相对应，而operator delete则与operator new对应。依上所述，则不难推断出关于delete expression和operator delete之间的关系以及一些特性，此略。 当使用new expression来动态分配数组的时候，Lippman在《深度探索C++对象模型》中指出：当分配的类型有一个默认构造函数的时候，new expression将调用一个所谓的vec_new()函数来分配内存，而不是operator new内存。但我在VC ++ 2010 上测试的结果却是，不论有没有构造函数，new expression都是调用operator new来分配内存，并在此之后，调用默认构造函数逐个初始化它们，而不调用所谓的vec_new()，也许cfront确实离我们有点遥远。 参考：Lippman 的两本书《深度探索C++对象模型》和《C++ Primer》。]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构造、复制、析构语意学]]></title>
    <url>%2Fdevelop%2Fcpp%2F%E6%9E%84%E9%80%A0%E3%80%81%E5%A4%8D%E5%88%B6%E3%80%81%E6%9E%90%E6%9E%84%E8%AF%AD%E6%84%8F%E5%AD%A6.html</url>
    <content type="text"><![CDATA[一种所谓的Plain OI’Data声明形式： 123struct Point &#123; float x,y,z;&#125;; 概念上来讲，对于一段这样的C++代码,编译器会为之合成一个默认构造函数、复制构造函数、析构函数、赋值操作符。然而实际上编译器会分析这段代码，并给Point贴上Plain OI’Data标签。编译器在此后对于Point的处理与在C中完全一样,也就是说上述的函数都不会被合成。可见概念上应当由编译器合成的函数，并不一定会合成，编译器只有在必要的时候才会合成它们。由此一来，原本在观念上应该调用这些函数的地方实质上不会调用，而是用其它的方法来完成上面的功能，比方复制控制会用bitwise copy。 对象构造语意学无继承情况下的对象构造：略。 单继承体系下的对象构造对于简单定义的一个对象T object;,很明显它的默认构造函数会被调用（被编译器合成的或用户提供的）。但是一个构造函数究竟做了什么，就显得比较复杂了——编译器给了它很多的隐藏代码。编译器一般会做如下扩充操作^注1： 调用所有虚基类的构造函数，从左到右，从最深到最浅： 如果该类被列于成员初始化列表中，任何明确明确指定的参数，都应该被传递过来。若没有列入成员初始化列表中，虚基类的一个默认构造函数被调用（有的话）。 此外，要保证虚基类的偏移量在执行期可存取，对于使用vbptr来实现虚基类的编译器来说，满足这点要求就是对vbptr的初始化。 然而，只有在类对象代表着“most-derived class”时，这些构造函数才可能会被调用。一些支持这个行为的代码会被放进去^注2（直观点说就是，虚基类的构造由最外层类控制)。 调用所有基类构造函数，依声明顺序： 如果该基类被列入了成员初始化队列，那么所有明确指定的参数，应该被传递过来。 没有列入的话，那么调用其默认构造函数，如果有的话。 如果该基类是第二顺位或之后的基类，this 指针必须被调整。 正确初始化vptr,如果有的话。 调用没有出现在初始化成员列表中的member object的默认构造函数，如果有的话。 记录在成员初始化队列中的数据成员初始化操作以声明的顺序被放进构造函数中。 虚拟继承下的构造抑制有如下继承体系： 根据c++ 语法，Point 的初始化应有most-derived class来施行。也就是说当Vertex3d为most-derived class的时候，应当由它的构造函数来调用Point的构造函数初始化Point子对象，Vertex3d的子对象的构造函数对于Point的调用则应当抑制。如果没有抑制会怎么样?当我们定义Vertex3d cv;时，Vertex3d的构造函数中调用Point的构造函数、而随之调用它的子对象，Point3d和Vertex的构造函数中也调用了Point的构造函数。先不说，对于同一个子对象进行三次初始化是否有效率，更重要的是，这将不可避免的带来错误。由Vertex3d指定的子对象Point的值，会被覆盖掉。 编译器通常使用一个条件变量来表示是否为most-derived class,各构造函数根据这个条件变量来决定是否调用虚基类的构造函数，因此通过控制这个条件变量，就可以抑制非most-derived class调用虚基类的构造函数。当然也有其它的方法来做同样的事。 对象复制语意学设计一个类，并考虑到要以一个对象指定给另一个对象时，有三种选择： 什么都不做，采用编译器提供默认行为（bitwise copy或者由编译器合成一个）。 自己提供一个赋值运算符操作。 明确拒绝将一个对象指定给另一个对象。 对于第三点，只要将赋值操作符声明为private，且不定义它就可以了。对于第二点，只有在第一点的行为不安全或不正确，或你特别想往其中插入点东西的时候。 以下四种情况 copy assignment operator(还是用它的英文名，感觉顺畅点)，不具有bitwise copy语意，也就是说这些情况下，编译器要合成copy assignmentoperator而不能依靠bitwise copy来完成赋值操作，这四种情况与构造函数、拷贝构造函数的情况类似，原因可以参考它们的。四种情况如下： 类包含有定义了copy assignment operator的class object成员。 类的基类有copy assignment operator。 类声明有任何虚函数的时候（问题同样会出现在由继承类对象向基类对象拷贝的时候）。 当class继承体系中有虚基类时。 在虚拟继承情况下，copy assignment opertator会遇到一个不可避免的问题，virtual base class subobject的复制行为会发生多次，与前面说到的在虚拟继承情况下虚基类被构造多次是一个意思，不同的是在这里不能抑制非most-derivedclass 对virtual base class 的赋值行为。 安全的做法是把虚基类的赋值放在最后，避免被覆盖。 对象析构语意学只有在基类拥有析构函数，或者object member拥有析构函数的时候，编译器才为类合成析构函数，否则都被视为不需要。 析构的顺序正好与构造相反： 本身的析构函数被执行。 以声明的相反顺序调用member object 的析构函数，如果有的话。 重设vptr 指向适当的基类的虚函数表，如果有的话。 以声明相反的顺序调用上一层的析构函数，如果有的话。 如果当前类是 most-derivedclass，那么以构造的相反顺序调用虚基类的析构函数。 “在此之前”的叙述并不适合我，我喜欢很直白的方式，按顺序来。书中的方 式在于，从最浅显的步骤入手，然后告诉你，做这步之前，你还该做点什么。 所以，我以对原文的理解写下这点。Lippman的原文为： These constructors, however, may be invoked if, and only if, the classobject represents the “most-derived class.” Some mechanism supportingthis must be put into place. 侯捷的译文为： 如果class object是最底层（most-derived）的class,其constructors可能被调用；某些用以支持这个行为的机制必须被放进来。 我认为，Lippman在这一句上要说的是，虚基类的构造函数只能由most-derived class调用，而为了支持这一机制，需要插入一些代码来抑制非most-derived class对虚基类构造函数的调用。同时说一点，5.4的标题个人以为应该译为“对象的效率”而非“对象的功能”——原标题为：Object Efficency。]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[几点类设计原则]]></title>
    <url>%2Fdevelop%2Fcpp%2F%E5%87%A0%E7%82%B9%E7%B1%BB%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99.html</url>
    <content type="text"><![CDATA[1.即使是一个抽象基类，如果它有非静态数据成员，也应该给它提供一个带参数的构造函数，来初始化它的数据成员。或许你可以通过其派生类来初始化它的数据成员（假如nostatic data member为publish或protected）,但这样做的后果则是破坏了数据的封装性，使类的维护和修改更加困难。由此引申，类的data member应当被初始化，且只在其构造函数或其member function中初始化。 2.不要将析构函数设计为纯虚的，这不是一个好的设计。将析构函数设计为纯虚函数意味着，即使纯虚函数在语法上允许我们只声明而不定义纯虚函数，但还是必须实现该纯虚析构函数，否则它所有的继承类都将遇到链接错误。一个不能派生继承类的抽象类有什么存在的意义？必须定义纯虚析构函数，而不能仅仅声明它的原因在于：每一个继承类的析构函数会被编译器加以扩展，以静态调用方式其每一个基类的析构函数（假如有的话，不论是显示的还是编译器合成的），所以只要任何一个基类的析构函数缺乏定义，就会导致链接失败。矛盾就在这里，纯虚函数的语法，允许只声明而不定义纯虚析构函数，而编译器则死脑筋的看到一个其基类的析构函数声明，则去调用它的实体，而不管它有没有被定义。 3.真的必要的时候才使用虚函数，不要滥用虚函数。虚函数意味着不小的成本，编译很可能给你的类带来膨胀效应： 每一个对象要多负担一个word的vptr。 给每一个构造函数（不论是显示的还是编译器合成的），插入一些代码来初始化vptr，这些代码必须被放在所有基类构造函数的调用之后，但需在任意用户代码之前。没有构造函数则需要合成，并插入代码。 合成一个拷贝构造函数和一个复制操作符（如果没有的话），并插入对vptr的初始化代码，有的话也需要插入vptr的初始化代码。 意味着，如果具有bitwise语意，将不再具有，然后是变大的对象、没有那么高效的构造函数，没有那么高效的复制控制。 4.不能决定一个虚函数是否需要 const ，那么就不要它。 5.决不在构造函数或析构函数中使用虚函数机制。在构造函数中，每次调用虚函数会被决议为当前构造函数所对应类的虚函数实体，虚函数机制并不起作用。当一个base类的构造函数含有对虚函数vf()的调用，当其派生类derived的构造函数调用基类base的构造函数的时候，其中调用的虚函数vf()是base中的实体，而不是derived中的实体。这是由vptr初始化的位置决定的——在所有基类构造函数调用之后，在程序员供应的代码或是成员初始化队列之前。因构造函数的调用顺序是：有根源到末端，由内而外，所以对象的构造过程可以看成是，从构建一个最基础的对象开始，一步步构建成一个目标对象。析构函数则有着与构造相反的顺序，因此在构造或析构函数中使用虚函数机制，往往不是程序员的意图。若要在构造函数或析构函数中调用虚函数，应当直接以静态方式调用，而不要通过虚函数机制。]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++之虚函数(Virtual Member Functions)]]></title>
    <url>%2Fdevelop%2Fcpp%2Fc%E4%B9%8B%E8%99%9A%E5%87%BD%E6%95%B0virtual-member-functions.html</url>
    <content type="text"><![CDATA[《深度探索C++对象模型》是这样来说多态的: 在C++中,多态表示“以一个public baseclass的指针（或引用），寻址出一个derived class object”的意思。 消极多态与积极多态用基类指针来寻址继承类的对象，我们可以这样： 1Point ptr=new Point3d; //Point3d继承自Point 在这种情况下，多态可以在编译期完成（虚基类情况除外），因此被称作消极多态（没有进行虚函数的调用）。相对于消极多态，则有积极多态——指向的对象类型需要在执行期在能决定^注1。积极多态的例子如虚函数和RTTI： 12345//例1，虚函数的调用ptr-&gt;z();//例2，RTTI 的应用if(Point3d *p=dynamic_cast&lt;Point3d*&gt;(ptr) ) return p-&gt;z(); 关于RTTI的笔记可见笔记EH &amp; RTTI。本文主要精力将集中于虚函数上。对于一个如上例关于虚函数的调用，要如何来保证在执行期调用的是正确的z()实体——Point3d::z()而不是调用了Point::z()。来看看虚函数的实现机制吧，它将保证这一点。 单继承下的虚函数虚函数的实现： 为每个有虚函数的类配一张虚函数表，它存储该类类型信息和所有虚函数执行期的地址。 为每个有虚函数的类插入一个指针（vptr）,这个指针指向该类的虚函数表。 给每一个虚函数指派一个在表中的索引。 用这种模型来实现虚函数得益于在C++中,虚函数的地址在编译期是可知的，而且这一地址是固定不变的。而且表的大小不会在执行期增大或减小。 一个类的虚函数表中存储有类型信息（存储在索引为0的位置）和所有虚函数地址，这些虚函数地址包括三种： 这个类定义的虚函数，会改写（overriding）一个可能存在的基类的虚函数实体——假如基类也定义有这个虚函数。 继承自基类的虚函数实体，——基类定义有，而这个类却没有定义。直接继承之。 一个纯虚函数实体。用来在虚函数表中占座，有时候也可以当做执行期异常处理函数。 每一个虚函数都被指派一个固定的索引值，这个索引值在整个继承体系中保持前后关联，例如,假如z()在Point虚函数表中的索引值为2，那么在Point3d虚函数表中的索引值也为2。 当一个类单继承自有虚函数的基类的时候，将按如下步骤构建虚函数表： 继承基类中声明的虚函数——这些虚函数的实体地址被拷贝到继承类中的虚函数表中对于的slot中。 如果有改写（override）基类的虚函数，那么在1中应将改写（override）的函数实体的地址放入对应的slot中而不是拷贝基类的。 如果有定义新的虚函数，那么将虚函数表扩大一个slot以存放新的函数实体地址。 我们假设z()函数在Point虚函数表中的索引为4，回到最初的问题——要如何来保证在执行期调用的是正确的z()实体？其中微妙在于，编译将做一个小小的转换: 123ptr-&gt;z();//被编译器转化为：(*ptr-&gt;vptr[4])(ptr); 这个转换保证了调用到正确的实体，因为： 虽然我们不知道ptr所指的真正类型,但它可以通过vptr找到正确类型的虚函数表。 在整个继承体系中z()的地址总是被放在slot 4。 多重继承下的虚函数在多重继承下，继承类需要为每一条继承线路维护一个虚函数表（也有可能这些表被合成为一个，但本质意义并没有变化）。当然这一切都发生在需要的情况下。 当使用第一继承的基类指针来调用继承类的虚函数的时候，与单继承的情况没有什么异样，问题出生在当以第二或后继的基类指针（或引用）的使用上。例如： 12345//假设有这样的继承关系：class Derived:public base1,public base2;//base1,base2都定义有虚析构函数。base2 *ptr = new derived;//需要被转换为，这个转换在编译期完成base2 *ptr = temp ? temp + sizeof(base1) : 0 ; 如果不做出上面的转换，那么 ptr 指向的并不是 derived 的 base2 subobject。后果是，ptr 将一个derived类型当做base2类型来用。 当要delete ptr时又面临了一次转换，因为在delete ptr的时候，需要对整个对象而不是其子对象施行delete运算符，这期间需要调整ptr指向完整的对象起点，因为不论是调用正确的析构函数还是delete运算符都需要一个指向对象起点的指针，想一想给予一个derived类的成员函数指向base2 subobjuect 的this指针会发生什么吧。因为ptr的具体类型并不知道，所以必须要等到执行期来完成。 Bjame的解决方法是将每一个虚函数表的slot扩展，以使之存放一个额外的偏移量。于是虚函数的调用： 123(*ptr-&gt;vptr[1])(ptr);//将变成：(*ptr-&gt;vptr[1].addr)(ptr+*ptr-&gt;vptr[1].offset); 其中使用ptr-&gt;vptr[1].addr用以获取正确的虚函数地址，而ptr+*ptr-&gt;vptr[1].offset来获得指向对象完整的起点。这种方法的缺点显而易见，代价过大了一点，所有的情况都被这一种占比较小的情况拖累。 还有一种叫做thunk的方法，thunk的作用在于: 以适当的offset值来this调整指针. 跳到虚函数中去。 Thunk技术即是：虚函数表中的slot仍然继续放一个虚函数实体地址，但是如果调用这个虚函数需要进行this调整的话,该slot中的地址就指向一个Thunk而不是一个虚函数实体的地址。 书中纷杂的讲到不少中种情况，但我以我的理解，做如下小结： 多继承下的虚函数，影响到虚函数的调用的实际质上为this的调整。而this调整一般为两种： 调整指针指向对应的subobject，一般发生在继承类类型指针向基类类型指针赋值的情况下。 将指向subobject的指针调整回继承类对象的起始点，一般发生在基类指针对继承类虚函数进行调用的时候。 第一点，使得该基类指针指向一个与其指针类型匹配的子对象，唯有如此才能保证使得该指针在执行与其指针类型相匹配的特定行为的正确性。比方调用基类的成员，获得正确的虚函数地址。可以想象如果不调整，用ptr存取base2 subobject的数据成员时，会发生什么？调用base2的成员函数的时候，其成员函数接受的this指针指向derived类型对象，这又会发生什么？结果是整个对象的内存结构有可能都被破坏。还有别忘了，vptr也可以看做一个数据成员，要找到虚函数，前提是获取正确的vptr偏移量。 而第二点，显然是让一个继承类的虚函数获取一个正确的this指针，因为一个继承类虚函数要的是一个指向继承类对象的this指针，而不是指向其子对象。 第一顺序继承类之所以不需要进行调整的关键在于，其subobject的起点与继承类对象的起点一致。 虚拟继承下的虚函数Lippman说，如果一个虚基类派生自另一虚基类，而且它们都支持虚函数和非静态数据成员的时候，编译器对虚基类的支持就像迷宫一样复杂。其实我原想告诉他，我是怀着一颗勇士之心而来的。 虽然书中没有介绍太多，但不难猜测的是在虚继承情况下，复杂点在仍旧在于this指针的调整，然而其复杂度显然又在多继承之上，因为又多了一个vbptr了。]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++之成员函数调用]]></title>
    <url>%2Fdevelop%2Fcpp%2Fc%E4%B9%8B%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8.html</url>
    <content type="text"><![CDATA[c++支持三种类型的成员函数，分别为static,nostatic,virtual。每一种调用方式都不尽相同。 非静态成员函数（Nonstatic Member Functions）保证nostatic member function至少必须和一般的nonmember function有相同的效率是C++的设计准则之一。事实上在c++中非静态成员函数（nostatic member function）与普通函数的调用也确实具有相同的效率，因为本质上非静态成员函数就如同一个普通函数,如一个非静态成员函数Xfloat Point::X();就相当于一个普通函数float X(Point* this);。编译器内部会将成员函数等价转换为非成员函数，具体是这样做的: 1.改写成员函数的签名，使得其可以接受一个额外参数，这个额外参数即是this指针： 123float Point::X();//成员函数X被插入额外参数thisfloat Point:: X(Point* this ); 当然如果成员函数是const的，插入的参数类型将为 const Point* 类型。 2.将每一个对非静态数据成员的操作都改写为经过this操作。 3.将成员函数写成一个外部函数，对函数名进行“mangling”处理，使之成为独一无二的名称。 可以看出，将一个成员函数改写成一个外部函数的关键在于两点，一是给函数提供一个可以直接读写成员数据的通道；二是解决好有可能带来的名字冲突。第一点通过给函数提供一个额外的指针参数来解决，第二点则是通过一定的规则将名字转换，使之独一无二。 由此可以做出一点总结：一个成员函数实际上就是一个被插入了一个接受其类的指针类型的额外参数的非成员函数，当然还要额外对函数的名称进行处理。额外插入的参数用来访问数据成员，而名称的特殊处理用来避免名字冲突。 对于名称的特殊处理并没有统一的标准，各大编译器厂商可能有不同的处理规则。在VC下上述的成员函数X()的名称X处理后就成了?X@Point@@QAEMXZ更多信息可以参见维基百科的Visual C++名字修饰。 于是在VC中对于上面的例子中的成员函数的调用将发生如下的转换： 1234//p-&gt;X();被转化为?X@Point@@QAEMXZ(p);//obj.X();被转化为?X@Point@@QAEMXZ(&amp;obj); 虚拟成员函数(Virtual Member Functions)如果function()是一个虚拟函数，那么用指针或引用进行的调用将发生一点特别的转换——一个中间层被引入进来。例如： 123// p-&gt;function()//将转化为(*p-&gt;vptr[1])(p); 其中vptr为指向虚函数表的指针，它由编译器产生。vptr也要进行名字处理，因为一个继承体系可能有多个vptr。 1是虚函数在虚函数表中的索引，通过它关联到虚函数function(). 何时发生这种转换？答案是在必需的时候——一个再熟悉不过的答案。当通过指针调用的时候，要调用的函数实体无法在编译期决定，必需待到执行期才能获得，所以上面引入一个间接层的转换必不可少。但是当我们通过对象（不是引用，也不是指针）来调用的时候，进行上面的转换就显得多余了，因为在编译器要调用的函数实体已经被决定。此时调用发生的转换，与一个非静态成员函数(Nonstatic Member Functions)调用发生的转换一致。 静态成员函数(Static Member Functions)静态成员函数的一些特性： 不能够直接存取其类中的非静态成员（nostatic members），包括不能调用非静态成员函数(Nonstatic Member Functions)。 不能够声明为 const、voliatile或virtual。 它不需经由对象调用，当然，通过对象调用也被允许。 除了缺乏一个this指针他与非静态成员函数没有太大的差别。在这里通过对象调用和通过指针或引用调用，将被转化为同样的调用代码。 需要注意的是通过一个表达式或函数对静态成员函数进行调用，被C++ Standard要求对表达式进行求值。如： 1(a+=b).static_fuc(); 虽然省去对a+b求值对于static_fuc()的调用并没有影响，但是程序员肯定会认为表达式a+=b已经执行，一旦编译器为了效率省去了这一步，很难说会浪费多少程序员多少时间。这无疑是一个明智的规定。]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++对象的数据成员]]></title>
    <url>%2Fdevelop%2Fcpp%2Fc%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%95%B0%E6%8D%AE%E6%88%90%E5%91%98.html</url>
    <content type="text"><![CDATA[数据成员的布局对于一个类来说它的对象中只存放非静态的数据成员,但是除此之外，编译器为了实现virtual功能还会合成一些其它成员插入到对象中。我们来看看这些成员的布局。 C++ 标准的规定 在同一个Access Section（也就是private,public,protected片段）中，要求较晚出现的数据成员处在较大的内存中。这意味着同一个片段中的数据成员并不需要紧密相连，编译器所做的成员对齐就是一个例子。 允许编译器将多个Acess Section的顺序自由排列，而不必在乎它们的声明次序。但似乎没有编译器这样做。 对于继承类，C++标准并未指定是其基类成员在前还是自己的成员在前。 对于虚基类成员也是同样的未予规定。 一般的编译器怎么做？ 同一个Access Section中的数据成员按期声明顺序，依次排列。但成员与成员之间因为内存对齐的原因可能存在空当。 多个Access Section按其声明顺序排放。 基类的数据成员总放在自己的数据成员之前，但虚基类除外。 编译器合成的成员放在哪？为了实现虚函数和虚拟继承两个功能，编译器一般会合成Vptr和Vbptr两个指针。那么这两个指针应该放在什么位置？C++标准肯定是不曾规定的，因为它甚至并没有规定如何来实现这两个功能，因此就语言层面来看是不存在这两个指针的。 对于Vptr来说有的编译器将它放在末尾，如Lippman领导开发的Cfront。有的则将其放在最前面，如MS的VC，但似乎没人将它放在中间。为什么不放在中间？没有理由可以让人这么做，放在末尾，可以保持C++类对C的struct的良好兼容性，放在最前可以给多重继承下的指针或引用调用虚函数带来好处。 看一小段代码： 123456789101112class X&#123;public: int a; virtual void vfc()&#123;&#125;;&#125;;int main()&#123; using namespace std; X x; cout&lt;&lt;&amp;x.a&lt;&lt;" "&lt;&lt;&amp;x&lt;&lt;endl; system("pause");&#125; 在VS2010和VC6.0中运行的结果都是地址值&amp;x.a比&amp;x大4，可见说vc的vptr放在对象的最前面此言非虚。 对于Vbptr来说，有好几种方法，在这儿我们只看看VC的实现原理： 对于由虚拟继承而得的类，VC会在其每一个对象中插入一个Vbptr,这个Vbptr指向vitual base class table（我称之为虚基类表）。虚基类表中则存放有其虚基类子对象相对于虚基类指针的偏移量。例如声明如class Y:virtual public X的类的virtual base class table的虚基类表中当存储有X对象相对于Vbptr的偏移量。 对象成员或基类对象成员后面的填充空白不能为其它成员所用看一段代码： 123456789class X&#123;public: int x; char c;&#125;;class X2:public X&#123;public:char c2;&#125;; X2的布局应当是x(4),c(1),c2(1),这么说来sizeof(X2)的值应该是8？错了，实际上是12。原因在于X后面的三个字节的填充空白不能为c2所用。也就是说X2的大小实际上为：X(8)+c2(1)+填补（3）=12。这样看来编译器似乎是那么的呆板，其实不然，看一下下面的语句会发生什么？ 123X2 x2;X x;x2=x; 如果X后面的填充空白可以被c2使用的话，那么X2和X都将是8字节。上面的语句执行后x2.c2的值会是多少？一个不确定的值！这样的结果肯定不是我们想要的。 Vptr与Vbptr^注1 在多继承情况下，即使是多虚拟继承，继承而得的类只需维护一个Vbptr；而多继承情况下Vptr则可能有要维护多个Vptr，视其基类有几个有虚函数。 一条继承线路只有一个Vptr，但可能有多个Vbptr，视有几次虚拟继承而定。换言之，对于一个继承类对象来说，不需要新合成vptr，而是使用其基类子对象的vptr。而对于一个虚拟继承类来说，必须新合成一个自己的Vbptr。 如： 1234567891011class X&#123; virtual void vf()&#123;&#125;;&#125;;class X2:virtual public X&#123; virtual void vf()&#123;&#125;;&#125;;class X3:virtual public X2&#123; virtual void vf()&#123;&#125;;&#125; X3将包含有一个Vptr，两个Vbptr。确切的说这两个Vbptr一个属于X3，一个属于X3的子对象X2,X3通过其Vbptr找到子对象X2，而X2通过其Vbptr找到X。 其中差别在于vptr通过一个虚函数表可以确切地知道要调用的函数，而Vbptr通过虚基类表只能够知道其虚基类子对象的偏移量。这两条规则是由虚函数与虚拟继承的实现方式，以及受它们的存取方式和复制控制的要求决定的。 数据成员的存取静态数据成员相当于一个仅对该类可见的全局变量，因为程序中只存在一个静态数据成员的实例，所以其地址在编译时就已经被决定。不论如何静态数据成员的存取不会带来任何额外负担。 非静态数据成员的存取，相当于对象起始地址加上偏移量。效率上与C struct成员的效率等同。因为它的偏移量在编译阶段已经确定。但有一种情况例外：pt-&gt;x=0.0。当通过指针或引用来存取——x而x又是虚基类的成员的时候。因为必须要等到执行期才能知道pt指向的确切类型，所以必须通过一个间接导引才能完成。 小结在VC中数据成员的布局顺序为： vptr部分（如果基类有，则继承基类的） vbptr （如果需要） 基类成员（按声明顺序） 自身数据成员 虚基类数据成员（按声明顺序） 参考：《深度探索C++对象模型》]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>Inside The C++ Object Model</tag>
        <tag>data object</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VC内存对齐准则（Memory alignment）]]></title>
    <url>%2Fdevelop%2Fcpp%2Fvc%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90%E5%87%86%E5%88%99%EF%BC%88memory-alignment%EF%BC%89.html</url>
    <content type="text"><![CDATA[本文所有内容在建立在一个前提下：使用VC编译器。着重点在于：VC的内存对齐准则；同样的数据，不同的排列有不同的大小，另外在有虚函数或虚拟继承情况下又有如何影响？ 内存对齐？！What？Why?对于一台32位的机器来说如何才能发挥它的最佳存取效率呢？当然是每次都读4字节（32bit）,这样才可以让它的bus处于最高效率。实际上它也是这么做的，即使你只需要一个字节，它也是读一个机器字长（这儿是32bit）。更重要的是，有的机器在存取或存储数据的时候它要求数据必须是对齐的，何谓对齐？它要求数据的地址从4的倍数开始，如若不然，它就报错。还有的机器它虽然不报错，但对于一个类似int变量，假如它横跨一个边界的两端，那么它将要进行两次读取才能获得这个int值。比方它存储在地址为2~5的四个字节中，那么要读取这个int，将要进行两次读取，第一次读取0~3四个字节，第二次读取4~7四个字节。但是如果我们把这个整形的起始地址调整到0,4,8…呢？一次存取就够了！这种调整就是内存对齐了。我们也可以依次类推到16位或64位的机器上。 边界该如何调整对于32位的机器来说，它当然最渴望它的数据的大小都是4 Byte或者4的倍数Byte，这样它就能最有效率的存取数据，当然如果数据小于4Byte,那也是没问题的。那么编译器要做的便是尽量满足这个要求。 这两天我断续对VC做了一些实验，并总结如下三条准则，你要明白的是这并非来自微软的官方文档，但我自以为这些准则或许不全但应该都是正确的： 变量存放的起始位置^注2应为变量的大小与规定对齐量[^注1]中较小者的倍数。例如，假设规定对齐量为4，那么char（1byte）变量应该存储在偏移量为1的倍数的地方，而整形变量（4byte）则是从偏移量为4的倍数的地方，而double（8 byte）也同样应存储在偏移量为4的倍数的地方，为什么不是8？因为规定对齐量默认值为4，而4 &lt; 8。在VC中默认对齐量为8，而非4。 结构体整体的大小也应该对齐，对齐依照规定对齐量与最大数据成员两者中较小的进行。 Vptr影响对齐而VbcPoint(Virtual base class pointer)不影响。 一个实例对于类T： 12345class T &#123; char c; int i; double d;&#125; 将其sizeof输出后的大小为16，其内存布局如图T.变量c从偏移量为0开始存储，而整形i第一个符号条件的偏移量为4，double型d的第一个符号条件的为8。整个对象的大小为16，不需要再进行额外的对齐。 图T（类T 的内存布局） : 同样的数据，不同的大小再看类L,它与T存储同样类型的数据，仅仅是顺序不同罢了，那么它sizeof输出的大小是多少呢? 类L: 12345class L &#123; char c; double d; int i;&#125; 它sizeof后的结果或许会令你大吃一惊，或许不会（如果你有认真读前面的两条准则）。Lsizeof后的结果是24！同样是一个int，一个char，一个double却整整多出了8个字节。这期间发生了什么？我们依据前面两条规则来看看。C存储于0的位置，1~7都不能整除8，所以d存储在8~15，16给i正好合适，i存储在16~19。总共花费了20个字节，抱歉不是8的倍数，还得补齐4个。现在你可以看看图L的关于类L的内存布局，再比较一下类L和类T的内存布局。 图L(类L的布局) 我得出了这样一条并不权威的结论，因为我还没听有人这样说过：在声明数据成员的时候，将最大字节数的变量放在最前面[^注3],切忌不要将大小差距很大的类型交替声明。 Vptr影响对齐而VbcPoint(Virtual base class pointer)不影响前面的实例只涉及前两条准则，现在我们来看看第三条的两个实例： 12class X&#123;char a;&#125;;class Y: virtual public X&#123;&#125;; Y的大小为:a占一个字节，VbcPoint（我称他为虚基类指针）占四个字节。我们不论a与VbcPoint的位置如何摆放，如果将VbcPoint等同于一个成员数据来看的话，sizeof(Y)都应该为8.实际上它是5！就我目前的水平，我只能先将其解释为VbcPoint不参与对齐。 对于vptr这个问题则不存在： 123class X&#123; char a; virtual int vfc()&#123;&#125;;&#125; sizeof（X）的大小确实为8. 关于#pragma pack(n)用#pragma pack(n)改变规定对齐量试试。 [^注1]: 规定对齐量：实际上并没有这么一个名词，是我为了方便而造出来的。在VC中这个“规定对齐量”会有一个默认值，这个默认值一般为8，我原来一直以为这个值以为是4，至于它为什么为8，我现在还不知道。。我们也可以通过#pargma pack(n)来规定这个值，目前n可以为1,2,4,8,16。 [^注3]: 此处有一点问题，这个问题由独酌逸醉提出，他认为将最小的数据放在最前面可能会更好，我们有进行过讨论，但可惜的是由于在2011/11/24日数据库丢失，我只能用备份还原，所以丢失了一些数据，无疑，本文的评论也在其中。不过我对这个问题映像深刻，因为我在写这篇博客的时候便困惑于到底成员是应该放在之前还是之后，因为这两种情况我都找不到强有力的理由来支撑它们。后来使我确信从大到小排列好于从小到大排列的理由在于，从大到小排列一般无需成员之间的对齐，唯一的对齐工作是最后进行的整个结构体对齐的工作。毫无疑问的是，这应该是最节省内存的方式。再之后，独酌提出从小到大可能好些，虽然没有给出有说服力的理由，但却使我无比困惑，我当时虽然认为从大到小的排列更有优势，但却实在想不出一个实例能使得它优于从小到大排列的。不过最终我击垮了自己的理由，在继承状况下从大到小排列很容易被打破，比方，基类的成员为一个char,继承类的成员为double,int,char虽然基类和继承类都是按从大到小的顺序排列的，但是继承类的内存布局最终会使char,double,int,char，此时既不能避免成员对齐，又导致后面的结构体对齐。暂时获得的最终结果是从小到大排列是更好的一种排列方式。（2011/12/31增补）]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
        <tag>Memory alignment</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++类对象的大小]]></title>
    <url>%2Fdevelop%2Fcpp%2Fc%E7%B1%BB%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%A4%A7%E5%B0%8F.html</url>
    <content type="text"><![CDATA[一个实例引出的思考1234class X&#123;&#125;;class Y:virtual public X&#123;&#125;;class Z:virtual public X&#123;&#125;;class A:public Y, public Z&#123;&#125;; 猜猜sizeof上面各个类都为多少？ Lippman的一个法国读者的结果是： sizeof X yielded 1 sizeof Y yielded 8 sizeof Z yielded 8 sizeof A yielded 12 我在vs2010上的结果是： sizeof X yielded 1 sizeof Y yielded 4 sizeof Z yielded 4 sizeof Z yielded 8 当我们对于C++对象的内存布局知之甚少的情况下，想搞清这些奇怪现象的缘由将是一件非常困难的事情。不过下文会为你一一解惑。 事实上，对于像X这样的一个的空类，编译器会对其动点手脚——隐晦的插入一个字节。为什么要这样做呢？插入了这一个字节，那么X的每一个对象都将有一个独一无二的地址。如果不插入这一个字节呢？哼哼，那对X的对象取地址的结果是什么？两个不同的X对象间地址的比较怎么办？ 我们再来看Y和Z。首先我们要明白的是实现虚继承，将要带来一些额外的负担——额外需要一个某种形式的指针。到目前为止，对于一个32位的机器来说Y、Z的大小应该为5，而不是8或者4。我们需要再考虑两点因素：内存对齐（alignment—）和编译器的优化。 alignment[^注1]会将数值调整到某数的整数倍，32位计算机上位4bytes。内存对齐可以使得总线的运输量达到最高效率。所以Y、Z的大小被补齐到8就不足为奇了。 那么在vs2010中为什么Y、Z的大小是4而不是8呢？我们先思考一个问题，X之所以被插入1字节是因为本身为空，需要这一个字节为其在内存中给它占领一个独一无二的地址。但是当这一字节被继承到Y、Z后呢？它已经完全失去了它存在的意义，为什么？因为Y、Z各自拥有一个虚基类指针，它们的大小不是0。既然这一字节在Y、Z中毫无意义，那么就没必要留着。也就是说vs2010对它们进行了优化，优化的结果是去掉了那一个字节,而Lippman的法国读者的编译器显然没有做到这一点。 当我们现在再来看A的时候，一切就不是问题了。对于那位Lippman的法国读者来说，A的大小是共享的X实体1字节,X和Y的大小分别减去虚基类带来的内存空间，都是4。A的总计大小为9，alignment以后就是12了。而对于vs2010来说，那个一字节被优化后，A的大小为8，也不需再进行alignment操作。 总结影响C++类的大小的三个因素： 支持特殊功能所带来的额外负担（对各种virtual的支持）。 编译器对特殊情况的优化处理。 alignment操作，即内存对齐。 [^注1]: 关于更多的memory alignment（内存对齐）的知识见VC内存对齐准则（Memory alignment）]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[命名返回值优化和成员初始化队列]]></title>
    <url>%2Fdevelop%2Fcpp%2F%E5%91%BD%E5%90%8D%E8%BF%94%E5%9B%9E%E5%80%BC%E4%BC%98%E5%8C%96%E5%92%8C%E6%88%90%E5%91%98%E5%88%9D%E5%A7%8B%E5%8C%96%E9%98%9F%E5%88%97.html</url>
    <content type="text"><![CDATA[命名返回值优化对于一个如foo()这样的函数，它的每一个返回分支都返回相同的对象，编译器有可能对其做Named return Value优化（下文都简称NRV优化），方法是以一个参数result取代返回对象。 foo()的原型： 12345678X foo() &#123; X xx; if(...) returnxx; else returnxx; &#125; 优化后的foo()以result取代xx： 1234567891011121314void foo(X &amp;result)&#123; result.X::X(); if(...) &#123; //直接处理result return; &#125; else &#123; //直接处理result return; &#125;&#125; 对比优化前与优化后的代码可以看出，对于一句类似于X a = foo()这样的代码，NRV优化后的代码相较于原代码节省了一个临时对象的空间（省略了xx）,同时减少了两次函数调用（减少xx对象的默认构造函数和析构函数，以及一次拷贝构造函数的调用，增加了一次对a的默认构造函数的调用）。 注：Lippman在《深度探索C++》书中指出NRV的开启与关闭取决于是否有显式定义一个拷贝构造函数，我实在想不出有什么理由必须要有显示拷贝构造函数才能开启NRV优化，于是在vs2010中进行了测试，测试结果表明，在release版本中，不论是否定义了一个显式拷贝构造函数，NRV都会开启。由此可见vs2010并不以是否有一个显式拷贝构造函数来决定NRV优化的开启与否。但同时，立足于这一点，可以得出Lippman所说的以是否有一个显式定义的拷贝构造函数来决定是否开启NRV优化，应该指的是他自己领导实现的cfront编译器，而非泛指所有编译器。那么cfront又为什么要以是否定义有显示的拷贝构造函数来决定是否开启NRV优化呢？我猜测，他大概这样以为，当显式定义有拷贝构造函数的时候一般代表着要进行深拷贝，也就是说此时的拷贝构造函数将费时较长，在这样的情况下NRV优化才会有明显的效果。反之，不开启NRV优化也不是什么大的效率损失。 另外，有一点要注意的是，NRV优化，有可能带来程序员并不想要的结果，最明显的一个就是——当你的类依赖于构造函数或拷贝构造函数，甚至析构函数的调用次数的时候，想想那会发生什么。由此可见、Lippman的cfront对NRV优化抱有更谨慎的态度，而MS显然是更大胆。 成员初始化队列（Member Initialization List）对于初始化队列，我相信厘清一个概念是非常重要的：在构造函数中对于对象成员的初始化发生在初始化队列中——或者我们可以把初始化队列直接看做是对成员的定义，而构造函数体中进行的则是赋值操作。所以不难理解有四种情况必须用到初始化列表： 有const成员 有引用类型成员 成员对象没有默认构造函数 基类对象没有默认构造函数 前两者因为要求定义时初始化，所以必须明确的在初始化队列中给它们提供初值。后两者因为不提供默认构造函数，所有必须显示的调用它们的带参构造函数来定义即初始化它们。 显而易见的是当类中含有对象成员或者继承自基类的时候，在初始化队列中初始化成员对象和基类子对象会在效率上得到提升——省去了一些赋值操作嘛。 最后，一个关于初始化队列众所周知的陷阱，初始化队列的顺序，请参考《C++primer》或者《深度探索C++对象模型》。]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拷贝构造函数（copy constuctor）]]></title>
    <url>%2Fdevelop%2Fcpp%2F%E6%8B%B7%E8%B4%9D%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%EF%BC%88copy-constuctor%EF%BC%89.html</url>
    <content type="text"><![CDATA[拷贝构造函数（copy constuctor）通常C++初级程序员会认为当一个类为没有定义拷贝构造函数的时候，编译器会为其合成一个，答案是否定的。编译器只有在必要的时候在合成拷贝构造函数。那么编译器什么时候合成，什么时候不合成，合成的拷贝构造函数在不同情况下分别如何工作呢？这是本文的重点。 拷贝构造函数的定义有一个参数的类型是其类类型的构造函数是为拷贝构造函数。如下： 123X::X( const X&amp; x);Y::Y( const Y&amp; y, int =0 );//可以是多参数形式，但其第二个即后继参数都有一个默认值 拷贝构造函数的应用当一个类对象以另一个同类实体作为初值时，大部分情况下会调用拷贝构造函数。一般是这三种具体情况： 显式地以一个类对象作为另一个类对象的初值，形如X xx=x; 当类对象被作为参数交给函数时。 当函数返回一个类对象时。 后两种情形会产生一个临时对象。 编译器何时合成拷贝构造函数并不是所有未定义有拷贝构造函数的类编译器都会为其合成拷贝构造函数，编译器只有在必要的时候才会为其合成拷贝构造函数。所谓必要的时刻是指编译器在普通手段无法完成解决“当一个类对象以另一个同类实体作为初值”时，才会合成拷贝构造函数。也就是说，当常规武器能解决问题的时候，就没必要动用非常规武器。 如果一个类没有定义拷贝构造函数，通常按照“成员逐一初始化(DefaultMemberwise Initialization)”的手法来解决“一个类对象以另一个同类实体作为初值”——也就是说把内建或派生的数据成员从某一个对象拷贝到另一个对象身上，如果数据成员是一个对象，则递归使用“成员逐一初始化(Default MemberwiseInitialization)”的手法。 成员逐一初始化(Default Memberwise Initialization)具体的实现方式则是位逐次拷贝（Bitwise copy semantics）[^注1]。也就是说在能使用这种常规方式来解决“一个类对象以另一个同类实体作为初值”的时候，编译器是不需要合成拷贝构造函数的。但有些时候常规武器不那么管用，我们就得祭出非常规武器了——拷贝构造函数。有以下几种情况之一，位逐次拷贝将不能胜任或者不适合来完成“一个类对象以另一个同类实体作为初值”的工作。此时，如果类没有定义拷贝构造函数，那么编译器将必须为类合成一个拷贝构造函数。 当类内含一个成员对象，而后者的类声明有一个拷贝构造函数时（不论是设计者定义的还是编译器合成的）。 当类继承自一个声明有拷贝构造函数的类时（同样，不论这个拷贝构造函数是被显示声明还是由编译器合成的）。 类中声明有虚函数。 当类的派生串链中包含有一个或多个虚基类。 对于前两种情况，不论是基类还是对象成员，既然后者声明有拷贝构造函数时，就表明其类的设计者或者编译器希望以其声明的拷贝构造函数来完成“一个类对象以另一个同类实体作为初值”的工作，而设计者或编译器这样做——声明拷贝构造函数，总有它们的理由，而通常最直接的原因莫过于因为他们想要做一些额外的工作或“位逐次拷贝”无法胜任。 对于有虚函数的类，如果两个对象的类型相同那么位逐次拷贝其实是可以胜任的。但问题将出现在，如果基类由其继承类进行初始化时，此时若按照位逐次拷贝来完成这个工作，那么基类的vptr将指向其继承类的虚函数表，这将导致无法预料的后果——调用一个错误的虚函数实体是无法避免的，轻则带来程序崩溃，更糟糕的问题可能是这个错误被隐藏了。所以对于有虚函数的类编译器将会明确的使被初始化的对象的vptr指向正确的虚函数表。因此有虚函数的类没有声明拷贝构造函数，编译将为之合成一个，来完成上述工作，以及初始化各数据成员，声明有拷贝构造函数的话也会被插入完成上述工作的代码。 对于继承串链中有虚基类的情况，问题同样出现在继承类向基类提供初值的情况，此时位逐次拷贝有可能破坏对象中虚基类子对象的位置。 [^注1]: Bitwise copy semantics 是Default Memberwise Intializiation的具体实现方式。也没有在任何地方对这两个名词进行对比或者更多的阐述，这一度使我疑惑，上面只是我个人的理解，你有任何不同的见解，欢迎你与我讨论。(2011/12/22日 补)]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[哈希表的C++模板实现]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E5%93%88%E5%B8%8C%E8%A1%A8%E7%9A%84c%E6%A8%A1%E6%9D%BF%E5%AE%9E%E7%8E%B0.html</url>
    <content type="text"><![CDATA[采用引用计数来解决指针管理问题。开放地址、双重哈希来解决碰撞和探测问题，实现了哈希表的创建、查找、插入，复制控制，[]操作符… 但总觉得欠缺点什么。 源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126//hash.h //2011/11/13 By Adoo#ifndef HASH_H#define HASH_Htemplate&lt;typename type,typename long (*count_key)(type)&gt;class hash&#123;public: hash(std::size_t size, const type empty, const type deleted):_size(size), _ref_count(new std::size_t (1)),table(NULL),_empty(empty),_deleted(deleted) &#123; //get the adjacency prime with the size; do&#123; if(is_prime(_size)) break; else ++_size; &#125;while(true); //allocate the memoey table=new type[_size](); for(std::size_t i=0 ; i!=_size; ++i) &#123; table[i]=_empty; &#125; &#125; ~hash() &#123; decr_cout(); &#125; bool insert(const type&amp; k) &#123;//insert an element k to hash table long a=std::abs(count_key(k)); for(size_t i=0; i!=_size; ++i) &#123; long index=hash_function(count_key(k),i); if(table[index]==_empty || table[index]==_deleted) &#123; table[index]=k; return true; &#125; &#125; return false; &#125; const type&amp; search(const type&amp; k) &#123; long key=std::abs(count_key(k)); for(std::size_t i=0; i!=_size; ++i) &#123; type ty=table[hash_function(key,i)] ; if( ty== k ) return table[hash_function(key,i)] ; if(ty=_empty) break; &#125; return _empty; &#125; hash(const type&amp; t) &#123; ++*t.ref_count; decr_count(); ref_count=t.ref_count; table=t.table; &#125; hash&amp; operator=(const hash&amp; t)&#123; ++*t.ref_count; decr_count(); ref_count=t.ref_count; table=t.table; return *this; &#125; const type&amp; operator[](const type&amp; t)&#123; return search(t); &#125; const hash&amp; operator=(const hash&amp; t) const&#123; ++*t.ref_count; decr_count(); ref_count=t.ref_count; table=t.table; _empty=t._empty; _deleted=t._deleted; return *this; &#125;;private: void decr_cout() &#123; if(!--*_ref_count) &#123; delete _ref_count; delete [] table; &#125; &#125; long hash_function(long key,std::size_t count) &#123; return (key%_size + count* (1 + key%(_size - 1)) % _size); &#125; bool is_prime(std::size_t l) &#123; bool prime=true; std::size_t sqrt=std::sqrtl( l )+1; for(int i=2; i!=sqrt; ++i) &#123; if(l%i ==0 ) &#123; prime=false; break; &#125; &#125; return prime; &#125;private: std::size_t _size; std::size_t *_ref_count; type *table; const type _empty; const type _deleted;&#125;;#endif]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>c++</tag>
        <tag>hash tables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入C++构造函数]]></title>
    <url>%2Fdevelop%2Fcpp%2F%E6%B7%B1%E5%85%A5c%E9%BB%98%E8%AE%A4%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0.html</url>
    <content type="text"><![CDATA[通常很多C++程序员存在两种误解： 没有定义默认构造函数的类都会被编译器生成一个默认构造函数。 编译器生成的默认构造函数会明确初始化类中每一个数据成员。 在读《深度探索C++对象模型》之前，我一直停留在上述二种误解上，所幸的是Lippman为我破除了藩篱。下面的部分我将随《深度探索C++对象模型》对C++默认构造函数一探究竟。 C++标准规定：如果类的设计者并未为类定义任何构造函数，那么会有一个默认构造函数被暗中生成，而这个暗中生成的默认构造函数通常是不做什么事的(无用的)，下面四种情况除外。 换句话说，有以下四种情况编译器必须为未声明构造函数的类生成一个会做点事的默认构造函数。我们会看到这些默认构造函数仅“忠于编译器”，而可能不会按照程序员的意愿程效命。 1.包含有带默认构造函数的对象成员的类若一个类X没有定义任何构造函数，但却包含一个或以上定义有默认构造函数的对象成员，此时编译器会为X合成默认构造函数，该默认函数会调用对象成员的默认构造函数为之初始化。如果对象的成员没有定义默认构造函数，那么编译器合成的默认构造函数将不会为之提供初始化。例如类A包含两个数据成员对象，分别为：string str和char *Cstr，那么编译器生成的默认构造函数将只提供对string类型成员的初始化，而不会提供对char*类型的初始化。 假如类X的设计者为X定义了默认的构造函数来完成对str的初始化，形如：A::A(){Cstr=”hello”};因为默认构造函数已经定义，编译器将不能再生成一个默认构造函数。但是编译器将会扩充程序员定义的默认构造函数——在最前面插入对初始化str的代码。若有多个定义有默认构造函数的成员对象，那么这些成员对象的默认构造函数的调用将依据声明顺序排列。 2.继承自带有默认构造函数的基类的类如果一个没有定义任何构造函数的类派生自带有默认构造函数的基类，那么编译器为它定义的默认构造函数，将按照声明顺序为之依次调用其基类的默认构造函数。若该类没有定义默认构造函数而定义了多个其他构造函数，那么编译器扩充它的所有构造函数——加入必要的基类默认构造函数。另外，编译器会将基类的默认构造函数代码加在对象成员的默认构造函数代码之前。 3.带有虚函数的类带有虚函数的类，与其它类不太一样，因为它多了一个vptr，而vptr的设置是由编译器完成的，因此编译器会为类的每个构造函数添加代码来完成对vptr的初始化。 4.带有一个虚基类的类在这种情况下，编译器要将虚基类在类中的位置准备妥当，提供支持虚基类的机制。也就是说要在所有构造函数中加入实现前述功能的的代码。没有构造函数将合成以完成上述工作。 总结：简单来讲编译器会为构造函数做的一点事就是调用其基类或成员对象的默认构造函数，以及初始化vprt以及准备虚基类的位置。 总的来说，编译器将对构造函数动这些手脚： 如果类虚继承自基类，编译器将在所有构造函数中插入准备虚基类位置的代码和提供支持虚基类机制的代码。 如果类声明有虚函数，那么编译器将为之生成虚函数表以存储虚函数地址，并将虚函数指针（vptr）的初始化代码插入到类的所有构造函数中。 如果类的父类有默认构造函数，编译将会对所有的默认构造函数插入调用其父类必要的默认构造函数。必要是指设计者没有显示初始化其父类，调用顺序，依照其继承时声明顺序。 如果类包含带有默认构造函数的对象成员，那么编译器将会为所有的构造函数插入对这些对象成员的默认构造函数进行必要的调用代码，所谓必要是指类设计者设计的构造函数没有对对象成员进行显式初始化。成员对象默认构造函数的调用顺序，依照其声明顺序。 若类没有定义任何构造函数，编译器会为其合成默认构造函数，再执行上述四点。 【2011/12/21 补】需要说明的是，从概念来上来讲，每一个没有定义构造函数的类都会由编译器来合成一个默认构造函数，以使得可以定义一个该类的对象，但是默认构造函数是否真的会被合成，将视是否有需要而定。C++ standard 将合成的默认构造函数分为 trivial 和 notrivial 两种，前文所述的四种情况对应于notrivial默认构造函数，其它情况都属于trivial。对于一个trivial默认构造函数，编译器的态度是，既然它全无用处，干脆就不合成它。在这儿要厘清的是概念与实现的差别，概念上追求缜密完善，在实现上则追求效率，可以不要的东西就不要。]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++对象面面观]]></title>
    <url>%2Fdevelop%2Fcpp%2Fc%E5%AF%B9%E8%B1%A1%E9%9D%A2%E9%9D%A2%E8%A7%82.html</url>
    <content type="text"><![CDATA[学习C++应该看过不少关于C与C++的口水贴，以及关于各种对比C与C++效率比较的帖子，最有影响力的恐怕当属linus对C++的炮轰——《糟糕程序员的垃圾语言》。但无论如何，我正喜欢着这样一种垃圾，我当然对linus充满敬意，但这不妨碍我口食垃圾而对其仰慕。 无需太在意站在山巅的巨人们的言论，每个人都有不同的道路来追求真理。与其听着Linus的嗤笑之声，不妨跟随Lippman一起探索C++对象模型的“内心世界”。若要对事物褒贬，总得先对其了解。唯有了解才能有负责的发声。 ——仅以此区区百余字为之前记。 C++的额外成本C++较之C的最大区别，无疑在于面向对象。类相较于C的struct不仅只包含了数据，同时还包括了对于数据的操作。在语言层面上C++带来了很多面向对象的新特性，类、继承、多态等等。新特性使得C++更加强大，但同时却伴随着空间布局和存取时间的额外成本。作为一个以效率为目标的语言，C++对于面向对象的实现，其实不大，这些额外成本主要由virtual引起，包括： virtual function 机制，用来支持“执行期绑定”。 virtual base class ——虚基类机制，以实现共享虚基类的 subobject。 除此之外C++没有太多理由比C迟缓。 三种对象模型C++类包含两种数据成员：静态数据成员和非静态数据成员；同时包含成员函数，静态函数和虚函数三种成员函数，这些机制在C++对象是如何被表现的？下面有三种模型可以用以表现它们——简单对象模型、表格驱动对象模型以及C++对象模型。也许你没兴趣去了解有几种方式可以实现C++的对象模型，只想了解C++对象模型。然则，C++对象模型是在前两种对象模型上发展而来的，甚至于局部上直接用到前两种对象模型。 假定有一个Point类，我们将用三种对象模型来表现它。Point类如下: 1234567891011121314class Point &#123; public: Point( float xval ); virtual ~Point(); float x() const; static int PointCount(); protected: virtual ostream&amp; print( ostream &amp;os ) const; float _x; static int _point_count; &#125;; 简单对象模型简单对象模型：一个C++对象存储了所有指向成员的指针，而成员本身不存储在对象中。也就是说不论数据成员还是成员函数，也不论这个是普通成员函数还是虚函数，它们都存储在对象本身之外，同时对象保存指向它们的指针。 简单对象模型对于编译器来说虽然极尽简单,但同时付出的代价是空间和执行期的效率.显而易见的是对于每一个成员都要额外搭上一个指针大小的空间以及对于每成员的操作都增加了一个间接层。因此C++并没有采用这样一种对象模型，但是被用到了C++中“指向成员的指针”的概念当中。 表格驱动对象模型 表格驱动模型则更绝，它将对象中所有的成员都抽离出来在外建表，而对象本身只存储指向这个表的指针。右图可以看到，它将所有的数据成员抽离出来建成数据成员表，将所有的函数抽取出来建成一张函数成员表，而对象本身只保持一个指向数据成员表的指针。 侯大大认为，在对象与成员函数表中间应当加一个虚箭头，他认为这是Lippman的疏漏之处，应当在对象中保存指向函数成员表的指针。 然而我在这儿还是保留原书（而非译本）的截图，因为以我之拙见，不保存指向成员函数表的指针也没有妨碍。因为形如float Point::x()的成员函数实际上相当于float x(Point*)类型的普通函数，因此保存指向成员函数表的指针当属多此一举。 当然C++也没有采用这一种对象模型，但C++却以此模型作为支持虚函数的方案。 C++对象模型所有的非静态数据成员存储在对象本身中。所有的静态数据成员、成员函数（包括静态与非静态）都置于对象之外。另外，用一张虚函数表（virtual table)存储所有指向虚函数的指针，并在表头附加上一个该类的type_info对象，在对象中则保存一个指向虚函数表的指针。如下图： class和struct按照lippman的意思是，struct仅仅是给想学习C++的C程序员攀上高峰少一点折磨。但遗憾的是当我开始学C++的时候这个问题给我带来更多的疑惑。以我的认识class与struct仅限一个默认的权限（后者为public前者为private）的不同。有时我甚至觉得只有一点畸形，他们不应当如此的相像，我甚至认为struct不应该被扩充，仅仅保存它在C中的原意就好了。[^注1] 一个有意思的C技巧（但别在C++中使用）在C中将一个一个元素的数组放在struct的末尾，可以令每个struct的对象拥有可变数组。看代码： 123456789struct mumble &#123; /* stuff */ char pc[ 1 ]; &#125;; // grab a string from file or standard input // allocate memory both for struct &amp; string struct mumble *pmumb1 = ( struct mumble* ) malloc(sizeof(struct mumble)+strlen(string)+1); strcpy( &amp;mumble.pc, string ); 这是一个很有意思的小技巧，但是别在C++中使用。因为C++的内存布局相对复杂。例如被继承，有虚函数… 问题将不可避免的发生。 三种编程典范 程序模型 ADT模型 面向对象模型 纯粹使用一种典范编程，有莫大的好处，如果混杂多种典范编程有可能带来意想不到的后果，例如将继承类的对象赋值给基类对象，而妄想实现多态，便是一种ADT模型和面向对象模型混合编程带来严重后果的例子。 一个类的对象的内存大小包括： 所有非静态数据成员的大小。 由内存对齐而填补的内存大小。 为了支持virtual有内部产生的额外负担。 如下类： 123456789class ZooAnimal &#123; public: ZooAnimal(); virtual ~ZooAnimal(); virtual void rotate(); protected: int loc; String name; &#125;; 在32位计算机上所占内存为16字节：int四字节，String8字节（一个表示长度的整形，一个指向字符串的指针），以及一个指向虚函数表的指针vptr。对于继承类则为基类的内存大小加上本身数据成员的大小。在cfront中其内存布局如下图： [^注1]: 实际上struct还要复杂一点，它有时表现的会和C struct完全一样，有时则会成为class的胞兄弟。]]></content>
      <categories>
        <category>深度探索C++对象模型</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>Inside The C++ Object Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[哈希表（Hash Tables）（2）]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E5%93%88%E5%B8%8C%E8%A1%A8%EF%BC%88hash-tables%EF%BC%89%EF%BC%882%EF%BC%89.html</url>
    <content type="text"><![CDATA[解决碰撞解决碰撞无非两种思路：使得一个位置能存储多个元素，此其一；不限定一个元素只能存储到一个位置，既然要去到地方挤不下，那便换个地方，此其二。下文给出对应两种思路将的两种方法。 用链表解决碰撞既然要使得一个位置能存储多个元素，我们便将要存储到这一位置的多个元素串成链表，并存储链表头，是为链表解决碰撞法。如图： 这个方法简单明了，但是效率方面可能要打折扣，如果碰巧诸君不走运，一组元素全哈希到了一个位置，全被放到一个链表中，查找的效率必然可怜（O(n)）。退一步，只要是哈希的不太平均，那么查找的效率也让人有些难受。 开放地址（Open addressing）解决碰撞开放地址法意味着:所有的元素都被存储在哈希表中,没有链表,没有存储在哈希表之外的元素；更少的内存，更高的内存利用率——开放地址意味着填满哈希表，另外完全逃离了指针，意味着节省了一笔空间，要明白对于一个很大的哈希表来说，如果使用指针（链表）来解决碰撞，意味着存储指针的空间也非常可观；潜在有更快的查找速度，更少的碰撞的可能（当然这只是潜能）。 实现开放地址的插入（叫存储更合适一些吧），首先要连续探查哈希表，直到找到一个为空的位置来放入要插入的数。可想而知这个探查的顺序我们不可能1,2,3,…这样按顺序来探查，这样的话效率怎么可能高的起来，探查的顺序依赖于要插入的Key。把哈希函数扩展到多一个参数——h(key,n)。n表示第n次探查。于是可以有一个序列，来表示要插入的Key k可以放入的位置的顺序：〈h(k,0),h(k,1), …, h(k,m - 1)〉 ——称之为探查序列。 假如函数的选择得当,那么k有机会放到每一个位置，也就是说只要哈希表未满，就可以插入。看一下插入的伪代码： 123456789HASH-INSERT(T, k) i = 0 repeat j = h(k, i) if T[j] == NIL then T[j] = k return j else i = i + 1 until i = m error "hash table overflow" 对于开放地址的查找，很显然按照其探查顺序去查找就可以，直到找到相等的key。伪代码： 12345678HASH-SEARCH(T, k) i = 0 repeat j = h(k, i) if T[j] == k then return j i = i + 1 until T[j] == NIL or i == m return NIL 需要注意的是，对于一个开放地址的哈希表，如果要从中删除一个元素，我们不能简单地将存放该元素的位置设置为NIL(用以表示空)，因为如此一来，所有原来因为该位置被占，而存储到其它位置的元素将不能再找到。例如，有一key为k的元素的探查序列为{1,5,6,2,8,3,…},被存储在位置8，假如我们将存储位置2设置为空，那么在对k进行查找时，我们依次查找1,5,6,2位置，但是因为2为空，程序任务已经查找完成——因为开放地址法总是将元素存储在第一个可以存储的位置的嘛——查找到2终止。要解决这个问题，我们应当将被删除元素的位置设置为“已删除”，而不是“空”。这样我们通过小小修改一下插入程序的代码使之能够在标记为“已删除”的位置插入元素就可以了。 开放地址的三种探查方式线性探查（Linear Probing）线性探查很简单，实际上就是一种遍历的方式来探查可用的位置。哈希函数为：h(k,i) = (h‘(k) + i) mod m 其中h’(k)称为辅助哈希函数。因为第一次探查的位置决定了整个探查顺序，所以所有的key最多只可能有m个探查顺序，可见发生碰撞的概率不小。 线性探查易于实现，但是随着时间的推移，哈希表中被占用的位置越多，连续被占用的位置也越来越多，碰撞的几率会大大提升，查找的平均时间将会大大增加。这种现象叫做primary clustering（主要聚集？应该叫扎堆现象比较合适，暂定将primary clustering翻译为“首要扎堆现象”）。 二次探查（Quadratic probing）二次探查函数形如\(h(h(‘k’) + c{1}i + c{2}i^2) \bmod m\),与一次探查类似，首次探查的位置决定了整个探查的顺序，因此对于所有的key也只可能最多用到m种探查顺序，与一次相比的探查比较的好处在于，它的偏移量不是一个常数，而是由一个二次方程决定，这样很大程度上避免了一次探查的首要扎堆现象，所以把二次探查这种现象称之为次要扎堆现象（secondary clustering）吧。但是要想填满整个哈希表的话，那么在\(c_i, c_2\)的选择上就要斟酌一番了。 双重哈希（Double hashing）注意！CLRS开场便说：双重哈希提供最好的方法之一给开放地址法。其函数形如：\( h(k, i) = (h_1(k) + ih_2(k)) \bmod m \),它有两个辅助函数\( h_i\)和\(h_2\)。双重哈希带来的好处是初始探查位置不能决定整个探查序列，因此双重哈希将能使用到\(O(m^2)\)中探查序列，比之线性探查和二次探查的m种强了很多。但要注意的一点是，要使探查序列能包含整个哈希表，\(h_2\)应当与表的大小m互质。两种使之互质的方法是： 使m为一个质数，\(h_2\)总产生比m小的正整数； 取m为2的幂，而\(h_2\)总产生质数。 完全哈希表完全哈希是指在最坏情况下，内存访问次数为O(1)。完全哈希采用二级结构，每一级上都采用全域散列。其实犹如用链表解决碰撞的哈希表那样，只不过完全哈希不是使用链表而是使用一个小的哈希表来实现，且保证在小的哈希表上不发生碰撞。 关于完全哈希尚有疑惑,不记录太多，以免误人，亦免自误。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>hash tables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[哈希表（1）]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E5%93%88%E5%B8%8C%E8%A1%A8%EF%BC%881%EF%BC%89.html</url>
    <content type="text"><![CDATA[直接寻址表（Direct-address tables）假设有一组元素，每个元素的Key值都包含在范围U={0,1,2,3,…m-1}中。如果这个值m不是太大，且这一组元素的Key值都不相同，我们用key值来直接决定元素或指向元素指针的存储位置（slot,我将其翻译为位置而不是狭缝，槽或…），这就是直接寻址表。如下图： 从左图看到，对于一个元素Key值为2的元素，指向它的指针被存储在下标为2的位置中。key值为3的被存储在小标为三的位置… 你也可以直接将元素存储在直接寻址表中，而不是存储它的指针。这一切视情况而定，比方当元素的附属数据比较多的情况下，我想存储它的指针应该更为合理；反之，存储元素本身应该更易管理。 直接寻指表虽然有逻辑简单，查询存储速度快等优点，但缺点也显而易见：假如U的范围非常大的话，那么建一张这样的直接寻址表的话，不知需内存几何？另外，对于一个U的范围偏大，而实际的元素个数又很少的话，其内存的利用率就令人发指了。再暴力点，直接给它两个key相同的元素呢？ …于是我们就引出了哈希表。 哈希表（Hash tables）与直接寻址表Key为k的元素存储在位置k不同，哈希表让Key为k的元素存储在位置为h(k)的位置。我们将h称为哈希函数，将h(k)称为哈希值。而恰是这么一种规则，使得哈希表的大小往往远远小于U的范围大小。因为我们可以定义一个函数值的范围比较适合的哈希函数嘛。再看一张图： 可以看到上图并非是直接映射，而是按照一定的规则令来映射Key值,这个规则当然就是哈希函数。 不过可以看到，哈希函数同时带来了一个问题，那就是两个或多个不同的Key有可能被映射到同一个位置，我们把这一问题称为碰撞（collision）,下篇文章会给出解决方案。其实左图中已经给出了一种解决方案——用链表来解决。 哈希函数一个好的哈希函数：每一个key都有相等几率哈希到哈希表中m个位置中的一个，独立于任何其它已哈希的Key。但这仅是一种理想情况，难以把握。尽可能的使不同的key哈希到同一个位置。 key的转换，大部分情况下，我们都是用自然数来作为Key,假如我们的key不是自然数，我们将使用某种方法将它转化为自然数。比如如果key=”pt”可以利用它的ASCALL码将其转换为自然数，比方p(112)+t(116)*2=344. 下面介绍的三种函数，前两种(除法哈希法，乘法哈希法)为启发式函数（heuristicfunction）,第三种（全域哈希法）使用随机技术。实际应用中我们往往使用启发式函数。 除法哈希如果我们要把一个Key为k的元素映射到大小为m的哈希表中去，则可以利用m除k的余数来确定位置。那么哈希函数就是：h(k)=kmodm。 关于m的选择我们应当避免一些值，置于这些值是什么，算法导论没有指出，但给了我们一个不错的例子： 比方，m不应当是2的幂，因为若\(m = 2^p\),那么h(k)仅仅是k的低p位，也就是说k的哈希值仅依赖于k的低p位而与其他位没有关系。除非低p位的各种排列概率相等，否则最好选择使得哈希值依赖于k的所有位的数。不错的选择是选一个与2的整数次幂不太接近的整数，至于为什么，有待证明。 乘法哈希乘法哈希则是令key与一个常小数A(0&lt;A&lt;1)相乘，取其小数部分再与m相乘来获取Key在大小为m的哈希表中的位置。哈希函数为：h(k)= ⌊m(kA mod 1)⌋。 乘法哈希有一个好处是，对于m的选值没有太多的要求。CLRS说一般选择一个值为2的幂的数，究其原因在于，这样方便实现在大部分计算机上实现哈希函数，我相信对于任何一种高级语言实现这样的哈希函数都非常简单，所以这一点，谁管他！ 虽然最佳的A值与数据的特征有关，但是Knuth说是个不错的值，但其原因，我是想管管不了，估计需要查一番资料，别深究。 全域哈希（Universal hashing）假使我们的对手已经模特了我们的哈希规则，很好，它将选择一组数,使得这一组数全部映射到同一位置，这就操蛋了。我们虽有办法解决碰撞的问题（下一篇文章会讲到），但是哈希表的效率将大打折扣，哈希表将变成链表，甚至更慢，完全失去了它的查找优势。问题在于任何一个哈希函数都会有这样一种最坏情况，要彻底解决这个问题并不容易，唯一有效的办法是，我们随机的选一个哈希函数，使之独立于key，这就是全域哈希。 其基本思想是，在执行之前随即地从一组哈希函数中选择一个作为哈希函数使用。 设计全域哈希函数类选一个够大的质数p,且p大于任意一个key。另有两系数a∈{0, 1, …, p - 1},b∈{1, 2, …, p - 1}. 哈希函数为对于任意的a,b可以组成p(p-1)个不同的哈希函数中一个。OK. 本文参考： Introduction To Algorithm ——third edition]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>hash tables</tag>
        <tag>散列表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chapter 10 Exercises and Problems (2)]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2Fchapter-10-exercises-and-problems-2.html</url>
    <content type="text"><![CDATA[Exercises 10.3-4 It is often desirable to keep all elements of a doubly linked list compact &gt;in storage, using, for example, the first m index locations in the &gt;multiple-array representation. (This is the case in a paged, virtual-memory &gt;computing environment.) Explain how the procedures ALLOCATE-OBJECT and FREE-&gt;OBJECT can be implemented so that therepresentation is compact. Assume that &gt;there are no pointers to elements of the linked list outside the list &gt;itself. (Hint: Use the array implementation of a stack.) Solutions:用栈来管理空闲资源，并且使得链表的内存紧凑，这表明栈中的空闲资源也是紧凑的，因为若空闲资源不是紧凑的，那分配出去的资源肯定也不是紧凑的。其次，这个栈每一次出栈的资源必然是位置最靠近已分配资源的，这也就是说明该栈中存储的所有空闲资源在位置上是有序的。总而言之，这个问题实质是要我们这样做：对于该双向链表的资源的管理，总是分配最靠近双向链表的空闲资源，而回收时总是回收位置最靠近空闲资源栈的资源。 具体操作为，对于资源分配，直接出栈即可。对于资源回收，应当先将其交换到位置最靠近资源回收栈的节点再回收。 资源分配的伪代码： 1234Allocate_Object() if(Stack-Empty(free) ) error "overflow" return Pop(free) 资源回收的伪代码： 123456789101112Free_Object(x) last_node = Top(free)-1 //remove the x List_Delete(x) //replace last_node by x x.key = last_node.key last_node.prev.next = x last.node.next.prev = x x.prev = last.prev x.next = last.next //free last_node; Push(free,x) Exercises 10.3-5 Let L be a doubly linked list of length m stored in arrays key,prev, and next of length n. Suppose that these arrays are managedby ALLOCATE-OBJECT and FREE-OBJECT procedures that keep a doubly linkedfree list F. Suppose further that of the n items, exactly m are onlist L and n-m are on the free list. Write a procedureCOMPACTIFY-LIST(L, F) that, given the list L and the free listF, moves the items in L so that they occupy array positions 1,2,…, m and adjusts the free list F so that it remains correct,occupying array positions m + 1, m + 2,…, n. The running time ofyour procedure should be Θ(m), and it should use only a constantamount of extra space. Give a careful argument for the correctness ofyour procedure. Solutions：遍历双向链表，依次将它的节点交换到数组的前m个位置即可，在交换时需要提供一个额外的节点。 Problems 10-2: Mergeable heaps using linked lists A mergeable heap supports the following operations: MAKE-HEAP(which creates an empty mergeable heap), INSERT, MINIMUM, EXTRACT-MIN,and UNION[^1].Show how to implement mergeable heaps using linked lists ineach of the following cases. Try to make each operation as efficient aspossible. Analyze the running time of each operation in terms of thesize of the dynamic set(s) being operated on. Lists are sorted. Lists are unsorted. Lists are unsorted, and dynamic sets to be merged are disjoint. Solution:*想了快一个小时，没找到什么思路，留待高手来教我。 [^1]:Because we have defined a mergeable heap to support MINIMUM andEXTRACT-MIN, we can also refer to it as a mergeable min-heap.Alternatively, if it supported MAXIMUM and EXTRACT-MAX, it would be amergeable max-heap.]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>Exercises</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chapter 10 Exercises（1）]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2Fchapter-10-exercises%EF%BC%881%EF%BC%89-2.html</url>
    <content type="text"><![CDATA[Exercises 10.1-2★ Explain how to implement two stacks in one array A[1 ‥ n] in such away that neither stack overflows unless the total number of elements inboth stacks together is n. The PUSH and POP operations should run inO(1) time. Solution:令两个栈的栈底为一个数组的两端，这样的话可以充分利用整个数组，直到两个栈顶相遇。关键在于怎么样来判断两个栈顶是否相遇，两种思路。 思路一：设置哨兵（Sentinel）：在栈顶的下一个位置存储一个特殊值来作为警戒线，这如同告诉另一个栈，到这个地方就是我的领地了，别再过来，哨兵随着栈的大小而移动，需要注意的是哨兵在移动到新的位置的过程中，需将原来的哨兵撤销。示图： 这种方式哨兵需占有两个空间，实际的空间利用为n-2而不是n. 思路二：与思路一相反，思路二将所有的未利用空间全部标记为“未利用空间”——用无穷表示。栈的任何一次Pop操作以后，都需将原来的栈顶标记为未使用空间。在Push操作之前，先判断栈顶之后的元素是否为未使用空间。如下图示： 两种不同的思路，恰恰如同大国奉行的国土攻守政策，思路一主防——凡是我过领土，派兵进驻边境，阻止外国倾入。思路二主攻——凡是无主领地，我便派兵占领。南海问题是一种怎么样的政策？ Exercises 10.1-6★ Show how to implement a queue using two stacks. Analyze the running timeof the queue operations. Solutions:我将这个问题概括为桶饼模型：给俩个与饼同大的小桶，往桶中放饼，要求你在拿饼的时候将先放进去的饼给拿出来。很显然，先放的饼在桶底，无法直接拿出，我们只能借助于另一个桶——把桶中的饼到往另一个桶中，原来桶底的饼就到了最上面，可以直接拿到了。 完整的步骤为：将一个桶设为放饼桶，另一个桶设为取饼桶。所有的放饼操作都在放饼桶进行，并保证放饼之前，所有的饼已经都在放饼桶，若不在将取饼桶的饼倒入放饼桶，所有的取饼操作都在取饼桶进行，取饼之前将放饼桶的饼倒入取饼桶。 以此模型类推，Dequeue和EnQueue操作的复杂度都为O(n).当连续进行Dequeue或连续进行EnQueue操作时，它们的复杂度为1。 Exercises 10.1-7★ Show how to implement a stack using two queues. Analyze the running timeof the stack operations. Solution:我一开始在纸上划了几个图，想快速找出方法，但总想不到可行办法，其实无形中忽略了问题的本质。栈的本质在于后进先出，抓住这一点问题就很快解决了。这个题的实质就是要得到队列的最后一个元素，那么我们直接拿出前n-1不就可以了。 具体步骤： 对于插入操作，将数据插入到有数据的那一个队列，若两队列都没有，随便插入一个队列。 对于出栈操作，将有数据的一个队列中的数据一个个第拿出放入另一个队列，直到拿到最后一个，该数就是要出栈的数。 算法复杂度，入栈复杂度为O(1),出栈复杂度O(n)。 Exercises 10.2-7★ Give a Θ(n)-time nonrecursive procedure that reverses a singly linked list &gt;of n elements. The procedure should use no more than constant storage &gt;beyond that needed for the list itself. Soulutions:在深信服笔试的时候好像做过这个题目，今天看到了特意再做一遍。要在O(n)的时间用非递归的方法使得单向线性表转向，要求空间复杂度为O(1)。反向嘛，所有的节点next指针指向前面的节点即可。但是有一点要注意的是将next指向它之前的节点的话，会有信息丢失，也就是说，此时你不知道了原来的next指向哪个节点了，迭代就无法继续，所以我们要用另外的空间来保存这些信息。 伪代码： 1234567891011121314ReverseList(L) if(L.head == NIL || L.head-&gt;next == NIL) return L; Pre_OP = L.head; //the previous node of the opera node; Op=head-&gt;next; //Op contain the opera node Pre_OP-&gt;next=NIL; //let the head point to the NIL,then head be the tail while(Op!= NIL) Next_OP = Op-&gt;next Op-&gt;next =Pre_OP L.head = Op Pre_op = Op Op = Next_OP retutn L; 16 Exercises 10.2-8: ★ Explain how to implement doubly linked lists using only one pointervalue np[x] per item instead of the usual two (next and prev).Assume that all pointer values can be interpreted as k-bit integers,and define np[x] to be np[x] = next[x] XOR prev[x], thek-bit “exclusive-or” of next[x] and prev[x]. (The value NIL isrepresented by 0.) Be sure to describe what information is needed toaccess the head of the list. Show how to implement the SEARCH, INSERT,and DELETE operations on such a list. Also show how to reverse such alist in O(1) time. Solution:这个题目比较有意思，用一个指针来实现一个双向链表。通常来讲我们实现一个双向链表每个节点有两个指针。在这儿的一个指针其实存储的是两个指针的信息——next和pre两个指针的按位异或。问题的关键在于如何将np解析成pre和next指针，这样我们就将问题转化为了一个普通的双向链表了。 由于是按位异或操作，只要将pre与next中任意一个与np进行一次按位异或操作就可以得到另一个了。而head的pre为0，那么可以得到head的next指针了，而head-&gt;next-&gt;pre==head,那么head-&gt;next-&gt;next==head XOR head-&gt;next-&gt;np，依次类推。这样就可以实现对这个一个指针的双向链表进行遍历了。需要的信息仅为指向表头的指针。 Search函数的伪代码： 12345678Search(L,k) x=L.head next=x XOR NIL while(x!=NIL &amp;&amp; x.key!=k) p=x XOR next.np x=next next=p return x Delete与Insert操作的伪代码略。 show how to reverse such a list in O(1)time.在没有存储尾节点的情况下在O(1)时间内似乎无法办到，如果有存储尾节点的话，这倒是好办，直接head与tail交换即可（也可能我没有理解好题意）。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>Exercises</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第十章 Elementary Data Structures]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AC%AC%E5%8D%81%E7%AB%A0-elementary-data-structures-3.html</url>
    <content type="text"><![CDATA[10.1 栈和队列栈是一个后进先出的数据结构，看到《算法导论》关于栈的部分，又让我想起了当初 在看严蔚敏的数据结构教科书的时候对栈的一个形象理解。我当初将这样理解栈：栈 就相当于往一个桶中方与其直径相同的饼，最先放进去的在最下面，最后才能拿出来。 而最后放进去的饼，总在最上面，可以最先拿到。栈简称为LIFO(last in first out )。 关于栈的应用，我印象比较深刻的是路径的记录，大一的时候写一个迷宫程序，就是 用栈来记录路径。 队列的概念还要简单一些，队列数据结构，与我们生活中的队列一样，讲究的是一个 先来后到。如同超市的收银队列，先来的先付帐，先出收银口. 关于具体的实现就省略了. 10.2链表线性表由节点组成,每个节点除了存储信息的数据部分,还会由一个或两个指针,来指向 它的前一个节点或后一个节点.看张图吧: 10.3实现对象和指针略 10.4有根树略 最后发现这一章没有什么好记的,明天做下题目的笔记吧.]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>Exercises</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[又到离别时]]></title>
    <url>%2Fessaies%2FTropic-of-Cancer.html</url>
    <content type="text"><![CDATA[在某处看到这样一句话：“我对生活的要求无外乎几本书，几场梦，几个女人而已。” 我虽然有看书过目即忘的陋习，但总喜欢查一查看到中意的话的出处，原因在于看到 一句中意的话，我若不去拜读一下该话的原著，便有可能错过一部中意的作品。我深 知，在这样一个伟大的时代，能让人中意一回却是多么艰难。可见，我尚处在一种从 书中找快慰的状态…… 我并未有多么认同这句话，但起码我不反感，因为范诺登仅仅说出其所想，我想真话 即使再烂，也总有能让人原谅的理由。这么一句平淡真实的话，非是大恶，又不煽情， 本该平淡如水，不惹人注意，偏偏让人感觉突兀。人在看待事情，往往会带有“思维惯 性”，事情的合理性反倒在其次，中国人尤其如此——说出这句话的时候，请原谅我的浅 薄，因为我并没有有过外国朋友，又不曾在异域生活，与见多识广的海龟相比，我充 其量是一只没有见过世面的“土鳖”，但实际上在“人”看来，海龟较之土鳖，亦难逃龟 类命途。——我既知，这话浅薄，但仍要这样说，为何？因为太多人这样说，太多人说 这类话，甚至都不经过思考——他们为什么这样说？因为他们与我有一样的理由。 有趣的是《北回归线》是一本解禁的禁书，而更有趣的是我上一次，因一句话去找一 本书，也是一本解禁的禁书。不禁感叹这个世界，百有禁忌。初中的时候贾平凹的一 句话让我印象深刻，他说：“常言说四十不惑，我却事事令人大惑，之一就是写了本 《废都》”。那段时间我在四处寻找《废都》，却求之不得。直到大二，我才从网上看 到关于《废都》解禁的新闻，才明白，丫的原来我一直在一个解禁的禁书都找不到的 地方找一本禁书。 回到范诺登的话，我必须很官方的澄清一下，一如外交部的郑重声明，或严重警告： 我虽然承认这是一句大实话，也大概是太多人的梦想——但并不代表我赞同或推崇这样的 作为，也并不表明我持有这样的立场。 我将《北回归线》放在床头。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[第九章习题选做]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AC%AC%E4%B9%9D%E7%AB%A0%E4%B9%A0%E9%A2%98%E9%80%89%E5%81%9A.html</url>
    <content type="text"><![CDATA[Exercise 9.1-1 Show that the second smallest of n elements can be found with n + ⌈log n⌉ − 2 comparisons in the worst case. (Hint: Also ﬁnd the smallest element.) Soulution: 我们先将N个数配对，每两个数一对，每对之间进行互相比较得出小值。 对得出的N/2个元素重复第一步，直至得出最小值。 到这儿我们得出了最小值，实际上比较的次数为n-1次。不难发现上面的过程实际上可以演示 为一个二叉树。例如在5,8,11,18四个数找出最小值，二叉树演示如下（每个节点相当于一次 比较）： 观察二叉树，可以得出这样一个结论，所有与最小值比较过的数中的最小值纪即为第二小的 的值。二叉树的高度为lgn，因此与最小值比较的数的数目为lgn,在lgn个数中找出最小值要 进行lgn-1次比较。 exercise 9.3-5 Suppose that you have a “black-box” worst-case linear-time median subroutine.Give a simple, linear-time algorithm that solves the selection problem for an arbitrary order statistic. Solution:9.3节的方法可以在最坏情况下的线性复杂度的算法来求Order statistic， 详见。其核心思想在于获得一个更好的中枢值来更好地划分数组。然而题中给了我们 一个”黑盒子”来以线性复杂度获取一个真正好的中枢值，那么再好不过了。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>Exercises</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第九章 中位数和顺序统计量（Medians and Order Statistic）]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AC%AC%E4%B9%9D%E7%AB%A0-%E4%B8%AD%E4%BD%8D%E6%95%B0%E5%92%8C%E9%A1%BA%E5%BA%8F%E7%BB%9F%E8%AE%A1%E9%87%8F%EF%BC%88medians-and-order-statistic%EF%BC%89.html</url>
    <content type="text"><![CDATA[概览本章主要讲的是如何来获取顺序统计量（Order statistic）,所谓第i个顺序统计量即是指在一组数中的第i小的元素，中位数即是大小位于一组数中间的那个数，如果一组数为偶数个，则有两个中位数，大的叫大中位数（upper medians 姑且这么翻译吧），小的叫小中位数（lower medians）。可以先考虑几个问题： 获取最大或者最小的元素，要比较多少次？ 同时获取最大或最小的元素，要比较多少次？ 通过排序来获取顺序统计量的话，是否合理？ 9.1最大值，最小值问题获取最大值或者最小值，可以通过一次遍历比较获得。对于规模为n的一组数，需要进行n-1次比较。且这已经是最优方法，因为除了最小的数本身，其它剩余的数都必然要与一个比它更小的数比较一次（不然如何能知道它自己不是最小的数？）。 同时获取最大值和最小值我们可以简单的通过n-1次比较来获得最小值或最大值，那么如果同时获取最大值我们是不是需要进行2n-2次比较呢?看起来2n-2次比较似乎不错了，毕竟它已经是一个线性复杂度的算法了，但是我们其实可以做的更好。只需要3n/2次比较我们就可以得出最大值和最小值，同样还是一个线性复杂度的算法，但其效率可以提高到将近原来的1.333倍。其具体做法是：不直接进行关于最大值最小值的比较，而是先将n个数分对，每对数之间进行比较，大的数只参加最大值的比较，小的数只参加最小值的比较。 具体实现略。 9.2以期望复杂度为线性获取第i个统计顺序量很显然我们通过排序来获取第i个统计顺序量，这种方法无疑简单护脑。但是毫无疑问的一点是，以排序来获取第i个统计量的话，这其中肯定有“浪费”，因为我们获取了一些我们不需要的信息。所以，我们可以更优秀的算法，其期望复杂度为Θ(n) ，最坏复杂度为\(\theta(n^2)\)。在这儿我们再一次用到“分治”思想，与快速排序类似,我们先利用一个中枢值将一组数分为两部分,一部分都大于中枢值,另一部分都小于中枢值。然后判断出要求的统计量在哪部分，另一部分则可以抛弃——以此达到缩小问题规模的目的，依此递归。 伪代码为 1234567891011RANDOMIZED-SELECT(A, p, r, i) if p == r then return A[p] q = RANDOMIZED-PARTITION(A, p, r) k = q - p + 1 if i == k // the pivot value is the answer then return A[q] else if i &lt; k then return RANDOMIZED-SELECT(A, p, q - 1, i) else return RANDOMIZED-SELECT(A, q + 1, r, i - k) 函数RANDOMIZED-PARTITION(A, p, r)为随机快排的辅助函数，其功能为在其目标数组A的第p个到第r个元素之间，随机选取一个数作为中枢值，并以此将p-r分为两部分，并返回其中枢值下标。参见快速排序。 C++实现1234567891011121314151617//RadomizedSelect//by Adoo 2011/10/17#ifndef RADOMIZEDSELECT#define RADOMIZEDSELECT#include"QuickSort.h"template&lt;typename Iter&gt;Iter RadomizedSelect(Iter IBeg,Iter IEnd,int index)&#123; if(std::distance(IBeg,IEnd)&lt;2) return IBeg; auto apart=RadomPartition(IBeg,IEnd); // Don´t forget add 1; int i=std::distance(IBeg,apart)+1; if(index==i) return apart; else return index&lt;i ? RadomizedSelect(IBeg,apart,index):RadomizedSelect(++apart,IEnd,index-i); &#125;#endif 注：代码中用到QuickSort.h头文件中的RadomPartition函数，具体实现可以见快速排序中源码中关于Partition函数的实现，唯一不同即是pivot的选取，Parition默认用最后一个元素作为pivot，而RadomPartition使用随机元素作为pivot。 关于算法复杂度的证明只能参考原书，没能沉下气看懂这一个证明。 9.3最坏情况下时间复杂度为线性的方法核心思想在于：选取一个更好的元素作为中枢值来划分数组。假使该算法名为Select，五步： 将n个元素按5个元素一组划分为n/5组，若n不能整除5，最后一组用剩余的数组成。 查找每一组的中位数： 用插入排序对每一组进行排序。 选取每一组数的中位数。 使用递归调用Select来获取由各组中位数组成的数组的中位数x。 以x作为中枢值使用类似快排的方法来划分数组，假设中枢值为第k个元素，那么前k-1个元素小于中枢值,后n-k个元素大于中枢值。 有三种可能： 如果i=k，那么已经找到，返回x。 如果i&lt;k，递归调用Select来获取在小于中枢值分段的第i小的元素，并返回该数。 如果i>k，递归调用Select来获取在大于中枢值分段的第i-k小的元素，并返回该数。 伪代码用自然语言来形容感觉有点复杂，我自己写了一段伪代码： 123456789101112131415161718Select(A,p,r,i) index=p while true if(k &gt; p) InsertSort(A,index-5,r) B.add(A[(r+index-5)/2]) break else InsertSort(A,index,index+4) B.add(A[index+2]) index=index+5 pivot=Select(B,0,B.length,B.length/2) q=partition(A,p,r,pivot) k=q-p+1 if(k==i) return pivot else retrun i&lt;pivot ? Select(B,0,k-1,i) : Select(B,k+1,r,i-k) 关于算法复杂度的证明勉强看懂，不证。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Order Statistic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第八章（5） 习题 8-4 8-5 8-7]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%885%EF%BC%89-%E4%B9%A0%E9%A2%98-8-4-8-5-8-7.html</url>
    <content type="text"><![CDATA[8-4 Water jugs Suppose that you are given n red and n blue water jugs, all of differentshapes andsizes. All red jugs hold different amounts of water, as do theblue ones. Moreover,for every red jug, there is a blue jug that holdsthe same amount of water, and vice versa. Your task is to ﬁnd a grouping of the jugs into pairs of red and bluejugs that hold the same amount of water. To do so, you may perform thefollowing operation: pick a pair of jugs in which one is red and one isblue, ﬁll the red jug with water, and then pour the water into the bluejug. This operation will tell you whether the red or the blue jug canhold more water, or that they have the same volume. Assume that such acomparison takes one time unit. Your goal is to ﬁnd an algorithm thatmakes a minimum number of comparisons to determine the grouping.Remember that you may not directly compare two red jugs or two bluejugs. Describe a deterministic algorithm that uses \(\theta(n^2)\)comparisons to group the jugs into pairs. Prove a lower bound of Ω(n lg n) for the number of comparisons that an algorithm solving this problem must make. Give a randomized algorithm whose expected number of comparisons is O(n lg n), and prove that this bound is correct. What is the worst-case number of comparisons for your algorithm? 答：1.使用一个与插入排序类似的算法，比方我们以红壶为准，拿红壶的第一只依次与蓝壶比较，找到与他匹配的蓝壶，然后用第二只红壶与剩下的蓝壶比较，找出第二只匹配的蓝壶，依次类推。 2.其实水壶问题，就是一个变相的排序问题，例如，我们先将红壶依次摆开，然后给他们找匹配的蓝壶，最终的结果不正就是我们将蓝壶按照红壶的顺序排好吗。很显然水壶的问题是基于比较的，自然逃不出比较排序在最坏情况下的下复杂度为Ω(nlg n)的命运,具体证明请参考。 3.快速排序恰好满足这种要求,只不过与a相似比较的对象是另一种颜色的水壶,其最坏情况下比较次数为\(O(n^2)\)。详情. 8-5 Average sorting Suppose that, instead of sorting an array, we just require that theelements increase on average. More precisely, we call an n-element arrayA k-sorted if, for all i = 1;2,…,n - k, the following holds: What does it mean for an array to be 1-sorted? Give a permutation of the numbers 1;2;….;10 that is 2-sorted, but not sorted. Prove that an n-element array is k-sorted if and only if A[i] &lt;= A[i+k] for all i =1;2;…;n-k.&gt; Give an algorithm that k-sorts an n-element array in O(n lg(n/k))time.We can also show a lower bound on the time to produce a k-sorted array, when k is a constant. Show that we can sort a k-sorted array of length n in O(n lg k)time. (Hint:Use the solution to Exercise 6.5-9. ) Show that when k is a constant, k-sorting an n-element array requires Ω(n lg n) time. (Hint: Use the solution to the previous part along withthe lower bound on comparison sorts.) 答： 意味着它与普通排序完全一样。 2,1,3,4,6,5,8,7,9,10。 反证法：若有任意i使得A[i]>A[i+k],那么题设不总是成立。 使用合并排序，当待排序的数目，小于等于k时停止递归。其递归深度为lg(n/k)。 根据c我们可以得出，对于一个k-排列的数组，我们可以得出k个有序的子数组，例如对于一个2-排列的2n个元素的数组我们可以得出两个2个有序的子数列：第一个为k1 &lt;= k3 又是一个关于比较排序的下限证明的问题，由c可知，对于一个k-排序的数组来说，必须满足一个条件：按照e的方法生成的k个数组必然是有序的。所以问题f可以看做是，对k组数目为n/k的数组进行比较排序。余下，略。 8-7 The 0-1 sorting lemma and columnsort关于8-7我对这个题目很有兴趣，但是却没有理解透彻，何其悲哀。题目太长也就不贴了，未能理解，所以答案贴了也无意义，反而可能扰乱以后的灵感。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>Average sorting</tag>
        <tag>water jugs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[桶排序（Bucket sort）]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%884%EF%BC%89-%E6%A1%B6%E6%8E%92%E5%BA%8F%EF%BC%88bucket-sort%EF%BC%89.html</url>
    <content type="text"><![CDATA[算法模型桶排序假设待排序的一组数统一的分布在一个范围中，并将这一范围划分成几个 子范围，也就是桶。将待排序的一组数，分档规入这些子桶。并将桶中的数据进行排序。将各个桶中的数据有序的合并起来。仔细想一想，这是不是一种“分治”策略呢？再仔细想一想，计数排序是不是桶排序的 一种特化呢？ 复杂度： 很显然桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为 其它部分的时间复杂度都为O(n);很显然，桶划分的越小，各个桶之间的数据越少，排 序所用的时间也会越少。但相应的空间消耗就会增大。 可以证明，即使选用插入排序作为桶内排序的方法，桶排序的平均时间复杂度为线性。 具体证明，请参考算法导论。其空间复杂度也为线性。 示意图 伪代码： 12345678910Bucket-Sort(A) let B[0..n-1] be a new array n = A.lenghtS for i = 0 to n - 1 make B[i] an empty list for i = 1 to n insert A[i] into list B[nA[i]] for i = 0 to n - 1 sort list B[i] with insertion sort concatenate the lists B[0], B[1]....B[n - 1] togather in order 与基数排序排序的比较基数排序与桶排序都为线性复杂度的排序算法，基数排序排序更稳定，但它的系数更大。桶排 序的时间复杂度，与待排序的数组的分布有关，最差情况下可以为O(n2)O(n2)。 总的来讲，以个人观点，基数排序与桶排序虽然复杂度为线性，但她们同时都会有各种限制， 其灵活性上有欠缺，相较于原地排序其空间要求也更高。所以有一利，总有一弊。但是，当我 们的待排序数组具备一些基数排序与桶排序要求的特性，且空间上又比较富裕时，桶排序与基 数排序不失为最佳选择。 实例略]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>桶排序</tag>
        <tag>Bucket sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第八章（3） 基数排序（Radix Sort）]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%883%EF%BC%89-%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F%EF%BC%88radix-sort%EF%BC%89.html</url>
    <content type="text"><![CDATA[算法模型基数排序是一种用在老式穿卡机上的算法。至于穿卡机是怎么使用基数排序的，你可以参考算法导论第八章的描述。 在之前两种比较排序——合并排序与快速排序中我们使用一种“分而治之”的策略，基数排序则使用另一种与之有有异曲同工之妙的策略。无论是合并排序还是快速排序，我们讲究的是在数组级别的“分而治之”；而基数排序我们讲究的是在元素级别的“分而治之”，例如我们将一个三位数分成，个位，十位，百位三部分。 我们先来看一个实例，假如，我们要对七个三位数来进行排序，依次对其个位，十位，百位进行排序，如下图： 很显然，每一位的数的大小都在[0，9]中，对于每一位的排序用计数排序再适合不过。 算法复杂度对于n个d位数而言,如果计数排序的Stable Sort[^注1]的算法复杂度为θ(n+k)，那么其本身的算法复杂度为θ(dn+kd)。这个就不用证明了。 进阶到目前为止，基数排序似乎并不是太实用。首先，你发现好像位数是个麻烦事，比如一组数中间，既有是一位的，也有十位的，这时候似乎就不好用了；其次，如果一列数中间有负数，似乎也死翘翘了。还有就是，这哥们能排浮点数吗？ 当你看到某些教程或者文章的时候，作者会郑重提醒你，排序的数必须是整数，而且整数还不够还要必须是正数。其实对于负数也是可以的，对于实数也同样是可以的，在后面我会给出一个C++实现的对整数（正负数不论）进行基数排序的代码。 其实，基数排序排序关键还是基于位，对于我们来讲讲位是基于十进制的。但对于计算机来讲，什么八进制，十进制，十六进制都是浮云，最实在的还是二进制。所以对于我们来讲int型5和55555两个数的位数是不一样的，一个一位，一个五位，但对于计算机来讲他们的位数是一样的，都是32位。 当然，基于二进制的时候我们不是按一位一位来排，我们要按几位几位来排，选多少位最合适？在选多少位之前，我们先总结一条定理。 定理：对于n个b-bit位的元素和一任意正数r &lt;= b（r代表基数排序选取的位数），在Stable Sort的时间复杂度为θ(n+k)的情况下，基数排序的时间复杂度为\(\theta((b/r)(n + 2^r))\)。 证明：每一次对r位进行排序，则总共进行b/r次Stable Sort排序。每一次选r位，显然k=2（k为计数排序的范围）的r次方。所以\(\theta(d(n+k)) = \theta((b/r)(n + 2^r))\)。算法导论给出说明：当b&lt;lgn时，r=b可以得到最小复杂度；当b>=lgn时，r=lgn有最小复杂度。原谅我不能给出数学上的证明。 实例回到之前说的关于有负数的时候怎么排序的问题上来，我们要注意的一点事和I负数在内存中存储的是补码。也就是说在我们基于二进制来进行排序的时候负数是用其补码来排序的而不是本身，所以经过基数排序以后会得出这样的序列，所有的正数在一边，所有的负数在一边，正数的一边是有序的，负数的一边也是有序的。但是正数的一边本应该是负数的位置，而负数的一边本应该是正数的位置。比方，我们对3，2，5，-1，-4，-2，-3排序后的结果会是：2，3，5，-4，-3，-2，-1.显然对于这样一个序列，只要在排序后将正数序列和负数序列互换位置就可以了。 对整数进行基数排序的C++代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//RadixSort.h//By Adoo//2011/10/2#ifndef RADIX_SORT#define RADIX_SORT#include&lt;deque&gt;#include&lt;iterator&gt;template&lt;typename InIt&gt;void RadixSort(InIt BegIt,InIt EndIt )&#123; int byte=8*sizeof(*BegIt); int count=std::distance (BegIt,EndIt); int size=std::log(double(count))/std::log(double(2)); size=byte&lt;size ? byte : size; int from=1; do &#123; RadixCounting(BegIt,EndIt,from,size); from+=size; &#125;while(from&lt;byte); for(auto index=BegIt;index!=EndIt; ++index) &#123; if(*index&lt;0) &#123; std::vector&lt; std::iterator_traits&lt;InIt&gt;::value_type &gt; vec(index,EndIt); vec.insert(vec.end(),BegIt,index); std::copy(vec.begin(),vec.end(),BegIt); return; &#125; &#125;&#125;;template&lt;typename InIt&gt;void RadixCounting(InIt BegIt,InIt EndIt ,const int From, const int Size)&#123;//counting sort the elements form BegIt to EndIt base on the Size bits from From; //the counter int capa=std::pow(double(2),Size); std::vector&lt;int&gt; Counter(capa,0); int clip=capa-1; for(auto Index=BegIt;Index!=EndIt;++Index) ++Counter[((*Index)&gt;&gt;From-1)&amp;clip]; for(int i=1;i!=capa;++i) Counter[i]+=Counter[i-1]; std::vector&lt;int&gt; Result(Counter[capa-1],0); for(std::reverse_iterator&lt;InIt&gt; RIter(EndIt),REnd(BegIt); RIter!=REnd ;++RIter) &#123; int index=((*RIter)&gt;&gt;From-1)&amp;clip; Result[ Counter[index]-- -1]=*RIter; &#125; std::copy(Result.begin(),Result.end(),BegIt);&#125;#endif 对于浮点数呢？（尾数，指数…）。基数排序虽然是线性排序，但在实际应用中它反而有可能比快速排序要慢，因为其常数因子可能远大于快速排序的常数因子。例如，在性能较差的机器上，快速排序在Cache的利用效率上要比基数排序高很多。在内存空间紧张的情况下，应当选择快速排序类的原地排序算法。 我做了一个小小的测试。 数据量 RadixSort QiuckSort 1k 15 16 10k 125 265 50k 672 1469 100k 922 3141 500k 4975 19125 1000k 11844 36025 （单位：毫秒）对同一组随机数，基数排序和快排分别测试五次取平均值。Cpu：E5200,内存：4G。100万后的数据测不下去了，cpu太慢，不知道等多久，不同的机器上，应该有很多差别。 [^注1]: 所谓Stable Sort是指相等的元素在排序完成之后能保持排序之前的相对顺序。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>c++</tag>
        <tag>快速排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计数排序(Counting Sort)]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA-%E7%AC%AC%E5%85%AB%E7%AB%A02-%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8Fcounting-sort.html</url>
    <content type="text"><![CDATA[与比较排序注重于元素之间的比较不同，计数排序专注于找准自己的位置，而不关心自己比谁小，比谁大。其核心在于，对于任意一个属于数组A的元素x，统计出在A中有多少个元素小于等于x,以确定x的位置。例如，有10个元素小于等于a那么a就应该排在第11位。 算法模型：假设对数组A[n]进行排序,A[n]中任意一元素x∈[0，k)。我们需要两个辅助数组，一个为B[k],我们用来记录统计信息，另一个为C[n],用来储存排序结果。 用下标i迭代数组A，用B[i]记录A中等于i的元素个数。 迭代数组B，用B[i]记录小于等于i的元素的个数。 根据B中的统计信息，将A中的元素放到C中合适的位置。 来看伪代码： 123456789101112COUNTING-SORT(A, B, k) for i = 0 to k c[i] = 0 for j = 1 to A.length C[A[j]] = C[A[j]] + 1 //C[i] now contains the number of elements equal to i for i = 1 to k C[i] = C[j] + C[i - 1] //C[i] now contains the number of elements less than or equal to i for j = A.lenght downto 1 B[C[A[j]]] = A[j] C[A[j]] = C[A[j]] - 1 注意：第十行从后向前迭代能保护相等元素的相对位置，12行减1也是因为考虑到相等的元素。 时间复杂度计数排序具有线性复杂度，与任何一个比较排序相比，其复杂度都要低很多。 Θ（k）+Θ(n)+Θ(k)+Θ(n)=Θ(k+n)。 容我说道一下人生：人生如同排序，若你执着与世人较高较低，便总有烦劳忧愁，其路也弯曲（nlgn）；若你心中自有定位，看淡争先落后，便自能泰然自若，其路也轻松（线性）。特别是在我们学习技术的时候，若我们总在与人比较，又或者总计较于技术间好坏的争论，就会落了下乘，重要的在于找准自己的定位。当然，回到技术层面，并不是说非比较排序就一定比比较排序好，具体分析下一篇算法导论心得——基数排序（Radix Sort）会讲到。 C++实现123456789101112131415161718192021222324#ifndef COUNTING_SORT#define COUNTING_SORT#include&lt;vector&gt;template &lt;typename InputIter,typename OutIter&gt;void CountingSort(InputIter BegIter,InputIter EndIter, OutIter OutputIter, const int Boundary)&#123; //the counter std::vector&lt;int&gt; Counter(Boundary,0); for(auto Index=BegIter;Index!=EndIter;++Index) ++Counter[*Index]; // Counter[] holds the number of input element equal to *index; for(int i=1;i!=Boundary;++i) Counter[i]+=Counter[i-1]; //Now Counter[] contains the number of elements less than or eaual to i std::vector&lt;int&gt; Result(Counter[Boundary-1],0); for(std::reverse_iterator&lt;InputIter&gt; RIter(EndIter),REnd(BegIter); RIter!=REnd ;++RIter) &#123; Result[Counter[*RIter]-1]=*RIter; --Counter[*RIter]; &#125; std::copy(Result.begin (),Result.end (),OutputIter);&#125;#endif]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Introduction to algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《算法导论》笔记汇总]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E7%B4%A2%E5%BC%95%E8%A1%A8.html</url>
    <content type="text"><![CDATA[2011.9—2012.x By Adoo 排序之插入排序与合并排序——C++实现 PartII Sorting and Order Statistics 算法导论之堆排序及其C++实现 利用堆来建立优先级队列 6-3 young tableaus 第七章（1） 快速排序 第七章（2）快排与随机快排效率分析 第七章（3）快速排序 exercise7.4-5 第八章（1） 比较排序在最坏情况下时间复杂度为Ω(nlgn) 第八章(2) 计数排序(Counting Sort) 第八章（3）基数排序（Radix Sort） 第八章（4）桶排序（Bucket Sort） 第八章（5） 习题 8-4 8-5 8-7 第九章 中位数和顺序统计量（Medians and Order Statistic） 第九章习题选做 Part III: Data Structures 第十章 基本数据结构 第十章 习题解答一 第十章 习题解答二 哈希表（1） 哈希表（2） 哈希表的C++模板实现 Solution of CLRS 11.1 exercises Chapter 12 二叉搜索树(Binary Search Tree) 1 Chapter 12 二叉搜索树(Binary Search Tree) 2 仿STL 的二叉搜索树的C++实现 非递归不用栈遍历搜索二叉树 Radix Tree 基数树 Chapter 13 Red-Black trees (红黑树) C++实现红黑树，仿STL封装 在没有父指针情况下的红黑树插入操作 扩展数据结构 Part IV: Advanced Design and Analysis Techniques 动态规划笔记（1）——Rod cutting 动态规划基础 最长公共子序列 最长单调子序列问题 最优二叉查找树 版本：所读版本为第三版英文版。 Introduction to Algorithm —— the thirdedition &quot;排序之插入排序与合并排序-C++实现&quot; &quot;堆排序及其C++实现&quot; &quot;利用堆来建立优先级队列&quot; &quot;算法导论6-3 young tableaus&quot; &quot;第七章（1） 快速排序&quot; &quot;快排与随机快排效率分析&quot; &quot;第七章（2） 快速排序 课后7.4-5&quot; &quot;算法导论 第八章（1） 比较排序在最坏情况下时间复杂度为Ω(nlgn)&quot; &quot;算法导论 第八章(2) 计数排序(Counting Sort)&quot; &quot;第八章（3） 基数排序（Radix Sort）&quot; &quot;第八章（4） 桶排序（Bucket sort）&quot; &quot;第八章（5） 习题 8-4 8-5 8-7&quot; &quot;第九章 中位数和顺序统计量（Medians and Order Statistic）&quot; &quot;第九章习题选做&quot; &quot;第十章 Elementary Data Structures&quot; &quot;Chapter 10 Exercises（1）&quot; &quot;Chapter 10 Exercises and Problems (2)&quot; &quot;哈希表（1）&quot; &quot;哈希表（Hash Tables）（2）&quot;]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二章]]></title>
    <url>%2Fessaies%2Fji-fo-2.html</url>
    <content type="text"><![CDATA[李家虽然不穷，但也沾不上富家。若要追寻家世，溯源族谱。那么，还要到图远太爷爷的爷爷那辈，到李太爷父辈也还是当地大家，不然也不能让图远的太爷爷读书求学。李太爷九岁的时候，母亲病重，一向惧内的父亲，趁此机会把多年不敢娶的青楼女子娶回了家。他父亲到不见得如何悲伤，仿佛新纳小妾的喜悦能与发妻亡命的悲愁相抵消。便如同正一加负一等于零一般。 李太爷隐隐觉得父亲有了一些变化，说话好像底气足了一般。但是这样的改变并没有多久.几天后，父亲就一下子从一个趾高气昂的老爷，变成了一个点头哈腰的奴才。因为，小娘掌了家，父亲再无银子去青楼逍遥。小娘似乎全不记得自己的出身，少不了对着父亲劈头盖脸的臭骂。又或者，数落那些个青楼女子的薄情和险恶，和夸赞自己的端庄和贤良。 怕老婆像一切复发病一样，总会一次厉害过一次。 一个刻薄女人的尖酸是无法描述的。到李太爷十六岁的时候，他觉得这家再也呆不小去了，于是他向父亲要求出门求学。当即被他父亲反对。 “‘家有老，不远行’，你念了这些年书是白念了。” “……..”。 “百行孝为先，你看我这副身子，怕是也活不了多少年了。等我入了黄土，你远走天涯海角我也不管你，何况我就你一个儿子，你小娘又不曾生儿产女…….”。 “小娘，小娘，你就懂得小娘，他能生孩子，你别忘了他原来就是个妓女。”李太爷像是一头激怒的牛犊，怒目圆睁。 “啪”一巴掌，李太爷牙缝里渗出血水，但仍就咬着牙关，鼓着鼻孔。 “连娘都骂，我生你养你有什么用。” “她没生我，更没养我，她不是我娘。” “小娘也是娘！” “父亲，休了他。”李太爷突然停止了咆哮，态度认真的可怕。 “混账！这样大逆不道的话你也说的出来!”李太爷的父亲眼眶怒睁着，像要滴出血来。 “哈哈哈哈，”李太爷突然笑出来“我知道你不敢，人家都是从夫，惟独我们家是要从妇。莫说要你把他扫地出门，她不把你赶出李宅就该千恩万谢了。” 又是一巴掌下来，不过这回却被李太爷一手接住了。他父亲震惊的看着他，李太爷放下他的手，还是走了。 接住父亲手的那一刻，李太爷心中一酸：父亲老了。走在路上，没来由的想起了从前种种，父亲把小娘煮给他的三鞭汤偷偷的带一碗给自己，背地里给自己铜板，夜里给自己盖被，带自己到林子里掏鸟蛋，给自己做弹弓……..没有包裹，没有盘缠，李太爷不知道自己要去哪儿，他原来想到南方去参军的。 走了不过两里路，当午饭没有着落，肚子也不争气的咕咕叫时，他坐在石头上不知道如何是好。 李太爷踟蹰不前，而这边他父亲却是，收拾起李太爷的衣物，又帮他把书本收拾在包袱中。不管不顾，一斧头劈开了小娘藏钱的柜子，拿了两锭最大的银子，跑出来追儿子了。 李太爷接过东西，他父亲什么也没说，转身走了。 似乎活到现在，所有的感动在顷刻间爆发了，眼泪一下子模糊了父亲的背影。李太爷只是扯着哭腔喊道：“我一定会风风光光的回来。” 父亲的背影一怔，没有回头，往回家的方向走去。等待的不知道又将是怎样的狂风暴雨。五十两银子，对于把宅子买了也凑出不过几百两银子的李家来说的确不是个小数目。 最让人不经意的莫过于时间，李太爷回家的时候已是十年后了。 世事总是难料，李太爷到南方参军不成，却在当地学校做了老师。 十年，似很长，又很短。四处弥漫着战争的影子，李太爷再也忍不住思乡的苦楚，踏上了回乡的归途。 李太爷听着小镇街角的齐老头讲着变故。 物是人非，李宅大门的牌匾已经换成了吴府。李太爷的父亲两年前就已经去世了。小娘买了宅子，和一个相好跑了。只几天后，小娘和相好便被路过的逃兵杀死在了路边，钱物都抢了，小娘被奸污时却誓死不从。只是小娘前半生在青楼买了身体，后半生从良了，又偷了汉子，一辈子放浪，反倒是性命关头，却贞烈了一回。 齐老头一阵唏嘘，带着李太爷找他父亲的坟墓。父亲的坟墓好找，立了碑。只是小娘的坟连齐老头也分不出，只是这几年暴死的人太多，这儿像一个乱葬岗，到处是坟头，没有墓碑，根本找不着。李太爷对着那一片坟地拜了一拜。 他不气小娘，也不恨那汉子。 这世间如同一个火烤的铜炉，我们都是其中的可怜虫，挣扎求生…….和平时是如此，战争时更是如此。 李太爷在战乱中漂浮了半个世纪，教过书，跑过货，最后参加了国民党的部队，老婆和儿子都在战乱中死去，他一个人把孙子天华拉扯大，还当上了政委。那一年，国名党要逃往台湾，他辞了政委，悄悄的当了逃兵，回到了小镇。 当文化大革命爆发的时候，他被批斗，被整改，六十多岁的男人被打断过肋骨，扇掉过牙齿。被人用鞋底拍在脸上，他被强摁着下过跪，磕过头。而他却活过来了，活到了九十七岁。 李天华（图远的父亲）讲到这儿的时候，露出坚定的目光：“是啊，你爷爷他活下来了，活着就是最大的成功。” 原来一起哭泣的两父子，再李天华的讲述中，慢慢把心情平静下来。 “远儿，没事了，没事了。生老病死，自然之道，爷爷值到死前也没经历过大的病痛，这是再让人安慰不过了。何况爷爷活了将近百岁，虽然其中苦楚颇多，但也算多姿多彩。你去看一看爷爷，他最大的遗憾便是没有你送终了。” 太爷爷安详的躺在床上，似乎一切再平常不过。图远轻轻的握着太爷爷的手。 恍惚间，图远似乎感觉到李太爷的手轻轻地卧了他一下。抬头看时，李太爷的嘴角带着一丝淡淡的微笑。好像在诉说这自己的满足。 李天华要遵从李太爷的遗言“丧事从简，人死归土，早日下葬，入土为安。” 而图远的母亲怕人背后嚼舌头，觉得应该办五天，这样才显得我们李家讲孝道。图远那唯一的小姑和姑爷也这样认为。李家就这一个老头，应该办得风风光光。 李天华问图远。图远愣了愣……. 原来自己已经长大了，这意味着担当和责任。 总之，生者是不该拿死去的亲人来赚取孝顺的名声的。 丧事如同李太爷的遗言那般简陋，李家也没有多少亲戚，三天就下了葬。小姑和姑爷回了自家，来帮忙的各位三姑六婶也都散去。李家还是李家，一切都好像都没有发生。只是门前的悼词挽联，屋内的遗照和七星灯散发着哀痛的气息。 图远又在家里呆了七天，过了头七的祭祀才返校。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一章]]></title>
    <url>%2Fessaies%2Fji-fo-1.html</url>
    <content type="text"><![CDATA[李图远在K大读书，而且读的一塌糊涂，足见K大是个培养人才的地方，而非天才。 图远少年时有文学梦，又有政治梦。然而这年头搞文学自是混的艰难，赚钱不多之外，还得哗众取宠。虽然作家要是出名了，除了文章那些儿钱外，还能赚得很多衍生价值。譬如，据说他很喜欢的作家贾平凹的字画，能买到几万块钱一副，只不过以图远以及作者那外行眼光，只觉得他的字画就如他的长相一般，断断算不得一流。当官呢虽有好的“钱途”，但无非要欺欺平头百姓，骗骗混蛋上司，只是想得做大之前，大多还得昧着数年良心，图远也是不愿。人生在世，除却那美丽的梦想外，总还得讨生活，养父母，娶老婆，生孩子。那梦想只有在做梦的时候还以为他是美丽的，醒了便如戳破的泡沫，除了一摊水渍，不留半点其他，那留下的水渍也多半是自己的口水。 受文学梦的影响，图远以为男人总该有点才情，胸中有些沟壑才是。只是在K大读了两年，终于明白，大学里面胸有“沟壑”的人四处皆是，不过全是女人——挤出双峰，露出乳沟。而胸有沟壑的男人，却是绝难见到。于是图远总结出一条：大学如同交易市场，有一半人是来寻沟壑的，而另一半人是来推销沟壑的（倘若中国的大学生，男女数目相仿的话）。 这时候夕阳已到天际，地平线上的两片白云，被染上了金红的残色。图远郁郁的走在路上，一言不发，脸色也一成不变，高高瘦瘦的身躯，微有佝偻，低头紧锁的两条青眉分明，又似看不出的深沉。 人们总以为，梦想会在时间的流淌下变得发酵，实际上往往是会发霉。你不去动它，它不会令人越来越沉醉，只会尘封在某个角落。只当你记忆再去触碰的时候带起一阵霉灰，徒惹心底唏嘘。 太阳还未落下，吉佛街街口的发廊红灯已然初上，几个女人尖细的笑骂声，从街口传出，那尖声，好似要打破整个吉佛街的寂静，传遍整个K大，又好像不甘于此，要传遍整个莲城才很罢休。图远低头走路，不曾抬头看几女，几女只顾搔首也不曾看他。 亲人的离去，是莫大的悲伤。图远刚买完票回来，明天凌晨的火车。太爷爷病重，父亲电话，大意是要图远赶回去送终的。图远心中空落落的。一年时间恍若隔世，原来太爷爷身子还健朗，图远怎么也料不到，这人说要走就要在的，留也留不住。 李太爷原来对图远期望很大，认定这孩子聪明，又上了大学，大有前途不可限量的感觉。只是如今，图远对自己大为失望，只觉得孝道未尽，又时光不再。 一路无话，院子门前的两颗枣树，还是那样，夕阳透过，投下两颗孤独的树影。图远似没听到张建人的招呼，也没有理会史书的打趣，一个人进了屋，坐在床上，回首往昔种种。张建人心里骂了一声：“还当自己是根葱了，算什么东西。”史书也耸耸肩，继续念着：“我家门前有两棵树，一棵是枣树，另一颗还是枣树;村里出了两个官，一个是贪官，另一个还是贪官”。 …….. 图远坐在车上，电话响个不停，于是索性把电话关了。 列车呼啸的奔驰，但是图远归家的心却更加急切，列车才走一半的路，他的心便快要看到了进小镇的旧桥。他盼望着家门，又想着太爷爷的往昔……. 李图远原来叫李途远，是李太爷给取的名字，于这个名字还有一些故事。 ——李图远决计是个有远大图谋的人，因此每日沉溺于自己的远大理想的规划中，却是顾不得眼前这短短时日。远图年近百岁的太爷爷，少时读过私塾，算的上是个读书人。在图远还未出生前，李太爷就为自己长重孙取好了名字——李途远。以此来时时告诫长重孙，人生短暂，前路遥遥。又有典故“日暮途远”。李太爷也一直为此捻须自得，觉得这名字涵养内敛。比之那亚运啊，建国，爱党之流的名字好了不只百倍。 但图远却不这般觉得。初中时候，图远有个同学叫王小乐，很受女孩子欢迎。让远图很是羡慕。他总归觉得都怪自己的名字不顺口，不像人家“小乐，小乐”的叫着朗朗上口，若自己叫“小远”说不定又是另一番光景。但从此，想改名字的种子便埋在了他的心中。万事都是这样，若是种子一旦种下了，便保不准会有生根发芽的一天。譬如，被开过玩笑的男女，纵不能成其好事，但多年后见了面，总免不了要生出一丝旎念的。 到考入K大的时候，图远顺便就把名字改了。“小远”自然是不行的，这单单是跟了那王小乐，图远不屑。他想人倘若一生跟着旁人走，便终生走不到人前。但一时半会却也想不出好的名字，于是便做了个小小的改动，将“途远”改成了“图远”。陡然间，图远便觉得名字似乎气势增了不少，连带着人也有了一丝霸气。 只一月军训完，便是国庆，图远本来不想回家，只是家里来了电话说是太爷爷生了病，图远只能回家看望。 改名的事被李太爷，如同很多文学家们不愿意旁人对自己的文章擅自修改一般，李太爷也对自己取的名字被改自然也很不满。对着图远和李父。“诶….诶….诶”一连三声叹气，才接着说下文。 “远儿这名改的倒是有些意思，原来给你取名途远，便是要告诉你踏踏实实，一步一印，莫要学现世很多人眼高于顶，浮躁的很。你却好，改一字，虽然没改了音，却把我的意思全改变了。”李太爷声音提高，松弛暗黑的老脸上难得见到两砣殷红。李父赶紧过去帮李太爷搓背顺气。 图远恭恭敬敬的低头站在旁边，心里却是暗自得意。李太爷的话太只听进了前小半句，隐隐自得，半点不顾李太爷话的重点在后半句。 李父看图远没有丝毫悔过之意，正要训斥，李太爷把手一伸制止住，倒是有一股清末古戏中读书人的摸样。李太爷根本就是读书人。 “现今名字也已经改了，改回来也麻烦。只是远儿要记住，切莫好高骛远。学了些东西，不要以为了不起了，莫要学人家买弄，肚子里要有真学才是。三国的孔明先生虽有经纶满腹，也甘躬耕陇亩。” “口说不求闻达，声声自比管乐。”图远突地这一句，差点把李太爷气的背过气。李太爷原来是想，图远小时候最喜欢诸葛亮，便想用诸葛亮教育图远，却不知图远什么时候转了性。李父赶紧扶着李太爷回了房，生怕图远这不肖子再气李太爷。 李太爷回房后揣摩图远的话，越是揣摩越是深以为然。反而认为这孩子见识不凡，心里也是安稳了。 他是以为这话来自图远自己的见地，但却不知这话出自和他同年代周大荒的书中。 只两天过后，图远便是支了各种理由返了K大。在路上一顿恍惚，觉得家里好似腐朽了一般，也不觉得太爷爷博学了，也不觉得父亲亲切了。家里的空气似乎带着一股霉味，与他这开放的思想格格不入。 到K大时候使劲的吸了几口空气。觉得这空气中弥漫了清新。看了两旁的大樟树，心里就有了底气。觉得有大树就是有历史，有历史就厚重，厚重就是有底蕴。对K大尤为满意。 照他看来大学似乎还真就是一个解放思想，增长见识的地方。很多的好事，喜事从这儿传出去，很多的坏事，丑事也从这儿捅出来。某天女博士被Z教授潜规则了；哪天又会有X书记在和教育部领导在晚宴上海量；又或者爆出来W大学的书记抄袭论文了……总之没完没了，三天两条。 ……. 只是转眼间，一年过去，此刻的图远再不是之前的图远，他不曾感到高等教育感到高明之处。大学是够大，老师也够老，但惟独这学校的才子无才，食堂也没什么菜。大学就如同吉佛街每日傍晚叫卖的烤番薯，香气四溢，看着觉得非吃不可，真的吃了，也不过是，嘴上哈哈气，裆后放放屁罢了。 当心儿停止了飞驰，列车似乎却快了，图远终于到了昌县。打了车回小镇。 图远远远的就看到了在大门前烧着火纸的父亲，大铁锅里的火苗一突一突的往上窜，跳动的火苗中似乎就有太爷爷苍老的脸容。图远心里空落落的，似乎一伸手便能触摸，又怕一伸手便打破了幻象。待走近时，图远不觉伸手要去触摸，甫一靠近，手指的灼痛传来，火苗还是在舞动，太爷爷的影像却不见了踪影。 “爸，我看到太爷爷了，他在火锅中冲我笑。” 李父一阵哽咽，两行热泪簌簌流下，图远也再忍不住眼中打转的泪水，顿时哭出声来。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比较排序在最坏情况下时间复杂度为Ω(nlgn)]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA-%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%881%EF%BC%89-%E6%AF%94%E8%BE%83%E6%8E%92%E5%BA%8F%E5%9C%A8%E6%9C%80%E5%9D%8F%E6%83%85%E5%86%B5%E4%B8%8B%E6%97%B6%E9%97%B4.html</url>
    <content type="text"><![CDATA[1.什么是比较排序?之前的排序算法，包括插入排序，合并排序（归并排序），堆排序，快速排序等有 一个共同特点——这些排序算法都是基于比较元素来决定其相对位置的，我们称这种 排序算法为比较排序。 2.比较排序只关注比较结果在比较排序中我们不检查元素的值，也不从其他渠道来获取其循序信息，也就是说， 对于比较排序，我们仅仅只关注其比较的结果，而并不理会进行比较的元素其本身 的值，或者任何其他能体现其相对位置的其它信息。 3.对n个元素进行排序，所有的比较排序算法在最坏情况下的复杂度为Ω(nlgn)我们使用判定树（decision tree）来证明。假设有一组三个元素的序列,我们用1， 2，3来分别表示这三个元素，我们基于比较来对它排序，可以有下面的判定树： 不难发现，判定树的叶子表示了三个元素的所有可能排列。另外，用比较排序对这 三个元素进行排序的话，你总可以找到一条路径来表示它的整个比较过程。（需要 注意的是，1并不表示它代表第一个元素，它可以代表三个元素中任意一个。2，3也 相同。但是1，2，3不指向相同元素）。显然最坏情况下的复杂度即是判定树的高。 假设用比较排序对N个元素进行排序，它的判定树高为H,叶子数目为L。显然\(L \leq 2^H \)，然而\( N≤LN≤L1 \)。所以 \( N!≤L≤2H \)可化为：\( H≥lg(N!)=Ω(N∗lgN) \)。 是考虑到原文这一句：Because each of the N! permutation appears as areachable leaf.我觉得作者的意思着重于用N！来表示N个元素的所有可能排列，但是N个元素的所 有可能排列实际上是小于等于N！的，因为在N个元素中有可能有相等的元素。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>8.1 Lower bounds for sorting</tag>
        <tag>比较排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速排序课后7.4-5]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%882%EF%BC%89-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F-%E8%AF%BE%E5%90%8E7-4-5.html</url>
    <content type="text"><![CDATA[7.4-5 We can improve the running time of quicksort in practice by taking advantage of thefast running time of insertion sort when its input is “nearly” sorted. Upon calling quicksort on a subarray with fewer than k elements, let it simply return without sorting the subarray. After the top-level call to quicksort returns, run insertion sort on the entire array to finish the sorting process. Argue that this sorting algorithm run in O(nk+ nlg(n/k)) expected time.How should we pick k, both in theory and in practice? 解答: 当每一个小分段为k个元素时，分段的数目count=n/k;显然，要得到count 个分段，要经过lg count = lg n/k 次递归。所以快排的复杂度为 O(nlg（n/k）)。 因为快排之后，整个序列段是近似有序的，只是各个小段之间的元素无序。也就是说， 进行插入排序的时候，各小段的元素的比较不会超出本段。所以相当于对n/k个小段进 行插入排序，其复杂度为n/k O(k平方)=O(nk).所以整个时间复杂度为O(nlg(n/k) + nk)。关于k的选取，我一直没有头绪，与瘟疫青年以及小兵的讨论也没有得出结果，最后小兵 给我提供了一个答案的链接，非常感谢。 答案的内容为：]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>7.4-5</tag>
        <tag>快速排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快排与随机快排效率分析]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E5%BF%AB%E6%8E%92%E4%B8%8E%E9%9A%8F%E6%9C%BA%E5%BF%AB%E6%8E%92%E6%95%88%E7%8E%87%E5%88%86%E6%9E%90.html</url>
    <content type="text"><![CDATA[今天在网上看到独酌逸醉关于快排的博客，在随机快排与快排就效率上有一些讨论，引发了我更深入的思考，于是今天晚上花了三个小时，进行实际验证，并作出记录。欢迎大家也加入讨论。与独酌的讨这儿[ # 1.随机快排并不能带来绝对性能提升 随机五组数据，每组数据为两万个，每组数据分别用随机快排与快排各执行五次求平均值。下面为数据记录（单位 毫秒）： 组名 选用排序方法 第一次 第二次 第三次 第四次 第五次 平均值 第一组 RandomQuicSort 484 469 484 485 484 481.2 QuickSort 484 485 484 485 484 484.4 第二组 RandomQuicSort 469 469 453 453 469 462.6 QuickSort 453 469 453 468 454 459.4 第三组 RandomQuicSort 453 453 469 453 469 459.4 QuickSort 453 453 453 438 452 449.8 第四组 RandomQuicSort 469 469 469 453 437 459.4 QuickSort 469 453 469 453 453 459.4 第五组 RandomQuicSort 453 454 453 453 453 453.2 QuickSort 453 453 453 453 454 453.2 可以看到第一组数据，随机快排比快排效率高，二三组快排比随机快排效率高，四五组两者效率一样。这证实了我的一个观点，在任何情况下随机快排并不绝对比快排效率高，因为随机快速排序避免了最坏情况，但它是以可能失去最好情况为代价的。五组数据的平均值，随机排序与快速随机排序居然都为461.24ms，将快速排序与随机快速排序各自的五组数据的均值分别与这个均值比较，可以发现随机快速排序比快速排序分布要集中。标准差给出了支持：随机快速排序的标准差为12.23879，快速排序的标准差为13.58926。这又告诉我们：随机快速排序的好处在于性能分布比较集中了，不会出现对包含相同数目的元素的不同序列进行排序现耗时差别大的情况（这恰恰是快速排序的缺点）。 2回独酌关于在交换开销情况大时随机快速排序效率高。同样是五组随机数据，同样每组数据执行五次，且取其平均值，不同的是每组数据减少为100个，但是在排序中，每次比较交换后延迟15ms。在这儿延迟的办法我不使用sleep，而是使用for循环来控制，减少因为操作系统内核相关的因素。这15ms是在我的机子上，主频不同，要执行的循环次数也不同。下面是数据（单位 ms）： 组别 排序算法 第一次 第二次 第三次 第四次 第五次 平均值 第一组 RandomQuicSort 4438 4062 4157 4062 4797 4303.2 QuicSort 4703 4703 4687 4719 4734 4709.2 第二组 RandomQuicSort 3704 4828 4062 5563 3703 4372 QuicSort 4203 4219 4187 4188 4203 4200 第三组 RandomQuicSort 3250 3485 3625 3703 3437 3500 QuicSort 3969 3969 3969 3953 3969 3965.8 第四组 RandomQuicSort 3735 3796 3766 3250 3031 3515.6 QuicSort 3313 3328 3312 3313 3313 3315.8 第五组 RandomQuicSort 4422 6125 3125 4390 3157 4243.8 QuicSort 4281 4297 4297 4297 4296 4293.6 就每一组来讲，随机快速排序五次排序中，有的比快速排序快，有的比快速排序慢。也就是说。就其平均值来讲，也是如此，五组平均值中三组快于快速排序，两组慢于。由此可见，随机快排与快速排序两者效率到底谁高，有两个因素决定：一是待排序的序列的顺序，而是随机快排中每次迭代随到的中枢轴好不好。而与每一次交换的消耗无关。为什么与消耗无关？假如我们不考虑产生随机数的消耗，不难发现，交换次数越少的效率越高，因为交换次数越少对序列的划分就越均匀。交换消耗增大大的话，会导致快的越快，慢的越慢。因为慢的交换次数更多，他的交换消耗也会增加的更多。源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141//main.cpp#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;algorithm&gt;#include"QuickSort.h"#include&lt;Windows.h&gt;int main()&#123;const int size=100;int count=5;std::vector&lt;int&gt; Ivec;for(int i=size;i!=0;--i)&#123;Ivec.push_back (i);&#125;;DWORD delay=Waste(LoopTimes);std::cout&lt;&lt;"delay "&lt;&lt;delay&lt;&lt;std::endl;do&#123;std::random_shuffle(Ivec.begin(),Ivec.end());std::vector&lt;int&gt; Temp(Ivec.begin (),Ivec.end ());std::cout&lt;&lt;"The "&lt;&lt;count&lt;&lt;" random list ,size "&lt;&lt;size&lt;&lt;" :"&lt;&lt;std::endl;std::cout&lt;&lt;" RandomQuicSort:"&lt;&lt;std::endl;for(int i=0;i!=5;++i)&#123;DWORD Start= GetTickCount();RadomQuickSort(Temp.begin(), Temp.end());DWORD Distance=GetTickCount()-Start;std::cout&lt;&lt;" The "&lt;&lt;i&lt;&lt;" times: "&lt;&lt;Distance&lt;&lt;std::endl;std::copy(Ivec.begin (),Ivec.end (),Temp.begin ());&#125;std::cout&lt;&lt;" QuicSort:"&lt;&lt;std::endl;for(int i=0;i!=5;++i)&#123;DWORD Start= GetTickCount();QuickSort(Temp.begin(), Temp.end());DWORD Distance=GetTickCount()-Start;std::cout&lt;&lt;" The "&lt;&lt;i&lt;&lt;" times: "&lt;&lt;Distance&lt;&lt;std::endl;std::copy(Ivec.begin (),Ivec.end (),Temp.begin ());&#125;&#125;while(--count!=0);std::cin.get ();&#125;//QuickSort.h//by Adoo 2011/9/25//when I learning Introduction to algorithm#ifndef QUICKSORT#define QUICKSORT#include&lt;ctime&gt;#include&lt;Windows.h&gt;const int LoopTimes=3000;template&lt;typename Iter&gt;void QuickSort(Iter BegIter, Iter EndIter)&#123;if(std::distance(BegIter,EndIter)&gt;1)&#123;//if betwen BegIter and EndIter not only one element;Iter Apart=Partition(BegIter,EndIter);QuickSort(BegIter,Apart);std::advance(Apart,1);QuickSort(Apart,EndIter);&#125;&#125;template&lt;typename Iter&gt;Iter Partition(Iter BegIter, Iter EndIter)&#123;//let the EndIter point to the pivot Iterator;--EndIter;//Apart the elements;Iter Apart=BegIter;while(BegIter!=EndIter)&#123;if(*BegIter&lt;*EndIter)&#123;std::swap (*BegIter,*Apart);++Apart;Waste(LoopTimes);&#125;++BegIter;&#125;std::swap(*Apart,*EndIter);return Apart;&#125;template&lt;typename Iter&gt;void RadomQuickSort(Iter BegIter, Iter EndIter)&#123;if(std::distance(BegIter,EndIter)&gt;1)&#123;//if betwen BegIter and EndIter not only one element;Iter Apart=RadomPartition(BegIter,EndIter);QuickSort(BegIter,Apart);std::advance(Apart,1);QuickSort(Apart,EndIter);&#125;&#125;template&lt;typename Iter&gt;Iter RadomPartition(Iter BegIter, Iter EndIter)&#123;//let the EndIter point to the pivot Iterator;srand(std::time(NULL));Iter Pivot=BegIter+rand()%(EndIter-BegIter-1);//Apart the elements;Iter Apart=BegIter;while(BegIter!=EndIter)&#123;if(*BegIter&lt;*Pivot)&#123;std::swap (*BegIter,*Apart);++Apart;Waste(LoopTimes);&#125;++BegIter;&#125;std::swap(*Apart,*Pivot);return Apart;&#125;DWORD Waste(int i)&#123;DWORD Start= GetTickCount();if(i&gt;0)&#123;do&#123;for(int index=i;index!=0;--index);&#125;while(i--);&#125;DWORD delay= GetTickCount()-Start;return delay;&#125;#endif 两组数据使用相同代码，有一点差别是，第一组数据没有使用Waste(int )函数。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Quick Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速排序及C++实现]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%881%EF%BC%89-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F.html</url>
    <content type="text"><![CDATA[快速排序（QuickSort）在最坏的情况下它的时间复杂度是O（n2），最佳情况下它的时间复杂度是为O(n*lgn).即使如此，但快速排序往往是实际应用中的排序算法的最佳选择，因为它隐含的常数因子非常小。 快排是又一个化整为零，各个击破策略的又一个经典应用。与合并排序（MergeSort）有一点不同。合并排序的是直接按数目不断递归划分成小段，然后又层层合并有序段，得出有序结果（合并排序）。而快排，则是按照一个中枢轴（pivot）来划分，即凡是大于中枢轴的分为一段，凡是小于等于中枢轴的分为另一段，对这两段又进行快排，显然当迭代到底的时候，排序就完成了。 来看C++代码： 1234567891011templatevoid QuickSort(Iter BegIter, Iter EndIter)&#123; if(std::distance(BegIter,EndIter)&gt;1) &#123;//if betwen BegIter and EndIter not only one element; Iter Apart=Partition(BegIter,EndIter); QuickSort(BegIter,Apart); std::advance(Apart,1); QuickSort(Apart,EndIter); &#125;&#125; 代码中使用Partition函数来划分待排序的序列，Parition返回一个迭代器Apart，Apart将一个序列分成两个序列，且Partition保证Apart前的元素小于Apart指向的值，它之后的元素大于等于它指向的值。 来看Partition的实现： 12345678910111213141516171819template&lt;typename Iter&gt; Iter Partition(Iter BegIter, Iter EndIter)&#123; //let the EndIter point to the pivot Iterator; --EndIter; //Apart the elements; Iter Apart=BegIter; while(BegIter!=EndIter) &#123; if(*BegIter&lt;*EndIter) &#123; std::swap (*BegIter,*Apart); ++Apart; &#125; ++BegIter; &#125; std::swap(*Apart,*EndIter); return Apart;&#125; 代码中中枢轴为序列的最后一个元素。这段代码的目的在于，将m个大于中枢轴的元素，放到前m个位置，并将中枢轴放在第m+1个位置，自然大于等于中枢轴的n-m-1个元素就在后n-m-1个位置。 关于中枢轴的选择快排的效率很大程度上依赖于中枢轴的选择，因为中枢轴影响了序列的划分，而序列的划分决定着递归的次数。当我们选择某一个相对固定的位置来作为中枢轴的时候，就很有可能陷入最坏情况，比方上面的实现代码，若是待排序的序列已经是有序的，那么就会陷入最坏情况。或是待排序的序列接近有序，则接近最坏情况。于是引出了一种改良的快速排序，随机快速排序。 随机快速排序随机快速排序与快速排序的唯一区别在于，随机快速排序的每一次中枢轴的选择是随机的，而不像快速排序一样是有相对固定位置的。因为中枢轴的是随机的，所以你很难有这么好的运气，每次递归都碰到了最坏情况。随机快速排序避免了最坏情况，但它何尝不是以可能失去最好情况为代价的呢？我想，对于快速排序的优化，应该考虑更多的实际情况。关于随机快速排序，在独酌的博客，我与博主进行了探讨。]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>c++</tag>
        <tag>Quick Sort</tag>
        <tag>随机快速排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论6-3 young tableaus]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA6-3-young-tableaus.html</url>
    <content type="text"><![CDATA[Problems 6-3: Young tableaus An m × n Young tableau is an m × n matrix such that the entries ofeach row are in sorted order from left to right and the entries ofeach column are in sorted order from top to bottom. Some of theentries of a Young tableau may be ∞, which we treat as nonexistentelements. Thus, a Young tableau can be used to hold r ≤ mn finitenumbers. Draw a 4×4 Young tableau containing the elements {9, 16, 3, 2,4, 8, 5, 14, 12}. Argue that an m × n Young tableau Y is empty if Y[1, 1] = ∞.Argue that Y is full (contains mn elements) if Y[m, n]&lt; ∞. Give an algorithm to implement EXTRACT-MIN on a nonempty m × nYoung tableau that runs in O(m + n) time. Your algorithm should use arecursive subroutine that solves an m × n problem by recursivelysolving either an (m - 1) × n or an m × (n - 1) subproblem. (Hint:Think about MAX-HEAPIFY.) Define T(p), where p = m + n, to be themaximum running time of EXTRACT-MIN on any m × n Young tableau. Giveand solve a recurrence for T(p) that yields the O(m + n) time bound. Show how to insert a new element into a nonfull m × n Youngtableau in O(m + n) time. Using no other sorting method as a subroutine, show how to use ann × n Young tableau to sort n2 numbers in O(n3) time. Give an O(m+n)-time algorithm to determine whether a given numberis stored in a given m × n Young tableau. 当我们仔细分析这个问题的时候不难发现，young tableaus和堆非常相像,像堆的堆属性一样young tableaus 有young tableaus属性。只要我们保证young tableaus的每个元素总是小于它的所在行的下个元素以及它的所在列的下个元素，不就可以了。下面写一个与堆排序中MaxHeapfy类似的函数Tableaufy:下面是伪代码，伪代码的所有约定与算法导论的伪代码约定一样。 12345678910111213Tableaufy(A,i,j) if(i &lt; A.RowSize &amp;&amp; A[i][j] &lt; A[i+1][j]) LargestRow=i+1 LargestColum=j else LargestRow=i LargestColum=j if( j &lt; ColumeSize &amp;&amp; A[LargestRow][LargesttColume]&lt; A[i][j+1] ) LargestRow=i LargestColum=j+1 if(LargestRow != i &amp;&amp; LargestColum!=j) exchage A[i][j] with A[LargestRow][LargestColum] Tableaufy(A,LargestRow,LargestColum) 一二问省略不说。看第三问，很明显最小的元素是Young Tableaus的最前面一个元素。我们只要把这个元素交换提取出来，然后给这个位置的元素赋值为无穷大，然后对第一个元素调用Tableaufy就可以了。分析Tableaufy，最大的递归次数为m+n次，递归之外函数的复杂度为O(1),所以函数的复杂度为O（m+n），所以我们用来解决第三问的办法只需O（m+n）。具体实现在这儿就免了。 以此类推，第四问，第五问就很容易了，只需参照堆排序的思路来解答就可以了。 参考：introduction to algorithm –third edition]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>young tableaus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用堆来建立优先级队列]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E5%88%A9%E7%94%A8%E5%A0%86%E6%9D%A5%E5%BB%BA%E7%AB%8B%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97.html</url>
    <content type="text"><![CDATA[堆除了用来排序，还可以有很多其他用途，本文利用堆来建立一个优先级队列（关于堆的介绍可以看前一篇博文堆排序）。对比一下堆与优先级队列，堆的根元素，总是整个堆中的最大或最小元素（最大还是最小，取决于大堆还是小堆）；而优先级队列呢，它要求我们从优先级队列取对象的时候，取的总是优先级最高的那一个。不难发现，假若我们以优先级来建大堆，那么优先级最高的对象总在根节点。那么不管是向队列中增加对象还是从队列中取出对象，我们只要维持这个堆，就可以确保，队列中优先级最高的元素在根节点。 当我们要从优先级队列取出对象的时候，我们是不是直接拿掉根结点呢？下面的代码可以看出不是的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445//PriorityQueue.h#pragma once#include"HeapSort.h"#include&lt;deque&gt;#include&lt;numeric&gt;using namespace std;template&lt;typename T&gt;class PriorityQueue&#123;public: PriorityQueue(void)&#123;&#125;; ~PriorityQueue(void)&#123;&#125;; void Add(const T&amp; value ) &#123; data.push_back(value); auto position=data.end ()-1; //mantain the heap property while(position&gt;data.begin () &amp;&amp; *position&gt;*parent(position)) &#123; swap(*parent(position),*position); position=parent(position); &#125; &#125;; T Get(void) &#123; if(data.empty()) return std::numeric_limits&lt;int&gt;::min (); std::swap(*data.begin(),*(data.end()-1)); T result=data.back(); data.pop_back(); //mantain the heap property MaxHeapfy(data.begin (),data.end (),data.begin ()); return result; &#125;private: typename deque&lt;T&gt;::iterator parent(typename const deque&lt;T&gt;::iterator&amp; last) &#123; return data.begin ()+(last-data.begin ())/2; &#125; deque&lt;T&gt; data;&#125;; 注意，函数MaxHeapfy为头文件HeapSort.h中的函数，HeapSort.h在堆排序中实现 回到代码支前的一个问题：当我们要从优先级队列取出对象的时候，我们是不是直接拿掉根结点呢？实际上，在取根结点之前，我是先将根节点与最后一个叶子交换，再取出根结点。不单取的时候如此，插入的时候也是如此，插入对象的时候，将其添加在末尾，为什么是添加到末尾而不是添加到中间或是添加到最前面呢？ 这样做的原因就是：进行增加和删除操作的时候，只有在末尾进行才不会破环整个堆的结构，才不会破会其他节点的堆属性。例如在要取出根节点的时候，假如直接删除根节点，那么整个二叉树，就要进行重构，所有节点的堆属性也可能会被破坏。但是若将根结点交换到末尾，再删除，那就只有根结点的堆属性被破坏了，其它结点，并没有影响，这样维护起堆的代价就小了很多。增添的时候也是一样的道理。 总结：当对堆执行带有结构破坏性的操作的时候，因该尽量将该操作置换到堆的末尾来进行。我想这一思想也可以推广到其他类似的数据结构上。 参考：introduction to algorithm –third edition]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>c++</tag>
        <tag>优先级队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[夜读金瓶梅]]></title>
    <url>%2F2011%2F09%2F13%2Fessaies%2F%E5%A4%9C%E8%AF%BB%E9%87%91%E7%93%B6%E6%A2%85.html</url>
    <content type="text"><![CDATA[有这么一件很悲哀的事，我在一直这么思考，难道忙到读《金瓶梅》的时 间都没了? 不得不承认的是，当我还在高中的时候，我曾一度想从一中图书馆的书架 里找出一本《金瓶梅》来。当然这事未果，我不知道是压根没有，还是需 要教师级的借书证才能借阅。这在当时是一件令我无比郁闷的事情，当我 看着那两排关于《金瓶梅》的研究，却单单没有《金瓶梅》原文的时候， 我难以理解。这种疑惑好比上学期去图书馆借书的时候看到成堆的关于 《庄子》语言，思想的研究，唯独不见《庄子》一般。 这是一个奇怪的社会，对，奇怪的社会。我不用愤怒，失望去对它，因为 这是无用的。奇怪之一就是，大多数成年人，当然也许包括未成年人（绝 不要对这个社会做太过保守的估计）都看过毛片，却没有多少人看过《金 瓶梅》。当然，不是要以看过《金瓶梅》为荣，这是故作高深的金学家的 姿态，也不用以之为耻，这尚比偷偷看毛片高过百倍。总而不过一本书， 因其声名在外我们尚且可以称之为“名著”。 当然不得不惭愧的说，当这会儿为止，我仅仅才看到第一回，没有资格多 做评价。不过祖国培养的学生，向来有一种奇异的能力，可以不用遵照事 实，仅凭风闻而作出高论，但很显然，我不是合格的祖国学生，因此没有 这种能力。所以关于《金瓶梅》整书暂且不说，但单就第一回而论，这让 我觉得很是欣慰。几百年了，这个世道并没有变坏，同样的“天下唯功”。 我但愿几百年后，不会再有一位青年，像今天的我一样叹息“天下唯功——普 天之下，唯功利尔！”。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>金瓶梅</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[堆排序及其C++实现]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E5%A0%86%E6%8E%92%E5%BA%8F.html</url>
    <content type="text"><![CDATA[堆即是一个可以看作为完全二叉树的数组。《算法导论》第三版这样定义： *The(binary) heap data structure is an array object that we can viewas a nearly completely binary tree. 只要一个序列可以看作为一个完全二叉树，它又满足堆的性质，那么它就可以称之为一个堆。——一个数组可以这样看成一个完全二叉树，将第一个数看作根结点，第二和第三个数看作第一个数的左孩子和右孩子，…，将第2n和第2n+1数看作是第n个数的两个孩子。 堆可以分为大堆和小堆，所谓堆属性是指结点应总是大于它的孩子，此为大堆属性。对于小堆来讲则反之。也就是说堆的根结点总是存储着最大或最小的数，当一个完全二叉树中所有的结点都满足堆属性时此完全二叉树就可以看作为一个堆。 总的来讲，堆排序的要诀在于堆的一个特性——堆的根结点总是存储着最大或最小的数。假使我们能将一组数建堆，那么只需要不断的在取出根结点和维持堆属性这两步中不断循环就可以完成排序了。 堆排序的C++实现代码（使用的是大堆）： 123456789101112template&lt;typename Iter&gt;void HeapSort(Iter BegIter, Iter EndIter)&#123; BuildMaxHeap(BegIter,EndIter); //we always get the largest element and put it on the end, //then shrink the heap, and build heap again; for(--EndIter; EndIter!=BegIter; --EndIter) &#123; std::swap(*EndIter,*BegIter); MaxHeapfy(BegIter,EndIter,BegIter); &#125;&#125; BuildMaxHeap用来建堆，而MaxHeapfy用来维持堆属性，它们的实现将在下文交代，这里先不去管它。HeapSort代码的思路很简单，*总是把根结点交换到堆的最后再取出(交换到最后相当于从堆中取出，因为每一次循环堆都要向前缩短1)。此时新的根结点点并不满足堆属性，所以我们要重新维护堆属性，调用MaxHeapfy就是为了这个目的。因为堆的根结点、点是这个堆的最大元素，所以每次我们都取到了当前堆的最大元素，一次遍历后就得到了排好序的序列。需要注意的一点是，根据C++标准库的惯例，EndIter指向最后一个元素的下一个位置，所以在for循环中第一句先–EndIter。很显然该函数的时间复杂度为O(BuildHeap)+O( n\O(MaxHeapfy))。 上述代码中将根结点换到最后叶子再取出是一个要注意的小细节，这样做的妙处在于只破坏了根结点的对属性，而不破坏其它任何结点的属性。对一个堆进行删除操作时，这样的做法很好的减小了复杂度。 我们还有两个函数没有实现，先来说说维持堆属性的MaxHeapfy；这个函数假定结点的左子树和右子树都是堆，那么对指定节点调用MaxHeapfy以后，以指定结点为根结点的子树也会成为堆。C++的实现如下。 12345678910111213141516171819202122232425262728template&lt;typename Iter&gt;void MaxHeapfy(Iter BegIter, Iter EndIter, Iter Position)&#123; //get the Left child and Right child; Iter LIter(Position); Iter RIter(Position); std::size_t Index=std::distance(BegIter,Position)+1; //we must check if the iterator will out the range before we opera it if(Index &lt; std::distance(Position,EndIter)) &#123; std::advance (LIter,Index); std::advance (RIter,Index+1); &#125; else &#123; return ; &#125;//get the largest element in Position and his childrens; Iter Largest(Position); if(LIter！?=EndIter&amp;&amp;*LIter&gt;*Largest) Largest=LIter; if(RIter！?=EndIter&amp;&amp;*RIter&gt;*Largest) Largest=RIter; if(Largest!=Position) &#123; std::swap (*Position,*Largest); MaxHeapfy(BegIter,EndIter,Largest); &#125;&#125; 代码看上去有点长，但其实思路也很简单，先分别获得Position的左孩子和右孩子，然后对比Position与它的孩子的大小，假如它的孩子比它大，那么取其中最大值与它交换，并对存储最大值的孩子调用MaxHeapfy,因为交换以后有可能破坏了它的堆属性。因为是完全二叉树，所以这个递归的最大深度为lgn. 所以该函数的时间复杂度为O（lg n）。 需要注意的是上面对迭代器的操作不使用+,-而是使用distance()和advance()，主要是考虑到非随机迭代器没有定义+，-操作的问题。这也是为了证实我之前说的堆排序不一定要使用连续内存，当然这时候的时间复杂度已经不一样了，因为对于非随机迭代器，distance()和advance()的复杂度将不会是1，这儿不多说这个问题。另外多说一句，为什么一定要对迭代器进行检查?TheC++ Standard Library上说对于迭代器越界问题C++并没有定义，所以不同编译器对于这个问题实现不同，VC++2010在里试图越界操作的时候会中断程序，不论你有没有对迭代器进行解引用。 到了这儿，对于BuildMaxHeap的实现是不是在简单不过呢？我们只要从堆的最后一个结点开始调用MaxHeapfy就可以了。代码如下： 1234567891011void BuildMaxHeap(const Iter BegIter,Iter EndIter)&#123; Iter Iter1(BegIter); //call MaxHeapfy from the last internal node of the heap; for(std::advance (Iter1,std::distance (BegIter,EndIter)/2); Iter1!=BegIter ; --Iter1) &#123; MaxHeapfy(BegIter,EndIter,Iter1); &#125; MaxHeapfy(BegIter,EndIter,Iter1);&#125; 参考：introduction to algorithm –third edition |2012/4/15 修订]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>笔记</tag>
        <tag>c++</tag>
        <tag>Heap Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书随想]]></title>
    <url>%2Fessaies%2Fsentiment.html</url>
    <content type="text"><![CDATA[海涅说：“人类烧书是自我毁灭的前奏。”我大概是个看书过目即忘的家伙。很多时候看过的书，过不了一个月大概连作者都不记得了，这与太多能够“经意间“便引经据典，“留神中”即博引旁征的才人实在差距太大。之所以能牢记开文海涅的这句，一是向这样一句话之间便能断文明兴衰的话太少，二是这样口气大的人更少。为此，当我初一看到这句话时，特地烧了几本教科书，以来反驳。当然，现在回首，才明白，那时的我原来才真是一个狂徒，十几岁的毛头小子，便妄想代表人类。 还有两个小时，要交一篇寒假的读书笔记。我呢确实是寒假不曾看书，即便看书也少有笔记的时候，偶然心血来潮，在书上留下的心得，大多不能上得台面，不为老师所喜。寒假唯一看的一本很厚的杂志，并没有留意名字，大概叫党史解密之类的名字，里面内容多不可信，我更不敢将感想这么正儿八经的上呈且要在档案室保留个三十年。所以，读书笔记我自然写不成，仅以此文替代。 作为一个小学时候，经常语文不及格，而同学们都能得八九十分的学生。我大部分能理解自己为什么不经意间就会写错字。但在我高中以前，我很不能理解，为什么大部分除了课本报纸都不摸一摸的同学，概括的名著中心思想，总能比我拿到更高的分———哪怕这本书我我看过，对方没看过。到后来有一个老师，给我这么一个提示：“一本名著你只要看看导读，然后把这个背了“，然后他拿出一份资料，上面有一些书本清单，后面跟着是主要人物，然后是故事内容，中心思想。天见尤怜，我从不看导读，我有这样一种认识，看过导读，无形中我便会被导读牵着鼻子走。 托尔斯泰的《复活》，帮我建立了我的阅读习惯。我那个时候十一岁，你大概很奇怪，对于一个十一岁的孩子来说，是什么能够吸引它看完《复活》，而且反复读了三遍呢？实不相瞒，到现在我能记得里面人物名字没有一个，而情节也是模模糊糊记得一两个，而唯一令我记忆犹新的只有一个词——”诱奸“！当我在第一页看到这个词的时候，我生平第一次体会了文字的魅力，我当时对这个词的创造者佩服的无以复加。对于一件这么复杂而晦涩的事情，形容起来仅仅需要两个字，这使我震惊。 再说上个学期，读到《孟子》中有一篇文章，我很喜欢。我虽然反复读了几遍，遗憾的是但到现在还是忘了名字。讲的大概是人心本美，犹如青山，但被人日日砍伐山上树木，最后青山也会变得丑陋。其中有一句我是记得的叫做:”旦旦而伐之，可以为美乎？”，之所以记得这句是因为就在读《孟子》后不久，我看到一个网络小说中有一句”旦旦而伐“，用来形容皇帝房事过度。我当即喷茶，最后拍案称绝。 《孝经》读了没有十遍也有八遍。上个学期，每晚都要翻翻，总有新意能有体会，但现在闭眼一想马上浮现的确实“谨身节用，以养父母，此庶人之孝也”和“身体发肤，受之父母”两句。至于，所谓天子之孝，诸侯之孝….. 写到此处，字数大概也够了，还有 一个小时就要去交。便到处为止吧。 曹子建上表随军出征（出征哪儿我又忘了）的奏折中有一句：“恐坟土未干，而身名两灭”。引以自勉。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序之插入排序与合并排序-C++实现]]></title>
    <url>%2Falgorithm%2Fintroductiontoalgorithm%2F%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F-insertionsort-c%E5%AE%9E%E7%8E%B0.html</url>
    <content type="text"><![CDATA[插入排序很简单，也好实现。下面是实现代码: 12345678910111213141516171819202122//2011/7/17#include&lt;algorithm&gt;#include&lt;limits&gt;template &lt;typename T&gt;T InsertionSort( const T&amp; BeginIter, const T&amp; EndIter)&#123; auto Iter=BeginIter; ++Iter; while(Iter!=EndIter) &#123; auto Key=*Iter; std::reverse_iterator &lt;T&gt; RIter(Iter); std::reverse_iterator &lt;T&gt; RBeginIter(BeginIter); while(RIter!=RBeginIter &amp;&amp; Key&lt;*RIter) &#123; auto Iter3=RIter; *--Iter3=*RIter++; &#125; *--RIter=Key; ++Iter; &#125; return Iter;&#125; 合并排序的核心思想则是将大的序列分成小的序列,再排序,然后将排好序的小序列合并. 下面是实现代码. 12345678910111213//2011/8/16template &lt;typename T&gt;void MergeSort(const T&amp; BegIter,const T&amp; EndIter)&#123; if(BegIter+1&lt;EndIter) &#123; auto MidIter=BegIter; advance(MidIter,distance(BegIter,EndIter)/2 ); MergeSort(BegIter,MidIter); MergeSort(MidIter,EndIter); //CombineResult(BegIter,MidIter,EndIter); std::inplace_merge(BegIter,MidIter,EndIter); &#125;&#125;]]></content>
      <categories>
        <category>Introduction to Algorithm -third edition</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>c++</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大记，亦大忌]]></title>
    <url>%2Fessaies%2Ftado.html</url>
    <content type="text"><![CDATA[大记，亦是大忌，每每动笔要写点什么，我总是想要尽量把它写短，但太多时候不能如意。大概一个人生活中过于默然，需得从文字上还回来。既是大忌，我当然只想小记一下，以免言多有失，但人的能力，总要限制住人的意愿，又不得不多费笔舌。又或者，我信奉这样一句话，有多大的本事，出多大的风头。…. 人贵于自知….. 回归正文。 我不只一次的感叹，头上杂草丛生，但又幸运于它比之寸草不生要好过太多。我的最大优点大概在于，于不幸中总能生出一点侥幸。大记于名字开始。 取名字不比娶老婆——从来都是先娶了大的，然后才有小的——恰与之相反，都是先有了小名，然后有了大名。说这句话，不必以为我是色中恶鬼，小小比较而已，也没有深意。寒假在家看族谱，又听我爸爸将他爷爷那一辈，我爷爷讲他爸爸那一辈的故事，也就是我太爷他们的故事。有那么一点震惊和那么一点唏嘘，抑在胸腹至今，始成笔墨。我祖宗叫广陵公，封地在现在广东哪个县的那一带，我已忘了。原因在于我对广东的不感冒，以至于祖籍都被遗忘，也忘却了他有几妻几妾，这到并非因为我对女人不感冒，仅仅是忘了。他有十四个儿子。儿子们的名字都取大水之意。譬如“巨川”，“巨涟”,”巨渊”之类。十四个儿子说不上大富大贵，但差劲的也能当一个县丞之类。再往后一些，是我太爷他三兄弟，取名各个也有意思，全取“大光”，譬如“裕光”。但三人都是英年早逝，最恰当，最能形容的词莫过于“不得好死”（纯粹用来概括死状，非咒人）来形容。所以我以一种江湖术士的眼光来推测，大概我们这一脉的人，与水相融，能得富贵，与火相近，不得舒坦，我自然是后者。 三兄弟都是革命家，革命是光荣的，自然也是惨烈的。无奈的是，三人都与惨烈结缘，却很少有荣光普照。三人中两个是挨户团，也就是跟着共（*）产（*）党干的。另外一个是国民党。假若，历史书上都说国民党是反动派，那么我们也就定之为反动派吧。大概事情到这里是令人欣喜的，因为知晓历史的我们都知道，挨户团是二几年的事，那时候革命才刚开始，任何一个能从那个时候活下来的，不论能干还是混蛋，总能成为了不起的人物。况且，据说从画像上看三兄弟高大英俊，相貌不凡，断不是我这样的后辈能望其项背的。然而，向来先驱总要先去，三人也不例外。挨户团的两位，一位被矛头，在胸口戳了七个洞，据说在改坟的时候，捡出了半截矛头。另一位呢，被山西钩钩着屁眼掉在大屋坪的牌坊上，直到活活吊死，这其中有几天几夜就不是我能只晓的。当然这些都是逼供的手段。总之，虽然死的时候不甘不脆，但死后确实干干脆脆，除了留下我爷爷未满周岁和我爷爷他爷爷，过了半百，甚至留抚恤金都没有留下。至于国（*）民（*）党的那位呢？死的时候是个连长还是营长来着，只是被活活围在碉堡中，不用说会死的多惨。但是这位反（*）动（*）派的连长又或是营长的死，得了五百大洋的抚恤金。 倘若事情便是这样，我觉得也是没有必要付诸笔墨的必要的。因为，向来动荡之期，危难之时，死人流血，太过平常。更何况，当先驱自然要有先死勇气，作为后人，我尚能有这样的觉悟。这些都是外话。 革命并非只贡献人命，还需得有钱。倘若你既能，贡献人命，又有金钱付出，那是最好不过了。而，爷爷他爷爷呢？恰好没儿子的时候有了钱。向来，政治的风格就是这样的，没了依傍的人，最好“做工作”，也最容易用让他们“理解组织难处”。然而，连丧三子，又带有未满周岁的孙子的老人，尚不足有位革命慷慨解囊，位党国倾家荡产的觉悟。为了避免敬爱的党来做思想工作，偷偷把五百大洋寄存在一个熟识的富户家。在完成了儿子为止奉献生命的党的思想工作以及为了保护烈属的检查后。不过，富户在第二天，就告之，钱被偷了。 之前说了，若是死了人，流了血，断没有付诸笔墨必要的，哪怕再加上失了财。最终，那一户骗了钱的富户，再往后的日子里，死绝了。绝种了，绝代了。仅此而已。 到此，很明显，很明显，我写此文的目的，很单纯，很单纯，那就是作恶会着报应的。仅此而已，仅此而已，请君回味。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[又到离别时]]></title>
    <url>%2F2010%2F04%2F01%2Fessaies%2F%E4%B8%80%E4%B8%9D%E4%B8%8D%E6%8C%82.html</url>
    <content type="text"><![CDATA[我想，很难再平静的写一些东西，很难。 来不及回头看过去的日子，放纵于浮夸的生活中。不经意的时候，想起某些不经意的事情。譬如会想起一中图书馆，正面第二个书架最下面的《金瓶梅》学究，又或者是右边第四还是第五个书架背面最上排的《中国古代帝王艳史》系列丛书，还有那个右墙最里面书架背后我窝着看《三个火枪手》的角落，那些在脑袋中一闪而过的画面，和来不及怀念的人物。 人最淡的哀愁莫过于无所适从的叹息时间绕身而过，而最浓的哀愁都比不过围着时间不知所措。 我大概猜想时间是不动的，它是一个大大的球，所有的人于其上或走或跑，并不自知，也看不到尽头。偶尔一搭，一搭的回答别人对于近况的问话说：“混日子罢了”。于是，从猜想来说不过是“混球”。 有这些天，我日夜在《骑马与砍杀》这个游戏里，体味在屈辱与荣耀中挣扎乞生。 那么一种状态，你不能理解是该庆幸还是该悲哀，何以自处？]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
</search>
